{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Episodic Memory for Continual Learning\n",
    "\n",
    "We adapt the GEM algorithm to train the ResNet18 model on the CIFAR-10 Dataset. The GEM algorithm is a continual learning algorithm that prevents catastrophic forgetting by constraining the gradient updates on the new task to be orthogonal to the gradients of the previous tasks. The algorithm is implemented in PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAGbCAYAAAAr/4yjAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8o6BhiAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAdiElEQVR4nO3dW6xlBZ3n8d9aa6+99uXc6wpUURcQqO5GmR5nprvBIVImJkKIJgb1wXhJqSTzYCLGRJykFBOJL5RPjhdiRJ8sH8AHDGpiJShJazoOjtLIdaqAunBOnTr3fV9rzYMz/3SNGP9/p7qxmO8n4cHjn/9Ze621929viv0jqeu6FgAAktLX+wAAAH85CAUAgCEUAACGUAAAGEIBAGAIBQCAIRQAAIZQAAAYQgEAYAgFXHY+//nPK0kSnT9//vU+FOANh1AAABhCAQBgCAXg/1LXtfr9/ut9GMDrglDAZWt1dVUf/vCHNTc3p9nZWX3kIx9Rr9ez/38ymeiLX/yirrnmGhVFof379+vee+/VcDi8aM/+/ft1xx136Ec/+pHe+ta3qt1u6+tf/7ok6Sc/+YluueUWzc3NaWpqStdff73uvffei/7+4XCoo0eP6tprr1VRFNq7d68+85nP/MHvAS4Hjdf7AIA/11133aUDBw7o/vvv169+9Ss9+OCD2rlzp7785S9Lko4cOaKHHnpI733ve3XPPffoF7/4he6//349/fTTevjhhy/a9cwzz+gDH/iAPvGJT+hjH/uYrr/+ej311FO644479OY3v1n33XefiqLQ888/ryeeeML+vqqqdOedd+rnP/+5Pv7xj+vQoUP6zW9+o2PHjunZZ5/VI4888m95SoD/dzVwmTl69Ggtqf7oRz960c/f85731Nu2bavruq6ffPLJWlJ95MiRi2Y+/elP15Lqn/70p/azffv21ZLqxx577KLZY8eO1ZLqpaWlP3os3/3ud+s0Teuf/exnF/38a1/7Wi2pfuKJJ/6sxwi8XvjHR7hs3X333Rf977e97W1aXl7W+vq6fvjDH0qSPvWpT100c88990iSHn300Yt+fuDAAb3zne+86Gdzc3OSpB/84Aeqquo1j+H73/++Dh06pBtuuEHnz5+3v2677TZJ0okTJ/68Bwe8TggFXLauvvrqi/73/Py8JGllZUWnTp1Smqa69tprL5rZvXu35ubmdOrUqYt+fuDAgT/Y/773vU8333yzjhw5ol27dun973+/jh8/flFAPPfcc3rqqae0Y8eOi/667rrrJEmLi4uX5LEC/1b4MwVctrIse82f1//ivzCbJIlrV7vdfs2fPf744zpx4oQeffRRPfbYY/re976n2267TT/+8Y+VZZmqqtKNN96oBx544DX37t271/X7gb8UhALekPbt26eqqvTcc8/p0KFD9vNXX31Vq6ur2rdvn2tPmqY6fPiwDh8+rAceeEBf+tKX9LnPfU4nTpzQO97xDl1zzTX69a9/rcOHD7sDCPhLxj8+whvSu971LknSV77ylYt+/n/e0d9+++1/cseFCxf+4Gc33XSTJNm/bnrXXXfp9OnT+uY3v/kHs/1+X1tbW5HDBl53fFLAG9Jb3vIWfehDH9I3vvENra6u6tZbb9Uvf/lLPfTQQ3r3u9+tt7/97X9yx3333afHH39ct99+u/bt26fFxUV99atf1Z49e3TLLbdIkj74wQ/q+PHjuvvuu3XixAndfPPNKstSv/vd73T8+HH77gNwuSAU8Ib14IMP6uDBg/r2t7+thx9+WLt379ZnP/tZHT161PX333nnnTp58qS+9a1v6fz589q+fbtuvfVWfeELX9Ds7Kyk3//jpUceeUTHjh3Td77zHT388MPqdDo6ePCgPvnJT9ofOAOXi6T+l38qBwD4/xp/pgAAMIQCAMAQCgAAQygAAAyhAAAwhAIAwLi/p/BfP/VfQotr+b/yn+V5aLcC5a5lGfs3bv9YG+ZrSmO1Blkgg9PAYUiSktjjTBqv3Rv0mscSrG+oy9I9W5axB9oIHHcV/LetS01C82nmv55FEnv/VU/8xzKq/OdbkurA9cwbsePO/0gf1WupAq8RkjSexO6VLI28TsR2V7X/+qTBa59W/vu2rsah3UeP/bc//ftDGwEAb2iEAgDAEAoAAEMoAAAMoQAAMIQCAMAQCgAAQygAAAyhAAAwhAIAwBAKAADj7j4qpqdDiyv5O1CSYAfK1tbQPdtudUK7k0CfTRrsPsrzwj1b1bE+mySNdaAktf/YJ+PY7nLs74VpxE6hskC3Th7ovvm9YLdOoBcoC/TZSFI58Z/z6OOcBLqSGsHdWeA5UQfPSdYMjSvN/f8J+qoK3oiB17cs+PqWBDqeykAHkxefFAAAhlAAABhCAQBgCAUAgCEUAACGUAAAGEIBAGAIBQCAIRQAAIZQAAAY9/fA57ftDC0eBb6qPexvhHafeeYV9+zC/PbQ7nHl/2p8tKJhzx7/OexM+SsxJCmpYx0Ae/Zf555dX10O7b6wdM49m6SxqgMFKjfSrBVaXQVrFxpF4D1V4r+vJGkyGvmPI1D9IUn1uOcfzmI3eSP134dVoA5Fkqo0dg7r2n+vxApOpDTN/ccRfJxpw3/fVqX/PnH//ku+EQBw2SIUAACGUAAAGEIBAGAIBQCAIRQAAIZQAAAYQgEAYAgFAIAhFAAAhlAAABh3mUjZWw8tHvQ33bPDTf+sJJ07+ZJ7dvOV/xnavdn3z57djPWOLOza5p69YudCaHdSxTpq/ipwyvdeORvarf6KezTSISNJ46G/JyttzYR2T4ax61mN/ee8aLVjx7Lhf5yNTuxxJuOBfzh2eZQ1/P1Ro0Gs80yNWB9YHXmcwV6lpOHveKpH/g4mSaobU+7ZcrAW2u3BJwUAgCEUAACGUAAAGEIBAGAIBQCAIRQAAIZQAAAYQgEAYAgFAIAhFAAAxv3d7jSJ1Sg0my3/cMv/1XhJaiSZe7abDEO7W03/41xKY8f98ll//cPi4mpod6OOXZ/Fc0vu2b//h78N7d4x13XPpo1YvUBW+ysDkkaso6GpKnYsuX9/Fj2Wjr9GoWh3QrtHtf++TQPPB0lKM38VRaMoQ7sVqJaQpFE5cc+mjcDrlaS0Gai5qGPvvfOmvxIlUaDKw4lPCgAAQygAAAyhAAAwhAIAwBAKAABDKAAADKEAADCEAgDAEAoAAEMoAAAMoQAAMO7imTrYfZTn/v6OftkP7e4EemFmmv4uFkka9P1dSds7seMebfp7e5TEel6mulOh+aT29/wsvXwmtHt9dZt7dmoq9jjnp/0dQu0i1gmUN2M9TEngLdWkjj3OOg1czyy2O8167tkqVgelUeR9ZrATKEljjzNv+F+D6mCPWSMP3Ctl7CTWqf+1Nmlc+vf1fFIAABhCAQBgCAUAgCEUAACGUAAAGEIBAGAIBQCAIRQAAIZQAAAYQgEAYNzf1R5troUWD2v/V7WXXn01tLs7468A6LZaod1lveqenR1OQrtHLf/X3Rc3t0K7VxU7FqVd/7GcORtafWHtRfdsy99aIUm6dv8u9+zB624I7U46sSqXOvGf8ySN1a2kpb9uRY3YcZcb/nurXwWqWSRlhf+cpJNYTUyalKH5euzfnxex14msHrhnB4PYa2fe9p/DYS+224NPCgAAQygAAAyhAAAwhAIAwBAKAABDKAAADKEAADCEAgDAEAoAAEMoAAAMoQAAMO7uo5nd+0OLxyN/d8vqmcXQ7rluxz07rGOdQGsDf6dJnjdDu3d3/R01ZX8jtHut7z9uSSrH/h6m1SIL7e73N92zozrWrXO28ne9NEaxc7j9qu2h+axou2frSaz7aPnCkn92axTaPV73PzerxH+fSNLV+65yz+7ae3Vo98oF/30lSUnguX/lzM7Q7kbuf040i9h771Z73j2bJrHnpmvnJd8IALhsEQoAAEMoAAAMoQAAMIQCAMAQCgAAQygAAAyhAAAwhAIAwBAKAADjrrlo1LGv0mvSd49261hFw3DTv/v8Ruyr8VsTf+3C1JS/bkOS8r5/9/ZOrEJjphGr82gXtXu2N9wK7R7Ifyx55j8OSUpL/324cvql0O6tlXOh+UmVu2fL2MPUoPa/XzuzErs+7dT9tFfR8D9GSTo79NeQnFuK1du8cD72XC6Krnv2P9+yENp94Ko592xnyn8ckqTUX12RN2L1Ka5ff8k3AgAuW4QCAMAQCgAAQygAAAyhAAAwhAIAwBAKAABDKAAADKEAADCEAgDAEAoAAOMuQRn1NkKL6y1/T0nLX8UiSdrYWnXPbg1inU1/c9Pfume7wQM/9eyL7tnxMNZlVOT+XiVJajYq92ymJLR7XPq7W1TFSoGqQInQwP8QJUlloFdJkhKV7tmiG3v/Nbd7j3s2a06Fdg82/c/l6U47tLud+nvJ1FsK7d49MxOaf+Gsf//zTz8b2r1v243u2fE4cE4kJZn/PsyS4E3uwCcFAIAhFAAAhlAAABhCAQBgCAUAgCEUAACGUAAAGEIBAGAIBQCAIRQAAIZQAAAYd3lP2Yh1oKz119yzK8Gen17tz7JDb/l3od0Hb/hr9+w4GYZ2V82mf/bJp0K7eysXQvN17e9Xmep0Qrsr+c/LJFbZpEbq72Gq61ivUlSW+vcXeawna6bw9xkls7Hrs1r7n29zs9Oh3dPNwj1bpP7uKEmaa86G5hc3Bu7Z51/095JJ0n+66Tr3bKedh3Yr9d8rJd1HAIB/TYQCAMAQCgAAQygAAAyhAAAwhAIAwBAKAABDKAAADKEAADCEAgDA+GsuxrE+go2BvwJgpfJXF0jSm/76b9yz0YqGUW/DPbtVb4Z2Ty34j2Xvwf2h3S8+uR6abzYz9+z8dKzqoFX4z2G/3w/tHg799RxVFau5SJPYfKvtP4fdbuw+TCf+c1hksefPzEzg2s/66zYkqWj732e22rHqj8l67Pp0mv56iRfPLYZ2n3z5jHv2uoO7QrvTxH9eRlWwJ8bz+y/5RgDAZYtQAAAYQgEAYAgFAIAhFAAAhlAAABhCAQBgCAUAgCEUAACGUAAAGEIBAGDcJRt54u9LkaRtO7a7Z7NWLJt2B3Zvri6Fdg/7/s6Z3sZKaHfW9HeaTC/4H6MktbvBjpqWv0dmamE+uLvlnl1ZXg7tHgY6uBpp7L7KFevWaRdt92yraIZ2q/R3WWXB7rCkCjyX81g/Ud3wP85+bxjavba6FpqPyAPPTUk6fdrffbR3d+z5Mx14vu3YGetV8uCTAgDAEAoAAEMoAAAMoQAAMIQCAMAQCgAAQygAAAyhAAAwhAIAwBAKAADj/m53ZyZWu5CP/HUEraII7c5S/1fSp4LHnWYd9+w4i1VLtLv+3Z3cXxUhSZ35p0PzzcR/fbIiD+0el/7dSR6rT8lSf6VDkcV2N4I1F5EWjUYjdg6rcuQ/jnIS2x1olxgPytBulQP36ObKq6HVF9a3QvNFc9o9OzM7G9q9HDiWzUnsvurIf6+MxrF73INPCgAAQygAAAyhAAAwhAIAwBAKAABDKAAADKEAADCEAgDAEAoAAEMoAAAMoQAAMO4SoWF/M7S4Lv2dKUnt73mRJH/7jTQe9kO7s8Kfk9MzsX6ivOnvNOm22qHd09P+XiVJyip/P1ER7KbaXLvgni0nsWufKnJfhVYrDfQqSVItf+dQtPsobfh7tTY3Yx1CdeI/lt4gUJQkabTuf51YWVwO7d4cVqH5Hdfvc8+OM//zQZJ6m/7zsrzq74OSpFZzyT27tnomtNuDTwoAAEMoAAAMoQAAMIQCAMAQCgAAQygAAAyhAAAwhAIAwBAKAABDKAAAjLvmQmXsq9qDkb++IMti9QJ57u8vGDdjX41PUn+NQj2JVQBUdaCiIVgtkTVj85MLG+7Z1o7tsWNJMvdsWsW6KJLA7jJwviUpT6LvkfzzSewWV5I03bPjLHbtx5X/HK6vr4d2r19Y9B9HP1ZBo8x/TiRp1+4r3bPNbbH78Le/fcE9+/Ir/toXSbpizl9xk2W90G4PPikAAAyhAAAwhAIAwBAKAABDKAAADKEAADCEAgDAEAoAAEMoAAAMoQAAMIQCAMC4u4+mFnbEFge6j6oq1lHTbM24Z9POfGh3GuhXKctxaHer8FdNFd1WaPfUlbHrc+rlk+7Z9vJKaHc18vdk1cFOoDT3n8N6FLs+k9htqFbqP5bxZBLavb655Z5tdOdCuyfL/s6hfj/WrVOW/g6huojd40XH3wkkSbMt//VpTcWO5ZWFKffs2lbsHPaG/m6q/QcOhHZ78EkBAGAIBQCAIRQAAIZQAAAYQgEAYAgFAIAhFAAAhlAAABhCAQBgCAUAgCEUAAAmUN7i72KRpKrv71dZH6yHds9V/tk0MCtJddNfgDMa+zt+JKka+HthJpuxUqBOMw/Nb9u9yz27sRa7Pmtra+7Z0+ubod2job/PqBvs1CoCvUqSlLUCfUabsce5vOLvm0rGsZu8nPjvwyyL7U4z//vMzWA31ULH30smSXnl7xyqxrF7Zd8uf//a2dOx7rAzp8+6Z1vNWK+SB58UAACGUAAAGEIBAGAIBQCAIRQAAIZQAAAYQgEAYAgFAIAhFAAAhlAAABj39/oneRFaXMv/tfE86YR2J4EsG078dRuS1Gz4KwDyahjanab+GoUkacV2x76lrzxQ6dBrxCo0zqz5z8vpwKwkLczNu2cvrMbqOVqT2EkcJv6ak2wrVunQG/vnd+2aDu3O5T/u4UbsHGZN/32bBR6jJC20stB8q+W/x4v2VGh3o+V/zSqq2HvvleUN9+zGWuy56cEnBQCAIRQAAIZQAAAYQgEAYAgFAIAhFAAAhlAAABhCAQBgCAUAgCEUAACGUAAAGHc5SKMxE1o8aPo7hLrtZmh3M/X3MFVJrF9FmT8nG8F+okagQygPdrEsv3QyNH/6pTPu2aS7ENpdt2bds/NVaLX+7u//wT176uTp0O5zr7wQmt+oR+7ZZtYO7T546K/cszfe9O9Du1/87//knh0M/Y9Rkg68yX/cq2f996AktdPYczltdt2znYXdod2twGlpt2PdVFnxqnt2OIldHw8+KQAADKEAADCEAgDAEAoAAEMoAAAMoQAAMIQCAMAQCgAAQygAAAyhAAAw7pqLweZSaHG/v+WezTJ/JYYkTZKee7Ya+o/j9wfjr6KYjGNfMW8V/nqOldXYcf/zMy+G5vNAFcUN/+HvQrvH//SP7tn1c7FzONX1n8P/+LbYcW+sXxOaLydD92wzj1WidDr++zBruJ/Gv59vBo4l9R+HJO28wl8XMd/KQrvPvHgqNL+02nfPXrU9Ce2uM38/S96I7d5z1S737LkzsSoXDz4pAAAMoQAAMIQCAMAQCgAAQygAAAyhAAAwhAIAwBAKAABDKAAADKEAADCEAgDAuEtTJrF6IiXyd6aMgx1CaRHoY8n8XTmSVOSBeX/9iSSpETiWl0+eD+1eHcV6ZO549x3u2em5qdDuc2decs8Otvz9NJJU1f73MZ25mdDudqcZmi/H/u4jJbF+oslgwz2bNtqh3f2x/8m8vhl7btaJ/z4sFuZCu8dnY8+JC4H+sO3DQWh30fZfz0kWe+/dKvzdVPPbt4V2e/BJAQBgCAUAgCEUAACGUAAAGEIBAGAIBQCAIRQAAIZQAAAYQgEAYAgFAIBxf1c7DdRWSFIz83+VflzH+iLq2r97NBmHduetjns2TWLnZJz4M3i95/+KviQtbJ8Pze+66gr37Mr5pdDuzpS/FqNoxSo0JoGKhlE/du0bSWhcSv21GJMytnwcmK+q2O6s8J/zSe5/PkjSaOQ/59Mzsd15N3avrK75n0PlIFi1k/ufy3WgmkWSFKgK6XZj59CDTwoAAEMoAAAMoQAAMIQCAMAQCgAAQygAAAyhAAAwhAIAwBAKAABDKAAADKEAADDu7qPBaD20OBlO/LNVrKMm0iUy3roQ2t2r/R0o481eaPckc59uTXVivUp1P9YfNe4P/lVmJWljbcW/e9IP7d7aWHbPzqzFunJqf+WMJKmUv4cp2n1Ujjbcs/2qDO1u5IEH2m6Fdq+unnXPdlsLod2d6W5ofnHZ39k13FoL7Z5p+2ez4TC0uxF4q57K/zrr3wkAwP9GKAAADKEAADCEAgDAEAoAAEMoAAAMoQAAMIQCAMAQCgAAQygAAIy7d6FoFqHFSdJ0z46GsaqDJPdXQIzLWHdBM/E/ziT31xxIkgJVB7MzsfN9dtNfLyBJo0A1wriOPc5B5Z+vu7EqiqTVcc+mqb9WRJImlb/iRJLqzH9vZUXseo4n/mqRRtN/TiSp1ws8zmCLwtzUjH84jT03W9OB3ZLK9Jx7dnVrM7R7fuece3aSxypO0qb/vfqkjN3jrt9/yTcCAC5bhAIAwBAKAABDKAAADKEAADCEAgDAEAoAAEMoAAAMoQAAMIQCAMAQCgAA4y7OmGzGukHG5dg9Oymr0O5C/t6eRhbbXZf+3aNxcHdkvN4K7V5cPB+a/+3/+Gf37J4rdoR2NwKdQ51OrPsoTf29V2Xqv5aSlFaxop8s9fd79cbD0O7RxH/sE8W6dVY2e+7Z+fl2aPf8jl3u2a1+7B7vdv3XXpLmZvzHvroe619bG/rvlTr4OjEZ+HdPxv6OLC8+KQAADKEAADCEAgDAEAoAAEMoAAAMoQAAMIQCAMAQCgAAQygAAAyhAAAwhAIAwLhLapI61q9Sjv1dImWgb0iSxrW/VykN9CRJ0njg73gaD/3HIUlJ6s/gSrG+lE47dn1eePop92w+via0uw70sTSVhXYPtjbcs73N2DkJnkKlee2eHfRj3UflwD+/NIod+PnlNffsm950RWh3mfrPiQIdWZLUKTqh+V2BHqZzS0uh3cPAc78eB86JpFHtf/6U/VhnkwefFAAAhlAAABhCAQBgCAUAgCEUAACGUAAAGEIBAGAIBQCAIRQAAIZQAAAY9/fMx5NeaHFS+7/ancW+Ba5+f+SeHU1iVRSNzJ+TeTBSy8p/LFkSqy7Ye8VCaP7cmQvu2cUzZ0K7Z3f46wjW1mN1HuXIX1symUxCu9UpQuNp21/RUTS6od1Vs+2ePbO0EtrdDNy4e666MrQ7afjPYasbO9/R97CtKf857730Umh3b91fhzM1MxXa3S/9VS5pFnv+uHZe8o0AgMsWoQAAMIQCAMAQCgAAQygAAAyhAAAwhAIAwBAKAABDKAAADKEAADCEAgDAuLuPhsHuo0jaZM1Yz89U7u+cGY/cD1GSVAc6h6rSfxyS1Ehz/3EEK01a0W6dnf4rVOSxg5ku/J02p5ZfCe2eK/zHMpXH+qDSwPWRpJG/gktFoxna3Z7z34e9vr8rR5LKq3a6Z7tdf4+VJG0FjiWp/T1WktTNW6H5qUagVC3Q1SZJw57/4u/dGbuv6lX/bJLFXjs9+KQAADCEAgDAEAoAAEMoAAAMoQAAMIQCAMAQCgAAQygAAAyhAAAwhAIAwLg7ILIkVumQJP56iUYey6YsDXy1O4nt7o8m/uEidk7SzH8sw94gtluxr7vnHf+xz83HKjQ21v2VKDu2xSoA8tR/DvtlrLpA/eA5D9RidDqxioZB338OW7EmFxWBmpil88uh3WXZd8+mSez6VJ1Y3cpg6K/RmAQqSyQpm4zds2nwtXNhbsY/HKzn8OCTAgDAEAoAAEMoAAAMoQAAMIQCAMAQCgAAQygAAAyhAAAwhAIAwBAKAABDKAAAjLs1pVEUocWTiT9vkkasG6QO1PyMKn//iSQp0KuUprEuFlX+npKpTqwTqNuKXZ+tnv9Yslitkqa6/p6fuXYztHs09h9M0oz1DakR65HJAt1H5XgY2j3YWnHPjkf+Hh5J6jT9ZUl5sFep3fTfh9127J4dlIFeMkmTwPxsN/Z8m5n2z1dlrFgpTQPPzUCfmvv3X/KNAIDLFqEAADCEAgDAEAoAAEMoAAAMoQAAMIQCAMAQCgAAQygAAAyhAAAw7i+x551ObPPQXy8Rqa2I/g3R3VXlrwxIApULkpSn/jqPdh772n2jjlU0dANVB41G7Fiq3H9eqkmsKqSu/dcnTWLnJPoOKQ1UDETvw5n2dvfscBSrf6hL/32YFrEKmnbhv1c6zdjuXq8fO5bUX6Gya+ZgaHezCPR/1LGai9EwcN8GzrcXnxQAAIZQAAAYQgEAYAgFAIAhFAAAhlAAABhCAQBgCAUAgCEUAACGUAAAGEIBAGCSug6W5gAA3rD4pAAAMIQCAMAQCgAAQygAAAyhAAAwhAIAwBAKAABDKAAADKEAADD/C//LmIkeHF8cAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import time\n",
    "from cifar import load_cifar10_data, split_into_classes, get_class_indexes, load_data\n",
    "import cifar\n",
    "from torch.utils.data import DataLoader\n",
    "import random\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(\".\"))  # Adds the current directory\n",
    "# from GEM.gem import *\n",
    "from GEM.args import *\n",
    "from torch.nn.functional import relu, avg_pool2d\n",
    "import torch.nn as nn\n",
    "import quadprog\n",
    "\n",
    "AGEM = True\n",
    "PRETRAIN = 0 # number of initial classes to pretrain on\n",
    "# Globals \n",
    "DATASET = 'cifar-100'\n",
    "DATASET_PATH = 'cifar-100-python' \n",
    "CLASSES = cifar.CLASSES\n",
    "SHUFFLEDCLASSES = CLASSES.copy()\n",
    "if DATASET == 'cifar-10':\n",
    "    CLASSES = cifar.CLASSES\n",
    "    SHUFFLEDCLASSES = CLASSES.copy()\n",
    "elif DATASET == 'cifar-100':\n",
    "    CLASSES = cifar.CLASSES_100_UNORDERED\n",
    "    SHUFFLEDCLASSES = CLASSES.copy()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Scraped code fundamental for GEM this is the code required to create a resnet18 model from scratch \n",
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=1, bias=False)\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(in_planes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion * planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion * planes, kernel_size=1,\n",
    "                          stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion * planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = relu(out)\n",
    "        return out\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes, nf):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = nf\n",
    "        self.conv1 = conv3x3(3, nf * 1)\n",
    "        self.bn1 = nn.BatchNorm2d(nf * 1)\n",
    "        self.layer1 = self._make_layer(block, nf * 1, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, nf * 2, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, nf * 4, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, nf * 8, num_blocks[3], stride=2)\n",
    "        self.linear = nn.Linear(nf * 8 * block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1] * (num_blocks - 1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        bsz = x.size(0)\n",
    "        out = relu(self.bn1(self.conv1(x.view(bsz, 3, 32, 32))))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "def ResNet18(nclasses, nf=20):\n",
    "    return ResNet(BasicBlock, [2, 2, 2, 2], nclasses, nf)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Now lets make the GEM model --  we will scrape this from the GEM code\n",
    "def compute_offsets(task, nc_per_task, is_cifar):\n",
    "    \"\"\"\n",
    "        Compute offsets for cifar to determine which\n",
    "        outputs to select for a given task.\n",
    "    \"\"\"\n",
    "    val1 = max(PRETRAIN - nc_per_task, 0)\n",
    "    val2 = max(PRETRAIN - nc_per_task, 0)\n",
    "    if task == 0:\n",
    "        val1 = 0\n",
    "        val2 = max(PRETRAIN - nc_per_task, 0)\n",
    "    offset1 = task * nc_per_task + val1\n",
    "    offset2 = (task + 1) * nc_per_task + val2    \n",
    "    return offset1, offset2\n",
    "\n",
    "\n",
    "def store_grad(pp, grads, grad_dims, tid):\n",
    "    \"\"\"\n",
    "        This stores parameter gradients of past tasks.\n",
    "        pp: parameters\n",
    "        grads: gradients\n",
    "        grad_dims: list with number of parameters per layers\n",
    "        tid: task id\n",
    "    \"\"\"\n",
    "    # store the gradients\n",
    "    grads[:, tid].fill_(0.0)\n",
    "    cnt = 0\n",
    "    for param in pp():\n",
    "        if param.grad is not None:\n",
    "            beg = 0 if cnt == 0 else sum(grad_dims[:cnt])\n",
    "            en = sum(grad_dims[:cnt + 1])\n",
    "            grads[beg: en, tid].copy_(param.grad.data.view(-1))\n",
    "        cnt += 1\n",
    "\n",
    "\n",
    "def overwrite_grad(pp, newgrad, grad_dims):\n",
    "    \"\"\"\n",
    "        This is used to overwrite the gradients with a new gradient\n",
    "        vector, whenever violations occur.\n",
    "        pp: parameters\n",
    "        newgrad: corrected gradient\n",
    "        grad_dims: list storing number of parameters at each layer\n",
    "    \"\"\"\n",
    "    cnt = 0\n",
    "    for param in pp():\n",
    "        if param.grad is not None:\n",
    "            beg = 0 if cnt == 0 else sum(grad_dims[:cnt])\n",
    "            en = sum(grad_dims[:cnt + 1])\n",
    "            this_grad = newgrad[beg: en].contiguous().view(\n",
    "                param.grad.data.size())\n",
    "            param.grad.data.copy_(this_grad)\n",
    "        cnt += 1\n",
    "\n",
    "\n",
    "def project2cone2(gradient, memories, margin=0.5, eps=1e-3):\n",
    "    \"\"\"\n",
    "        Solves the GEM dual QP described in the paper given a proposed\n",
    "        gradient \"gradient\", and a memory of task gradients \"memories\".\n",
    "        Overwrites \"gradient\" with the final projected update.\n",
    "\n",
    "        input:  gradient, p-vector\n",
    "        input:  memories, (t * p)-vector\n",
    "        output: x, p-vector\n",
    "    \"\"\"\n",
    "    memories_np = memories.cpu().t().double().numpy()\n",
    "    gradient_np = gradient.cpu().contiguous().view(-1).double().numpy()\n",
    "    t = memories_np.shape[0]\n",
    "    P = np.dot(memories_np, memories_np.transpose())\n",
    "    P = 0.5 * (P + P.transpose()) + np.eye(t) * eps\n",
    "    q = np.dot(memories_np, gradient_np) * -1\n",
    "    G = np.eye(t)\n",
    "    h = np.zeros(t) + margin\n",
    "    v = quadprog.solve_qp(P, q, G, h)[0]\n",
    "    x = np.dot(v, memories_np) + gradient_np\n",
    "    gradient.copy_(torch.Tensor(x).view(-1, 1))\n",
    "    #penis\n",
    "def agemprojection(gradient, gradient_memory, margin=0.5, eps=1e-5):\n",
    "    \"\"\"\n",
    "    Projection of gradients for A-GEM with the memory approach\n",
    "    Use averaged gradient memory for projection\n",
    "    \n",
    "    input:  gradient, g-reference\n",
    "    output: gradient, g-projected\n",
    "    \"\"\"\n",
    "\n",
    "    g = gradient_memory.t().double().mean(axis=0).cuda() # * margin\n",
    "    gref = gradient.contiguous().view(-1).double().cuda()\n",
    "    g_transpose = g.view(1, -1)\n",
    "    dot_prod = torch.dot(g_transpose.squeeze(), gref.squeeze())\n",
    "    dot_prod = dot_prod / torch.dot(g_transpose.squeeze(), g.squeeze())\n",
    "    \n",
    "    # add epsilon to prevent 0 values from fucking everything up  \n",
    "    epsvector = torch.Tensor([eps]).cuda()\n",
    "    \n",
    "    x = g + (gref * abs(dot_prod)) + epsvector\n",
    "    gradient.copy_(torch.Tensor(x).view(-1, 1))\n",
    "    \n",
    "def replay(gradient, gradient_memory):\n",
    "    \"\"\"\n",
    "    Adds the gradients of the current task to the memory \n",
    "    \n",
    "    input:  gradient, g-reference\n",
    "    output: gradient, g-projected\n",
    "    \"\"\"\n",
    "    g = gradient_memory.t().double().mean(axis=0).cuda()\n",
    "    gref = gradient.contiguous().view(-1).double().cuda()\n",
    "    # simply add the gradients\n",
    "    g = g + gref\n",
    "    gradient.copy_(torch.Tensor(g).view(-1, 1))\n",
    "    \n",
    "def naiveretraining(gradient):\n",
    "    \"\"\"\n",
    "    Naive retraining of the model on the current task\n",
    "    \n",
    "    input:  gradient, g-reference\n",
    "    output: gradient, g-projected\n",
    "    \"\"\"\n",
    "    g = gradient.t().double().mean(axis=0).cuda()\n",
    "    gradient.copy_(torch.Tensor(g).view(-1, 1))\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self,\n",
    "                 n_inputs,\n",
    "                 n_outputs,\n",
    "                 n_tasks,\n",
    "                 args):\n",
    "        super(Net, self).__init__()\n",
    "        nl, nh = args.n_layers, args.n_hiddens\n",
    "        self.margin = args.memory_strength\n",
    "        self.net = ResNet18(n_outputs)\n",
    "     \n",
    "\n",
    "        self.ce = nn.CrossEntropyLoss()\n",
    "        self.n_outputs = n_outputs\n",
    "\n",
    "        self.opt = torch.optim.SGD(self.parameters(), args.lr)\n",
    "\n",
    "        self.n_memories = args.n_memories\n",
    "        self.gpu = args.cuda\n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "        Allocate episodic memory\n",
    "        n_tasks: number of tasks\n",
    "        n_memories: number of memories per task\n",
    "        n_inputs: number of input features\n",
    "        \"\"\"\n",
    "\n",
    "        # allocate episodic memory\n",
    "        self.memory_data = torch.FloatTensor(\n",
    "            n_tasks, self.n_memories, n_inputs)\n",
    "        self.memory_labs = torch.LongTensor(n_tasks, self.n_memories)\n",
    "        if args.cuda:\n",
    "            self.memory_data = self.memory_data.cuda()\n",
    "            self.memory_labs = self.memory_labs.cuda()\n",
    "\n",
    "        # allocate temporary synaptic memory\n",
    "        \"\"\" This is the memory that stores the gradients of the parameters of the network\n",
    "            FOR each task. This is used to check for violations of the GEM constraint\n",
    "            Assume:\n",
    "\n",
    "            The model has 3 parameters with sizes 100, 200, and 300 elements respectively.\n",
    "            n_tasks = 5 (number of tasks).\n",
    "            The allocated tensors would have the following shapes:\n",
    "\n",
    "            self.grad_dims: [100, 200, 300]\n",
    "            self.grads: Shape [600, 5] (600 is the sum of 100, 200, and 300).\n",
    "        \"\"\"\n",
    "        self.grad_dims = []\n",
    "        for param in self.parameters():\n",
    "            self.grad_dims.append(param.data.numel())\n",
    "        self.grads = torch.Tensor(sum(self.grad_dims), n_tasks)\n",
    "        if args.cuda:\n",
    "            self.grads = self.grads.cuda()\n",
    "\n",
    "        # allocate counters\n",
    "        self.observed_tasks = []\n",
    "        self.old_task = -1\n",
    "        self.mem_cnt = 0\n",
    "        minus = 0\n",
    "        if PRETRAIN > 0:\n",
    "            minus = 1\n",
    "        else: \n",
    "            minus = 0\n",
    "        self.nc_per_task = int((n_outputs - PRETRAIN) / (n_tasks - minus))\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        output = self.net(x)\n",
    "        if t == -1:\n",
    "            return output\n",
    "        # make sure we predict classes within the current task\n",
    "        val1 = 0\n",
    "        val2 = 0\n",
    "        if t != 0:\n",
    "            val1 = max(PRETRAIN - self.nc_per_task, 0)\n",
    "            val2 = val1\n",
    "        else:\n",
    "            val1 = 0\n",
    "            val2 = max(PRETRAIN - self.nc_per_task, 0)                                                 \n",
    "        offset1 = int(t * self.nc_per_task + val1) #t = 0 0, 5 -----t = 1 5 , 6 ## t = 0 0 ,5 --- t =1 5, 7\n",
    "        offset2 = int((t + 1) * self.nc_per_task + val2) \n",
    "        if offset1 > 0:\n",
    "            output[:, :offset1].data.fill_(-10e10)\n",
    "        if offset2 < self.n_outputs:\n",
    "            output[:, offset2:self.n_outputs].data.fill_(-10e10)\n",
    "        return output\n",
    "\n",
    "    def observe(self, algorithm, x, t, y):\n",
    "        # update memory\n",
    "        if t != self.old_task:\n",
    "            self.observed_tasks.append(t)\n",
    "            self.old_task = t\n",
    "            \n",
    "        val = 0\n",
    "        if t == 0:\n",
    "            val = max(PRETRAIN,1)\n",
    "        else:\n",
    "            val = 1\n",
    "        # Update ring buffer storing examples from current task\n",
    "        bsz = y.data.size(0)\n",
    "        if (algorithm == 'NAIVE'):\n",
    "            self.zero_grad()\n",
    "            loss = self.ce(self.forward(x, t), y)\n",
    "            loss.backward()\n",
    "            self.opt.step()\n",
    "            return\n",
    "        endcnt = min(self.mem_cnt + bsz, self.n_memories) #256\n",
    "        effbsz = endcnt - self.mem_cnt # 256\n",
    "        self.memory_data[t, self.mem_cnt: endcnt].copy_(\n",
    "            x.data[: effbsz])\n",
    "        if bsz == 1:\n",
    "            self.memory_labs[t, self.mem_cnt] = y.data[0]\n",
    "        else:\n",
    "            self.memory_labs[t, self.mem_cnt: endcnt].copy_(\n",
    "                y.data[: effbsz])\n",
    "        self.mem_cnt += effbsz\n",
    "        if self.mem_cnt == self.n_memories:\n",
    "            self.mem_cnt = 0\n",
    "\n",
    "        # compute gradient on previous tasks\n",
    "        # if PRETRAIN == 0:\n",
    "        #     val = 1\n",
    "        # else:\n",
    "        #     val = 0\n",
    "        if len(self.observed_tasks) > 1: ### CHANGED FROM 1 to 0 SINCE WE PRETRAIN ON FST 5 CLASSES \n",
    "            for tt in range(len(self.observed_tasks) -1): ### CHANGED FROM -1 to -0 SINCE WE PRETRAIN ON FST 5 CLASSES \n",
    "                self.zero_grad()\n",
    "                # fwd/bwd on the examples in the memory\n",
    "                past_task = self.observed_tasks[tt]\n",
    "                \n",
    "                offset1, offset2 = compute_offsets(past_task, self.nc_per_task,\n",
    "                                                   self.is_cifar)\n",
    "                ptloss = self.ce(\n",
    "                    self.forward(\n",
    "                        self.memory_data[past_task],\n",
    "                        past_task)[:, offset1: offset2],\n",
    "                    self.memory_labs[past_task] - offset1)\n",
    "                ptloss.backward()\n",
    "                store_grad(self.parameters, self.grads, self.grad_dims,\n",
    "                           past_task)\n",
    "\n",
    "        # now compute the grad on the current minibatch\n",
    "        self.zero_grad()\n",
    "\n",
    "        offset1, offset2 = compute_offsets(t, self.nc_per_task, self.is_cifar) \n",
    "        loss = self.ce(self.forward(x, t)[:, offset1: offset2], y - offset1)\n",
    "        loss.backward()\n",
    "\n",
    "        # check if gradient violates constraints\n",
    "        if len(self.observed_tasks) > 1: ### CHANGED FROM 1 to 0 SINCE WE PRETRAIN ON FST 5 CLASSES \n",
    "            if algorithm == 'AGEM':\n",
    "                store_grad(self.parameters, self.grads, self.grad_dims, t)\n",
    "                indx = torch.cuda.LongTensor(self.observed_tasks[:-1]) if self.gpu \\\n",
    "                    else torch.LongTensor(self.observed_tasks[:-1])\n",
    "                dotp = torch.mm(self.grads[:, t].unsqueeze(0),\n",
    "                                self.grads.index_select(1, indx))\n",
    "                if (dotp < 0).sum() != 0:\n",
    "                    agemprojection(self.grads[:, t].unsqueeze(1), self.grads.index_select(1, indx), self.margin)\n",
    "                    # copy gradients back\n",
    "                    overwrite_grad(self.parameters, self.grads[:, t],\n",
    "                                self.grad_dims)\n",
    "            # copy gradient\n",
    "            elif algorithm == 'GEM':\n",
    "                store_grad(self.parameters, self.grads, self.grad_dims, t)\n",
    "                indx = torch.cuda.LongTensor(self.observed_tasks[:-1]) if self.gpu \\\n",
    "                    else torch.LongTensor(self.observed_tasks[:-1])\n",
    "                dotp = torch.mm(self.grads[:, t].unsqueeze(0),\n",
    "                                self.grads.index_select(1, indx))\n",
    "                if (dotp < 0).sum() != 0:\n",
    "                    project2cone2(self.grads[:, t].unsqueeze(1),\n",
    "                                self.grads.index_select(1, indx), self.margin)\n",
    "                    # copy gradients back\n",
    "                    overwrite_grad(self.parameters, self.grads[:, t],\n",
    "                                self.grad_dims)\n",
    "            elif algorithm == 'REPLAY':\n",
    "                store_grad(self.parameters, self.grads, self.grad_dims, t)\n",
    "                indx = torch.cuda.LongTensor(self.observed_tasks[:-1]) if self.gpu \\\n",
    "                    else torch.LongTensor(self.observed_tasks[:-1])\n",
    "                replay(self.grads[:, t].unsqueeze(1), self.grads.index_select(1, indx))\n",
    "                # copy gradients back\n",
    "                overwrite_grad(self.parameters, self.grads[:, t],\n",
    "                            self.grad_dims)\n",
    "        self.opt.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define main function to run on the cifar dataset\n",
    "N_TASKS = 20 #[2 tasks [airplane, automobile, etc], [dog , frog, etc]]\n",
    "SIZE_OF_TASKS = 5\n",
    "N_OUTPUTS = 100\n",
    "N_INPUTS = 32 * 32 * 3\n",
    "def run_cifar(algorithm, args, n_inputs=N_INPUTS, n_outputs=N_OUTPUTS, n_tasks=N_TASKS, size_of_task=SIZE_OF_TASKS, newclasses = SHUFFLEDCLASSES):\n",
    "    # Set up the model\n",
    "    model = Net(n_inputs, n_outputs, n_tasks, args)\n",
    "    if args.cuda:\n",
    "        model.cuda()\n",
    "    model.is_cifar = True\n",
    "    test_bs = 2500\n",
    "    \n",
    "    test_accuracies = []\n",
    "\n",
    "    # Load data\n",
    "    train_data, train_labels, test_data, test_labels = load_data(DATASET_PATH, DATASET)\n",
    "    ## NEWCLASSES = suffled CLASSES\n",
    "    NEWCLASSES = newclasses\n",
    "    print(\"new ordering of classes: \", NEWCLASSES)\n",
    "    oldClasstoNewClass = {}\n",
    "    for i in range(len(CLASSES)):\n",
    "        oldClasstoNewClass[i] = NEWCLASSES.index(CLASSES[i])\n",
    "    for i in range(len(train_labels)):\n",
    "        train_labels[i] = oldClasstoNewClass[train_labels[i]]\n",
    "    for i in range(len(test_labels)):\n",
    "        test_labels[i] = oldClasstoNewClass[test_labels[i]]\n",
    "\n",
    "    pretrain_classses = NEWCLASSES[:PRETRAIN]\n",
    "    pretrain_data, pretrain_labels = split_into_classes(train_data, train_labels, pretrain_classses, NEWCLASSES)\n",
    "    pretest_data, pretest_labels = split_into_classes(test_data, test_labels, pretrain_classses, NEWCLASSES)\n",
    "    tasks = []\n",
    "    tests = []\n",
    "    if PRETRAIN > 0:\n",
    "        tasks = [[pretrain_data, pretrain_labels]]\n",
    "        tests = [pretest_data, pretest_labels]\n",
    "    else:\n",
    "\n",
    "        tasks = []\n",
    "        tests = []\n",
    "    for i in range(n_tasks):\n",
    "        if i == 0 and PRETRAIN > 0: ## as task 1 we already grab from \n",
    "            continue\n",
    "        elif PRETRAIN > 0:\n",
    "            task_data, task_labels = split_into_classes(train_data, train_labels, NEWCLASSES[PRETRAIN + size_of_task * (i-1) : PRETRAIN + size_of_task * (i)], NEWCLASSES)\n",
    "            tasks.append([task_data, task_labels])\n",
    "            partition_test_data, partition_test_labels = split_into_classes(test_data, test_labels, NEWCLASSES[PRETRAIN + size_of_task * (i-1) : PRETRAIN + size_of_task * (i)], NEWCLASSES)\n",
    "            tests.append(partition_test_data)\n",
    "            tests.append(partition_test_labels)\n",
    "        else:\n",
    "            task_data, task_labels = split_into_classes(train_data, train_labels, NEWCLASSES[size_of_task * i : size_of_task * (i + 1)] , NEWCLASSES)\n",
    "            tasks.append([task_data, task_labels])\n",
    "            partition_test_data, partition_test_labels = split_into_classes(test_data, test_labels, NEWCLASSES[size_of_task * i : size_of_task * (i + 1)] , NEWCLASSES)\n",
    "            tests.append(partition_test_data)\n",
    "            tests.append(partition_test_labels)\n",
    "        \n",
    "    # task1data, task1labels = split_into_classes(train_data, train_labels, ['airplane', 'automobile', 'bird', 'cat', 'deer']) ## pre train on this \n",
    "    # task2data, task2labels = split_into_classes(train_data, train_labels, ['dog', 'frog', 'horse', 'ship', 'truck']) ## split this guy up into 5 tasks \n",
    "    # # tasks = [[task1data, task1labels], [task2data,task2labels]]\n",
    "    # test_data_per_class_1, test_labels_per_class_1 = split_into_classes(test_data, test_labels, ['airplane', 'automobile', 'bird', 'cat', 'deer'])\n",
    "    # test_data_per_class_2, test_labels_per_class_2 = split_into_classes(test_data, test_labels, ['dog', 'frog', 'horse', 'ship', 'truck'])\n",
    "\n",
    "    # Train the model\n",
    "    for task in range(n_tasks):\n",
    "        print(\"Training task: \", task  + 1)\n",
    "        \n",
    "        x = torch.Tensor(tasks[task][0].reshape(-1, 32*32*3)).float()\n",
    "        y = torch.Tensor(tasks[task][1]).long()\n",
    "        \n",
    "        if args.cuda:\n",
    "            x, y = x.cuda(), y.cuda()\n",
    "    \n",
    "        for epoch in range(args.n_epochs):\n",
    "            for j in range(0, len(tasks[task][0]), args.batch_size):\n",
    "                current_data = x[j: j + args.batch_size]\n",
    "                current_labels = y[j: j + args.batch_size]\n",
    "                model.train()\n",
    "                model.observe(algorithm, current_data, task, current_labels)\n",
    "            #print(\"Epoch: \", epoch)\n",
    "            \n",
    "            #test the model after each epoch\n",
    "            correct = 0\n",
    "            total = len(tasks[task][0])\n",
    "            for j in range(0,len(tasks[task][0]), test_bs):\n",
    "                current_data = x[j: j + test_bs]\n",
    "                current_labels = y[j: j + test_bs]\n",
    "                output = model.forward(current_data, task)\n",
    "                pred = output.data.max(1)[1]\n",
    "                correct += (pred == current_labels).sum().item()\n",
    "            #print(\"Accuracy: \", correct / total)\n",
    "            # if correct / total > 0.85:\n",
    "            #     break\n",
    "            #   output loss only\n",
    "\n",
    "\n",
    "    # Test the model after training\n",
    "        for i in range(0, len(tests), 2):\n",
    "            correct = 0\n",
    "            total = len(tests[i])     \n",
    "\n",
    "            # Test the model\n",
    "            #print(\"Testing task: \" , i // 2 + 1)\n",
    "            \n",
    "            x = torch.Tensor(tests[i].reshape(-1, 32*32*3)).float()\n",
    "            y = torch.Tensor(tests[i+1]).long()\n",
    "            if args.cuda:\n",
    "                x, y = x.cuda(), y.cuda()\n",
    "            for j in range(0,len(tests[i]), test_bs):\n",
    "                current_data = x[j: j + test_bs]\n",
    "                current_labels = y[j: j + test_bs]\n",
    "                output = model.forward(current_data, i // 2)\n",
    "                pred = output.data.max(1)[1]\n",
    "                correct += (pred == current_labels).sum().item()\n",
    "            #print(\"Accuracy: \", correct / total)\n",
    "            test_accuracies.append(correct / total)\n",
    "            \n",
    "       \n",
    "    return model, test_accuracies\n",
    "\n",
    "        \n",
    "# model, test_accuracies = run_cifar(Args())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_next_task(args, model, tasknum, n_inputs=N_INPUTS, n_outputs=N_OUTPUTS, n_tasks=N_TASKS, size_of_task=SIZE_OF_TASKS, newclasses = SHUFFLEDCLASSES):\n",
    "    \n",
    "    test_accuracies = []\n",
    "    test_bs = 2500\n",
    "    # Load data\n",
    "    train_data, train_labels, test_data, test_labels = load_data(DATASET_PATH)\n",
    "    ## NEWCLASSES = suffled CLASSES\n",
    "    NEWCLASSES = newclasses\n",
    "    print(\"new ordering of classes: \", NEWCLASSES)\n",
    "    oldClasstoNewClass = {}\n",
    "    for i in range(len(CLASSES)):\n",
    "        oldClasstoNewClass[i] = NEWCLASSES.index(CLASSES[i])\n",
    "    for i in range(len(train_labels)):\n",
    "        train_labels[i] = oldClasstoNewClass[train_labels[i]]\n",
    "    for i in range(len(test_labels)):\n",
    "        test_labels[i] = oldClasstoNewClass[test_labels[i]]\n",
    "\n",
    "    pretrain_classses = NEWCLASSES[:PRETRAIN]\n",
    "    pretrain_data, pretrain_labels = split_into_classes(train_data, train_labels, pretrain_classses, NEWCLASSES)\n",
    "    pretest_data, pretest_labels = split_into_classes(test_data, test_labels, pretrain_classses, NEWCLASSES)\n",
    "    tasks = []\n",
    "    tests = []\n",
    "    if PRETRAIN > 0:\n",
    "        tasks = [[pretrain_data, pretrain_labels]]\n",
    "        tests = [pretest_data, pretest_labels]\n",
    "    else:\n",
    "\n",
    "        tasks = []\n",
    "        tests = []\n",
    "    for i in range(n_tasks):\n",
    "        if i == 0 and PRETRAIN > 0: ## as task 1 we already grab from \n",
    "            continue\n",
    "        elif PRETRAIN > 0:\n",
    "            task_data, task_labels = split_into_classes(train_data, train_labels, NEWCLASSES[PRETRAIN + size_of_task * (i-1) : PRETRAIN + size_of_task * (i)], NEWCLASSES)\n",
    "            tasks.append([task_data, task_labels])\n",
    "            partition_test_data, partition_test_labels = split_into_classes(test_data, test_labels, NEWCLASSES[PRETRAIN + size_of_task * (i-1) : PRETRAIN + size_of_task * (i)], NEWCLASSES)\n",
    "            tests.append(partition_test_data)\n",
    "            tests.append(partition_test_labels)\n",
    "        else:\n",
    "            task_data, task_labels = split_into_classes(train_data, train_labels, NEWCLASSES[size_of_task * i : size_of_task * (i + 1)] , NEWCLASSES)\n",
    "            tasks.append([task_data, task_labels])\n",
    "            partition_test_data, partition_test_labels = split_into_classes(test_data, test_labels, NEWCLASSES[size_of_task * i : size_of_task * (i + 1)] , NEWCLASSES)\n",
    "            tests.append(partition_test_data)\n",
    "            tests.append(partition_test_labels)\n",
    "        \n",
    "\n",
    "    # Train the model\n",
    "    task = tasknum - 1\n",
    "    print(\"Training task: \", task  + 1)\n",
    "    \n",
    "    x = torch.Tensor(tasks[task][0].reshape(-1, 32*32*3)).float()\n",
    "    y = torch.Tensor(tasks[task][1]).long()\n",
    "    \n",
    "    if args.cuda:\n",
    "        x, y = x.cuda(), y.cuda()\n",
    "\n",
    "    for epoch in range(args.n_epochs):\n",
    "        for j in range(0, len(tasks[task][0]), args.batch_size):\n",
    "            current_data = x[j: j + args.batch_size]\n",
    "            current_labels = y[j: j + args.batch_size]\n",
    "            model.train()\n",
    "            model.observe(current_data, task, current_labels)\n",
    "        #print(\"Epoch: \", epoch)\n",
    "        \n",
    "        #test the model after each epoch\n",
    "        correct = 0\n",
    "        total = len(tasks[task][0])\n",
    "        for j in range(0,len(tasks[task][0]), test_bs):\n",
    "            current_data = x[j: j + test_bs]\n",
    "            current_labels = y[j: j + test_bs]\n",
    "            output = model.forward(current_data, task)\n",
    "            pred = output.data.max(1)[1]\n",
    "            correct += (pred == current_labels).sum().item()\n",
    "        #print(\"Accuracy: \", correct / total)\n",
    "        if correct / total > 0.65:\n",
    "            break\n",
    "        #   output loss only\n",
    "\n",
    "\n",
    "# Test the model after training\n",
    "    for i in range(0, len(tests), 2):\n",
    "        correct = 0\n",
    "        total = len(tests[i])     \n",
    "\n",
    "        # Test the model\n",
    "        #print(\"Testing task: \" , i // 2 + 1)\n",
    "        \n",
    "        x = torch.Tensor(tests[i].reshape(-1, 32*32*3)).float()\n",
    "        y = torch.Tensor(tests[i+1]).long()\n",
    "        if args.cuda:\n",
    "            x, y = x.cuda(), y.cuda()\n",
    "        for j in range(0,len(tests[i]), test_bs):\n",
    "            current_data = x[j: j + test_bs]\n",
    "            current_labels = y[j: j + test_bs]\n",
    "            output = model.forward(current_data, i // 2)\n",
    "            pred = output.data.max(1)[1]\n",
    "            correct += (pred == current_labels).sum().item()\n",
    "        #print(\"Accuracy: \", correct / total)\n",
    "        test_accuracies.append(correct / total)\n",
    "            \n",
    "        \n",
    "    return model, test_accuracies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_task_accuracies(test_accuracies, num_tasks):\n",
    "    for t in range(num_tasks):\n",
    "        # Calculate the indices for the current set of accuracies\n",
    "        start_idx = t * num_tasks\n",
    "        end_idx = start_idx + num_tasks\n",
    "        # Extract accuracies for all tasks after training task t+1\n",
    "        print (test_accuracies)\n",
    "        accuracies = test_accuracies[start_idx:end_idx]\n",
    "        # Create labels for the tasks\n",
    "        task_labels = [f'{i+1}' for i in range(num_tasks)]\n",
    "        # Plot the accuracies\n",
    "        plt.bar(task_labels, [acc * 100 for acc in accuracies])\n",
    "\n",
    "        # Calculate the y-value for the horizontal line\n",
    "        y_value = 100 / SIZE_OF_TASKS  # or use SIZE_OF_TASKS if it's defined separately\n",
    "\n",
    "        # Add horizontal line across the bar chart\n",
    "        plt.axhline(y=y_value, color='red', linestyle='--', label=f'y = {y_value:.2f}')\n",
    "        \n",
    "        plt.title(f'Test Set Accuracy for All Tasks (Post Task {t+1} Training)')\n",
    "        plt.ylabel('Accuracy (%)')\n",
    "        plt.xlabel('Task')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "def plot_comparison_accuracies(accuracies_list, num_tasks, num_models, model_names):\n",
    "    bar_width = 0.2\n",
    "    index = np.arange(num_tasks)\n",
    "    \n",
    "    for i, accuracies in enumerate(accuracies_list):\n",
    "        start_idx = (num_tasks-1) * num_tasks\n",
    "        end_idx = start_idx + num_tasks\n",
    "        plt.bar(index + i * bar_width, [acc * 100 for acc in accuracies[start_idx:end_idx]], bar_width, label=model_names[i])\n",
    "    \n",
    "    plt.xlabel('Tasks')\n",
    "    plt.ylabel('Accuracy (%)')\n",
    "    plt.title('Comparison of Test Set Accuracies for All Models')\n",
    "    plt.xticks(index + bar_width * (num_models - 1) / 2, [f'{i+1}' for i in range(num_tasks)])\n",
    "    plt.legend()\n",
    "    plt.savefig('comparison_accuracies.png')\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "# Example usage:\n",
    "# plot_comparison_accuracies([average_AGEM_accuracies, average_GEM_accuracies, average_REPLAY_accuracies, average_NAIVE_accuracies], N_TASKS, 4, ['AGEM', 'GEM', 'REPLAY', 'NAIVE'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_classes(classes, dataset):\n",
    "    if dataset == 'cifar-10':\n",
    "        return random.shuffle(classes)\n",
    "    elif dataset == 'cifar-100':\n",
    "        shuffled_classes = []\n",
    "        partitions = [classes[i:i + SIZE_OF_TASKS] for i in range(0, len(classes), SIZE_OF_TASKS)]\n",
    "        random.shuffle(partitions)\n",
    "        for partition in partitions:\n",
    "            shuffled_classes.extend(partition)\n",
    "        return shuffled_classes\n",
    "    else:\n",
    "        return classes  # No shuffling for other datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 1\n",
      "new ordering of classes:  ['baby', 'cloud', 'dolphin', 'beaver', 'clock', 'crab', 'plates', 'kangaroo', 'snail', 'couch', 'apples', 'ray', 'bottles', 'sweet peppers', 'castle', 'telephone', 'snake', 'cattle', 'lobster', 'caterpillar', 'wardrobe', 'roses', 'orchids', 'beetle', 'camel', 'seal', 'bowls', 'spider', 'pickup truck', 'chimpanzee', 'bed', 'fox', 'skyscraper', 'squirrel', 'table', 'chair', 'bicycle', 'oak', 'tractor', 'tank', 'worm', 'tiger', 'raccoon', 'forest', 'maple', 'porcupine', 'television', 'road', 'whale', 'lawn-mower', 'hamster', 'plain', 'otter', 'girl', 'shrew', 'lamp', 'sea', 'poppies', 'mountain', 'train', 'leopard', 'rabbit', 'bridge', 'mouse', 'bus', 'rocket', 'mushrooms', 'cans', 'palm', 'elephant', 'skunk', 'aquarium fish', 'butterfly', 'cups', 'woman', 'streetcar', 'flatfish', 'trout', 'crocodile', 'tulips', 'lizard', 'dinosaur', 'bear', 'lion', 'pine', 'oranges', 'motorcycle', 'man', 'sunflowers', 'house', 'wolf', 'computer keyboard', 'shark', 'cockroach', 'willow', 'turtle', 'boy', 'pears', 'bee', 'possum']\n",
      "Training task:  1\n",
      "Training task:  2\n",
      "Training task:  3\n",
      "Training task:  4\n",
      "Training task:  5\n",
      "Training task:  6\n"
     ]
    }
   ],
   "source": [
    "\n",
    "max_runs = 1\n",
    "test_accuracies_AGEM_all = []\n",
    "test_accuracies_GEM_all = []\n",
    "test_accuracies_REPLAY_all = []\n",
    "test_accuracies_NAIVE_all = []\n",
    "\n",
    "for i in range(max_runs):\n",
    "    print(f\"Run {i+1}\")\n",
    "    random.shuffle(SHUFFLEDCLASSES)\n",
    "\n",
    "    model, test_accuracies_AGEM = run_cifar('AGEM', Args())\n",
    "    print(test_accuracies_AGEM)\n",
    "    test_accuracies_AGEM_all.append(test_accuracies_AGEM)\n",
    "\n",
    "    model, test_accuracies_GEM = run_cifar('GEM', Args())\n",
    "    print(test_accuracies_GEM)\n",
    "    test_accuracies_GEM_all.append(test_accuracies_GEM)\n",
    "    \n",
    "    model, test_accuracies_REPLAY = run_cifar('REPLAY', Args())\n",
    "    print(test_accuracies_REPLAY)\n",
    "    test_accuracies_REPLAY_all.append(test_accuracies_REPLAY)\n",
    "    \n",
    "    model, test_accuracies_NAIVE = run_cifar('NAIVE', Args())\n",
    "    print(test_accuracies_NAIVE)\n",
    "    test_accuracies_NAIVE_all.append(test_accuracies_NAIVE)\n",
    "    \n",
    "average_AGEM_accuracies = np.mean(test_accuracies_AGEM_all, axis=0)\n",
    "average_GEM_accuracies = np.mean(test_accuracies_GEM_all, axis=0)\n",
    "average_REPLAY_accuracies = np.mean(test_accuracies_REPLAY_all, axis=0)\n",
    "average_NAIVE_accuracies = np.mean(test_accuracies_NAIVE_all, axis=0)\n",
    "\n",
    "task_1_accuracies_AGEM = []\n",
    "task_1_accuracies_GEM = []\n",
    "task_1_accuracies_REPLAY = []\n",
    "task_1_accuracies_NAIVE = []\n",
    "task_1_accuracies_AGEM.append(0.5)\n",
    "task_1_accuracies_GEM.append(0.5)\n",
    "task_1_accuracies_REPLAY.append(0.5)\n",
    "task_1_accuracies_NAIVE.append(0.5)\n",
    "\n",
    "for i in range(0, N_TASKS * N_TASKS, N_TASKS):\n",
    "    task_1_accuracies_GEM.append(average_GEM_accuracies[i])\n",
    "    task_1_accuracies_AGEM.append(average_AGEM_accuracies[i])\n",
    "    task_1_accuracies_REPLAY.append(average_REPLAY_accuracies[i])\n",
    "    task_1_accuracies_NAIVE.append(average_NAIVE_accuracies[i])\n",
    "\n",
    "plt.plot(task_1_accuracies_AGEM, label='AGEM')\n",
    "plt.plot(task_1_accuracies_GEM, label='GEM')\n",
    "plt.plot(task_1_accuracies_REPLAY, label='REPLAY')\n",
    "plt.plot(task_1_accuracies_NAIVE, label='NAIVE')\n",
    "plt.title('Task 1 Test Set Accuracy Comparison')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.xlabel('Tasks')\n",
    "plt.legend()\n",
    "plt.savefig('task_1_accuracy_comparison.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_task_accuracies(average_AGEM_accuracies, N_TASKS)\n",
    "#plot_task_accuracies(average_GEM_accuracies, N_TASKS)\n",
    "#plot_task_accuracies(average_REPLAY_accuracies, N_TASKS)\n",
    "#plot_task_accuracies(average_NAIVE_accuracies, N_TASKS)\n",
    "\n",
    "#plot_last_task_accuracies(average_AGEM_accuracies, N_TASKS)\n",
    "plot_comparison_accuracies([average_AGEM_accuracies, average_GEM_accuracies, average_REPLAY_accuracies, average_NAIVE_accuracies], N_TASKS, 4, ['AGEM', 'GEM', 'REPLAY', 'NAIVE'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "\n",
    "save_path = '/dcs/large/u2145461/cs407/Machine-Unlearning-x-Continual-Learning/GEM/Results/'\n",
    "\n",
    "def save_accuracies_to_file(name_of_file, accuracies):\n",
    "    completeName = os.path.join(save_path, name_of_file+\".csv\")\n",
    "    file1 = open(completeName, \"w\")\n",
    "    for item in accuracies:\n",
    "        file1.write(\"%s\\n\" % item)\n",
    "    file1.close()\n",
    "    \n",
    "save_accuracies_to_file('task_1_accuracies_AGEM', task_1_accuracies_AGEM)\n",
    "save_accuracies_to_file('task_1_accuracies_GEM', task_1_accuracies_GEM)\n",
    "save_accuracies_to_file('task_1_accuracies_REPLAY', task_1_accuracies_REPLAY)\n",
    "save_accuracies_to_file('task_1_accuracies_NAIVE', task_1_accuracies_NAIVE)\n",
    "\n",
    "save_accuracies_to_file('average_AGEM_accuracies', average_AGEM_accuracies)\n",
    "save_accuracies_to_file('average_GEM_accuracies', average_GEM_accuracies)\n",
    "save_accuracies_to_file('average_REPLAY_accuracies', average_REPLAY_accuracies)\n",
    "save_accuracies_to_file('average_NAIVE_accuracies', average_NAIVE_accuracies)\n",
    "\n",
    "save_accuracies_to_file('all_accuracies_AGEM', test_accuracies_AGEM_all)\n",
    "save_accuracies_to_file('all_accuracies_GEM', test_accuracies_GEM_all)\n",
    "save_accuracies_to_file('all_accuracies_REPLAY', test_accuracies_REPLAY_all)\n",
    "save_accuracies_to_file('all_accuracies_NAIVE', test_accuracies_NAIVE_all)\n",
    "       \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
