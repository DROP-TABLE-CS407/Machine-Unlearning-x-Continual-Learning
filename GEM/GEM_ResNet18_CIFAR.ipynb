{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Episodic Memory for Continual Learning\n",
    "\n",
    "We adapt the GEM algorithm to train the ResNet18 model on the CIFAR-10 Dataset. The GEM algorithm is a continual learning algorithm that prevents catastrophic forgetting by constraining the gradient updates on the new task to be orthogonal to the gradients of the previous tasks. The algorithm is implemented in PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import time\n",
    "from cifar import load_cifar10_data, split_into_classes, get_class_indexes, load_data\n",
    "import cifar\n",
    "from torch.utils.data import DataLoader\n",
    "import random\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(\".\"))  # Adds the current directory\n",
    "# from GEM.gem import *\n",
    "from GEM.args import *\n",
    "from torch.nn.functional import relu, avg_pool2d\n",
    "import torch.nn as nn\n",
    "import quadprog\n",
    "\n",
    "AGEM = True\n",
    "PRETRAIN = 0 # number of initial classes to pretrain on\n",
    "# Globals \n",
    "DATASET = 'cifar-100'\n",
    "DATASET_PATH = 'cifar-100-python' \n",
    "CLASSES = cifar.CLASSES\n",
    "SHUFFLEDCLASSES = CLASSES.copy()\n",
    "CONFIDENCE_SAMPLES = 5\n",
    "if DATASET == 'cifar-10':\n",
    "    CLASSES = cifar.CLASSES\n",
    "    SHUFFLEDCLASSES = CLASSES.copy()\n",
    "elif DATASET == 'cifar-100':\n",
    "    CLASSES = cifar.CLASSES_100_UNORDERED\n",
    "    SHUFFLEDCLASSES = CLASSES.copy()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Scraped code fundamental for GEM this is the code required to create a resnet18 model from scratch \n",
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=1, bias=False)\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(in_planes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion * planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion * planes, kernel_size=1,\n",
    "                          stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion * planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = relu(out)\n",
    "        return out\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes, nf):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = nf\n",
    "        self.conv1 = conv3x3(3, nf * 1)\n",
    "        self.bn1 = nn.BatchNorm2d(nf * 1)\n",
    "        self.layer1 = self._make_layer(block, nf * 1, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, nf * 2, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, nf * 4, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, nf * 8, num_blocks[3], stride=2)\n",
    "        self.linear = nn.Linear(nf * 8 * block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1] * (num_blocks - 1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        bsz = x.size(0)\n",
    "        out = relu(self.bn1(self.conv1(x.view(bsz, 3, 32, 32))))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "def ResNet18(nclasses, nf=20):\n",
    "    return ResNet(BasicBlock, [2, 2, 2, 2], nclasses, nf)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Now lets make the GEM model --  we will scrape this from the GEM code\n",
    "def compute_offsets(task, nc_per_task, is_cifar):\n",
    "    \"\"\"\n",
    "        Compute offsets for cifar to determine which\n",
    "        outputs to select for a given task.\n",
    "    \"\"\"\n",
    "    val1 = max(PRETRAIN - nc_per_task, 0)\n",
    "    val2 = max(PRETRAIN - nc_per_task, 0)\n",
    "    if task == 0:\n",
    "        val1 = 0\n",
    "        val2 = max(PRETRAIN - nc_per_task, 0)\n",
    "    offset1 = task * nc_per_task + val1\n",
    "    offset2 = (task + 1) * nc_per_task + val2    \n",
    "    return offset1, offset2\n",
    "\n",
    "\n",
    "def store_grad(pp, grads, grad_dims, tid):\n",
    "    \"\"\"\n",
    "        This stores parameter gradients of past tasks.\n",
    "        pp: parameters\n",
    "        grads: gradients\n",
    "        grad_dims: list with number of parameters per layers\n",
    "        tid: task id\n",
    "    \"\"\"\n",
    "    # store the gradients\n",
    "    grads[:, tid].fill_(0.0)\n",
    "    cnt = 0\n",
    "    for param in pp():\n",
    "        if param.grad is not None:\n",
    "            beg = 0 if cnt == 0 else sum(grad_dims[:cnt])\n",
    "            en = sum(grad_dims[:cnt + 1])\n",
    "            grads[beg: en, tid].copy_(param.grad.data.view(-1))\n",
    "        cnt += 1\n",
    "\n",
    "\n",
    "def overwrite_grad(pp, newgrad, grad_dims):\n",
    "    \"\"\"\n",
    "        This is used to overwrite the gradients with a new gradient\n",
    "        vector, whenever violations occur.\n",
    "        pp: parameters\n",
    "        newgrad: corrected gradient\n",
    "        grad_dims: list storing number of parameters at each layer\n",
    "    \"\"\"\n",
    "    cnt = 0\n",
    "    for param in pp():\n",
    "        if param.grad is not None:\n",
    "            beg = 0 if cnt == 0 else sum(grad_dims[:cnt])\n",
    "            en = sum(grad_dims[:cnt + 1])\n",
    "            this_grad = newgrad[beg: en].contiguous().view(\n",
    "                param.grad.data.size())\n",
    "            param.grad.data.copy_(this_grad)\n",
    "        cnt += 1\n",
    "\n",
    "\n",
    "def project2cone2(gradient, memories, margin=0.5, eps=1e-3):\n",
    "    \"\"\"\n",
    "        Solves the GEM dual QP described in the paper given a proposed\n",
    "        gradient \"gradient\", and a memory of task gradients \"memories\".\n",
    "        Overwrites \"gradient\" with the final projected update.\n",
    "\n",
    "        input:  gradient, p-vector\n",
    "        input:  memories, (t * p)-vector\n",
    "        output: x, p-vector\n",
    "    \"\"\"\n",
    "    memories_np = memories.cpu().t().double().numpy()\n",
    "    gradient_np = gradient.cpu().contiguous().view(-1).double().numpy()\n",
    "    t = memories_np.shape[0]\n",
    "    P = np.dot(memories_np, memories_np.transpose())\n",
    "    P = 0.5 * (P + P.transpose()) + np.eye(t) * eps\n",
    "    q = np.dot(memories_np, gradient_np) * -1\n",
    "    G = np.eye(t)\n",
    "    h = np.zeros(t) + margin\n",
    "    v = quadprog.solve_qp(P, q, G, h)[0]\n",
    "    x = np.dot(v, memories_np) + gradient_np\n",
    "    gradient.copy_(torch.Tensor(x).view(-1, 1))\n",
    "    #penis\n",
    "def agemprojection(gradient, gradient_memory, margin=0.5, eps=1e-5):\n",
    "    \"\"\"\n",
    "    Projection of gradients for A-GEM with the memory approach\n",
    "    Use averaged gradient memory for projection\n",
    "    \n",
    "    input:  gradient, g-reference\n",
    "    output: gradient, g-projected\n",
    "    \"\"\"\n",
    "\n",
    "    g = gradient_memory.t().double().mean(axis=0).cuda() # * margin\n",
    "    gref = gradient.contiguous().view(-1).double().cuda()\n",
    "    g_transpose = g.view(1, -1)\n",
    "    dot_prod = torch.dot(g_transpose.squeeze(), gref.squeeze())\n",
    "    dot_prod = dot_prod / torch.dot(g_transpose.squeeze(), g.squeeze())\n",
    "    \n",
    "    # add epsilon to prevent 0 values from fucking everything up  \n",
    "    epsvector = torch.Tensor([eps]).cuda()\n",
    "    \n",
    "    x = g + (gref * abs(dot_prod)) + epsvector\n",
    "    gradient.copy_(torch.Tensor(x).view(-1, 1))\n",
    "    \n",
    "def replay(gradient, gradient_memory):\n",
    "    \"\"\"\n",
    "    Adds the gradients of the current task to the memory \n",
    "    \n",
    "    input:  gradient, g-reference\n",
    "    output: gradient, g-projected\n",
    "    \"\"\"\n",
    "    g = gradient_memory.t().double().mean(axis=0).cuda()\n",
    "    gref = gradient.contiguous().view(-1).double().cuda()\n",
    "    # simply add the gradients\n",
    "    g = g + gref\n",
    "    gradient.copy_(torch.Tensor(g).view(-1, 1))\n",
    "    \n",
    "def naiveretraining(gradient):\n",
    "    \"\"\"\n",
    "    Naive retraining of the model on the current task\n",
    "    \n",
    "    input:  gradient, g-reference\n",
    "    output: gradient, g-projected\n",
    "    \"\"\"\n",
    "    g = gradient.t().double().mean(axis=0).cuda()\n",
    "    gradient.copy_(torch.Tensor(g).view(-1, 1))\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self,\n",
    "                 n_inputs,\n",
    "                 n_outputs,\n",
    "                 n_tasks,\n",
    "                 args):\n",
    "        super(Net, self).__init__()\n",
    "        nl, nh = args.n_layers, args.n_hiddens\n",
    "        self.margin = args.memory_strength\n",
    "        self.net = ResNet18(n_outputs)\n",
    "     \n",
    "\n",
    "        self.ce = nn.CrossEntropyLoss()\n",
    "        self.n_outputs = n_outputs\n",
    "\n",
    "        self.opt = torch.optim.SGD(self.parameters(), args.lr)\n",
    "\n",
    "        self.n_memories = args.n_memories\n",
    "        self.gpu = args.cuda\n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "        Allocate episodic memory\n",
    "        n_tasks: number of tasks\n",
    "        n_memories: number of memories per task\n",
    "        n_inputs: number of input features\n",
    "        \"\"\"\n",
    "\n",
    "        # allocate episodic memory\n",
    "        self.memory_data = torch.FloatTensor(\n",
    "            n_tasks, self.n_memories, n_inputs)\n",
    "        self.memory_labs = torch.LongTensor(n_tasks, self.n_memories)\n",
    "        if args.cuda:\n",
    "            self.memory_data = self.memory_data.cuda()\n",
    "            self.memory_labs = self.memory_labs.cuda()\n",
    "\n",
    "        # allocate temporary synaptic memory\n",
    "        \"\"\" This is the memory that stores the gradients of the parameters of the network\n",
    "            FOR each task. This is used to check for violations of the GEM constraint\n",
    "            Assume:\n",
    "\n",
    "            The model has 3 parameters with sizes 100, 200, and 300 elements respectively.\n",
    "            n_tasks = 5 (number of tasks).\n",
    "            The allocated tensors would have the following shapes:\n",
    "\n",
    "            self.grad_dims: [100, 200, 300]\n",
    "            self.grads: Shape [600, 5] (600 is the sum of 100, 200, and 300).\n",
    "        \"\"\"\n",
    "        self.grad_dims = []\n",
    "        for param in self.parameters():\n",
    "            self.grad_dims.append(param.data.numel())\n",
    "        self.grads = torch.Tensor(sum(self.grad_dims), n_tasks)\n",
    "        if args.cuda:\n",
    "            self.grads = self.grads.cuda()\n",
    "\n",
    "        # allocate counters\n",
    "        self.observed_tasks = []\n",
    "        self.old_task = -1\n",
    "        self.mem_cnt = 0\n",
    "        minus = 0\n",
    "        if PRETRAIN > 0:\n",
    "            minus = 1\n",
    "        else: \n",
    "            minus = 0\n",
    "        self.nc_per_task = int((n_outputs - PRETRAIN) / (n_tasks - minus))\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        output = self.net(x)\n",
    "        if t == -1:\n",
    "            return output\n",
    "        # make sure we predict classes within the current task\n",
    "        val1 = 0\n",
    "        val2 = 0\n",
    "        if t != 0:\n",
    "            val1 = max(PRETRAIN - self.nc_per_task, 0)\n",
    "            val2 = val1\n",
    "        else:\n",
    "            val1 = 0\n",
    "            val2 = max(PRETRAIN - self.nc_per_task, 0)                                                 \n",
    "        offset1 = int(t * self.nc_per_task + val1) #t = 0 0, 5 -----t = 1 5 , 6 ## t = 0 0 ,5 --- t =1 5, 7\n",
    "        offset2 = int((t + 1) * self.nc_per_task + val2) \n",
    "        if offset1 > 0:\n",
    "            output[:, :offset1].data.fill_(-10e10)\n",
    "        if offset2 < self.n_outputs:\n",
    "            output[:, offset2:self.n_outputs].data.fill_(-10e10)\n",
    "        return output\n",
    "\n",
    "    def observe(self, algorithm, x, t, y):\n",
    "        # update memory\n",
    "        if t != self.old_task:\n",
    "            self.observed_tasks.append(t)\n",
    "            self.old_task = t\n",
    "            \n",
    "        val = 0\n",
    "        if t == 0:\n",
    "            val = max(PRETRAIN,1)\n",
    "        else:\n",
    "            val = 1\n",
    "        # Update ring buffer storing examples from current task\n",
    "        bsz = y.data.size(0)\n",
    "        if (algorithm == 'NAIVE'):\n",
    "            self.zero_grad()\n",
    "            loss = self.ce(self.forward(x, t), y)\n",
    "            loss.backward()\n",
    "            self.opt.step()\n",
    "            return\n",
    "        endcnt = min(self.mem_cnt + bsz, self.n_memories) #256\n",
    "        effbsz = endcnt - self.mem_cnt # 256\n",
    "        self.memory_data[t, self.mem_cnt: endcnt].copy_(\n",
    "            x.data[: effbsz])\n",
    "        if bsz == 1:\n",
    "            self.memory_labs[t, self.mem_cnt] = y.data[0]\n",
    "        else:\n",
    "            self.memory_labs[t, self.mem_cnt: endcnt].copy_(\n",
    "                y.data[: effbsz])\n",
    "        self.mem_cnt += effbsz\n",
    "        if self.mem_cnt == self.n_memories:\n",
    "            self.mem_cnt = 0\n",
    "\n",
    "        # compute gradient on previous tasks\n",
    "        # if PRETRAIN == 0:\n",
    "        #     val = 1\n",
    "        # else:\n",
    "        #     val = 0\n",
    "        if len(self.observed_tasks) > 1: ### CHANGED FROM 1 to 0 SINCE WE PRETRAIN ON FST 5 CLASSES \n",
    "            for tt in range(len(self.observed_tasks) -1): ### CHANGED FROM -1 to -0 SINCE WE PRETRAIN ON FST 5 CLASSES \n",
    "                self.zero_grad()\n",
    "                # fwd/bwd on the examples in the memory\n",
    "                past_task = self.observed_tasks[tt]\n",
    "                \n",
    "                offset1, offset2 = compute_offsets(past_task, self.nc_per_task,\n",
    "                                                   self.is_cifar)\n",
    "                ptloss = self.ce(\n",
    "                    self.forward(\n",
    "                        self.memory_data[past_task],\n",
    "                        past_task)[:, offset1: offset2],\n",
    "                    self.memory_labs[past_task] - offset1)\n",
    "                ptloss.backward()\n",
    "                store_grad(self.parameters, self.grads, self.grad_dims,\n",
    "                           past_task)\n",
    "\n",
    "        # now compute the grad on the current minibatch\n",
    "        self.zero_grad()\n",
    "\n",
    "        offset1, offset2 = compute_offsets(t, self.nc_per_task, self.is_cifar) \n",
    "        loss = self.ce(self.forward(x, t)[:, offset1: offset2], y - offset1)\n",
    "        loss.backward()\n",
    "\n",
    "        # check if gradient violates constraints\n",
    "        if len(self.observed_tasks) > 1: ### CHANGED FROM 1 to 0 SINCE WE PRETRAIN ON FST 5 CLASSES \n",
    "            if algorithm == 'AGEM':\n",
    "                store_grad(self.parameters, self.grads, self.grad_dims, t)\n",
    "                indx = torch.cuda.LongTensor(self.observed_tasks[:-1]) if self.gpu \\\n",
    "                    else torch.LongTensor(self.observed_tasks[:-1])\n",
    "                dotp = torch.mm(self.grads[:, t].unsqueeze(0),\n",
    "                                self.grads.index_select(1, indx))\n",
    "                if (dotp < 0).sum() != 0:\n",
    "                    agemprojection(self.grads[:, t].unsqueeze(1), self.grads.index_select(1, indx), self.margin)\n",
    "                    # copy gradients back\n",
    "                    overwrite_grad(self.parameters, self.grads[:, t],\n",
    "                                self.grad_dims)\n",
    "            # copy gradient\n",
    "            elif algorithm == 'GEM':\n",
    "                store_grad(self.parameters, self.grads, self.grad_dims, t)\n",
    "                indx = torch.cuda.LongTensor(self.observed_tasks[:-1]) if self.gpu \\\n",
    "                    else torch.LongTensor(self.observed_tasks[:-1])\n",
    "                dotp = torch.mm(self.grads[:, t].unsqueeze(0),\n",
    "                                self.grads.index_select(1, indx))\n",
    "                if (dotp < 0).sum() != 0:\n",
    "                    project2cone2(self.grads[:, t].unsqueeze(1),\n",
    "                                self.grads.index_select(1, indx), self.margin)\n",
    "                    # copy gradients back\n",
    "                    overwrite_grad(self.parameters, self.grads[:, t],\n",
    "                                self.grad_dims)\n",
    "            elif algorithm == 'REPLAY':\n",
    "                store_grad(self.parameters, self.grads, self.grad_dims, t)\n",
    "                indx = torch.cuda.LongTensor(self.observed_tasks[:-1]) if self.gpu \\\n",
    "                    else torch.LongTensor(self.observed_tasks[:-1])\n",
    "                replay(self.grads[:, t].unsqueeze(1), self.grads.index_select(1, indx))\n",
    "                # copy gradients back\n",
    "                overwrite_grad(self.parameters, self.grads[:, t],\n",
    "                            self.grad_dims)\n",
    "        self.opt.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define main function to run on the cifar dataset\n",
    "N_TASKS = 20 #[2 tasks [airplane, automobile, etc], [dog , frog, etc]]\n",
    "SIZE_OF_TASKS = 5\n",
    "N_OUTPUTS = 100\n",
    "N_INPUTS = 32 * 32 * 3\n",
    "def run_cifar(algorithm, args, n_inputs=N_INPUTS, n_outputs=N_OUTPUTS, n_tasks=N_TASKS, size_of_task=SIZE_OF_TASKS, newclasses = SHUFFLEDCLASSES):\n",
    "    # Set up the model\n",
    "    model = Net(n_inputs, n_outputs, n_tasks, args)\n",
    "    if args.cuda:\n",
    "        model.cuda()\n",
    "    model.is_cifar = True\n",
    "    test_bs = 2500\n",
    "    \n",
    "    test_accuracies = []\n",
    "\n",
    "    # Load data\n",
    "    train_data, train_labels, test_data, test_labels = load_data(DATASET_PATH, DATASET)\n",
    "    ## NEWCLASSES = suffled CLASSES\n",
    "    NEWCLASSES = newclasses\n",
    "    print(\"new ordering of classes: \", NEWCLASSES)\n",
    "    oldClasstoNewClass = {}\n",
    "    for i in range(len(CLASSES)):\n",
    "        oldClasstoNewClass[i] = NEWCLASSES.index(CLASSES[i])\n",
    "    for i in range(len(train_labels)):\n",
    "        train_labels[i] = oldClasstoNewClass[train_labels[i]]\n",
    "    for i in range(len(test_labels)):\n",
    "        test_labels[i] = oldClasstoNewClass[test_labels[i]]\n",
    "\n",
    "    pretrain_classses = NEWCLASSES[:PRETRAIN]\n",
    "    pretrain_data, pretrain_labels = split_into_classes(train_data, train_labels, pretrain_classses, NEWCLASSES)\n",
    "    pretest_data, pretest_labels = split_into_classes(test_data, test_labels, pretrain_classses, NEWCLASSES)\n",
    "    tasks = []\n",
    "    tests = []\n",
    "    if PRETRAIN > 0:\n",
    "        tasks = [[pretrain_data, pretrain_labels]]\n",
    "        tests = [pretest_data, pretest_labels]\n",
    "    else:\n",
    "\n",
    "        tasks = []\n",
    "        tests = []\n",
    "    for i in range(n_tasks):\n",
    "        if i == 0 and PRETRAIN > 0: ## as task 1 we already grab from \n",
    "            continue\n",
    "        elif PRETRAIN > 0:\n",
    "            task_data, task_labels = split_into_classes(train_data, train_labels, NEWCLASSES[PRETRAIN + size_of_task * (i-1) : PRETRAIN + size_of_task * (i)], NEWCLASSES)\n",
    "            tasks.append([task_data, task_labels])\n",
    "            partition_test_data, partition_test_labels = split_into_classes(test_data, test_labels, NEWCLASSES[PRETRAIN + size_of_task * (i-1) : PRETRAIN + size_of_task * (i)], NEWCLASSES)\n",
    "            tests.append(partition_test_data)\n",
    "            tests.append(partition_test_labels)\n",
    "        else:\n",
    "            task_data, task_labels = split_into_classes(train_data, train_labels, NEWCLASSES[size_of_task * i : size_of_task * (i + 1)] , NEWCLASSES)\n",
    "            tasks.append([task_data, task_labels])\n",
    "            partition_test_data, partition_test_labels = split_into_classes(test_data, test_labels, NEWCLASSES[size_of_task * i : size_of_task * (i + 1)] , NEWCLASSES)\n",
    "            tests.append(partition_test_data)\n",
    "            tests.append(partition_test_labels)\n",
    "        \n",
    "    # task1data, task1labels = split_into_classes(train_data, train_labels, ['airplane', 'automobile', 'bird', 'cat', 'deer']) ## pre train on this \n",
    "    # task2data, task2labels = split_into_classes(train_data, train_labels, ['dog', 'frog', 'horse', 'ship', 'truck']) ## split this guy up into 5 tasks \n",
    "    # # tasks = [[task1data, task1labels], [task2data,task2labels]]\n",
    "    # test_data_per_class_1, test_labels_per_class_1 = split_into_classes(test_data, test_labels, ['airplane', 'automobile', 'bird', 'cat', 'deer'])\n",
    "    # test_data_per_class_2, test_labels_per_class_2 = split_into_classes(test_data, test_labels, ['dog', 'frog', 'horse', 'ship', 'truck'])\n",
    "\n",
    "    # Train the model\n",
    "    for task in range(n_tasks):\n",
    "        print(\"Training task: \", task  + 1)\n",
    "        \n",
    "        x = torch.Tensor(tasks[task][0].reshape(-1, 32*32*3)).float()\n",
    "        y = torch.Tensor(tasks[task][1]).long()\n",
    "        \n",
    "        if args.cuda:\n",
    "            x, y = x.cuda(), y.cuda()\n",
    "    \n",
    "        for epoch in range(args.n_epochs):\n",
    "            for j in range(0, len(tasks[task][0]), args.batch_size):\n",
    "                current_data = x[j: j + args.batch_size]\n",
    "                current_labels = y[j: j + args.batch_size]\n",
    "                model.train()\n",
    "                model.observe(algorithm, current_data, task, current_labels)\n",
    "            #print(\"Epoch: \", epoch)\n",
    "            \n",
    "            #test the model after each epoch\n",
    "            correct = 0\n",
    "            total = len(tasks[task][0])\n",
    "            for j in range(0,len(tasks[task][0]), test_bs):\n",
    "                current_data = x[j: j + test_bs]\n",
    "                current_labels = y[j: j + test_bs]\n",
    "                output = model.forward(current_data, task)\n",
    "                pred = output.data.max(1)[1]\n",
    "                correct += (pred == current_labels).sum().item()\n",
    "            #print(\"Accuracy: \", correct / total)\n",
    "            # if correct / total > 0.85:\n",
    "            #     break\n",
    "            #   output loss only\n",
    "\n",
    "\n",
    "    # Test the model after training\n",
    "        average_confidence = []\n",
    "        for i in range(0, len(tests), 2):\n",
    "            correct = 0\n",
    "            total = len(tests[i])     \n",
    "\n",
    "            # Test the model\n",
    "            #print(\"Testing task: \" , i // 2 + 1)\n",
    "            \n",
    "            x = torch.Tensor(tests[i].reshape(-1, 32*32*3)).float()\n",
    "            y = torch.Tensor(tests[i+1]).long()\n",
    "            if args.cuda:\n",
    "                x, y = x.cuda(), y.cuda()\n",
    "            model.eval()\n",
    "            average_confidence_task = []\n",
    "            # keep track of average confidence score\n",
    "            for j in range(0,len(tests[i]), test_bs):\n",
    "                current_data = x[j: j + test_bs]\n",
    "                current_labels = y[j: j + test_bs]\n",
    "                output = model.forward(current_data, i // 2)\n",
    "                # apply softmax to get predictions\n",
    "                probabilities = torch.nn.functional.softmax(output, dim=1)\n",
    "                # get the maximum value of the probabilities for each image\n",
    "                predicted = torch.max(probabilities, 1).values\n",
    "                # get the average confidence score of the batch\n",
    "                average_confidence_task.append(torch.mean(predicted).item())\n",
    "                \n",
    "                pred = output.data.max(1)[1]\n",
    "                correct += (pred == current_labels).sum().item()\n",
    "            #print(\"Accuracy: \", correct / total)\n",
    "            test_accuracies.append(correct / total)\n",
    "            average_confidence.append(sum(average_confidence_task) / len(average_confidence_task))\n",
    "            \n",
    "        #print(\"Average confidence: \", sum(average_confidence) / len(average_confidence))     \n",
    "    \n",
    "    return model, test_accuracies, average_confidence\n",
    "\n",
    "        \n",
    "# model, test_accuracies = run_cifar(Args())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_next_task(args, model, tasknum, n_inputs=N_INPUTS, n_outputs=N_OUTPUTS, n_tasks=N_TASKS, size_of_task=SIZE_OF_TASKS, newclasses = SHUFFLEDCLASSES):\n",
    "    \n",
    "    test_accuracies = []\n",
    "    test_bs = 2500\n",
    "    # Load data\n",
    "    train_data, train_labels, test_data, test_labels = load_data(DATASET_PATH)\n",
    "    ## NEWCLASSES = suffled CLASSES\n",
    "    NEWCLASSES = newclasses\n",
    "    print(\"new ordering of classes: \", NEWCLASSES)\n",
    "    oldClasstoNewClass = {}\n",
    "    for i in range(len(CLASSES)):\n",
    "        oldClasstoNewClass[i] = NEWCLASSES.index(CLASSES[i])\n",
    "    for i in range(len(train_labels)):\n",
    "        train_labels[i] = oldClasstoNewClass[train_labels[i]]\n",
    "    for i in range(len(test_labels)):\n",
    "        test_labels[i] = oldClasstoNewClass[test_labels[i]]\n",
    "\n",
    "    pretrain_classses = NEWCLASSES[:PRETRAIN]\n",
    "    pretrain_data, pretrain_labels = split_into_classes(train_data, train_labels, pretrain_classses, NEWCLASSES)\n",
    "    pretest_data, pretest_labels = split_into_classes(test_data, test_labels, pretrain_classses, NEWCLASSES)\n",
    "    tasks = []\n",
    "    tests = []\n",
    "    if PRETRAIN > 0:\n",
    "        tasks = [[pretrain_data, pretrain_labels]]\n",
    "        tests = [pretest_data, pretest_labels]\n",
    "    else:\n",
    "\n",
    "        tasks = []\n",
    "        tests = []\n",
    "    for i in range(n_tasks):\n",
    "        if i == 0 and PRETRAIN > 0: ## as task 1 we already grab from \n",
    "            continue\n",
    "        elif PRETRAIN > 0:\n",
    "            task_data, task_labels = split_into_classes(train_data, train_labels, NEWCLASSES[PRETRAIN + size_of_task * (i-1) : PRETRAIN + size_of_task * (i)], NEWCLASSES)\n",
    "            tasks.append([task_data, task_labels])\n",
    "            partition_test_data, partition_test_labels = split_into_classes(test_data, test_labels, NEWCLASSES[PRETRAIN + size_of_task * (i-1) : PRETRAIN + size_of_task * (i)], NEWCLASSES)\n",
    "            tests.append(partition_test_data)\n",
    "            tests.append(partition_test_labels)\n",
    "        else:\n",
    "            task_data, task_labels = split_into_classes(train_data, train_labels, NEWCLASSES[size_of_task * i : size_of_task * (i + 1)] , NEWCLASSES)\n",
    "            tasks.append([task_data, task_labels])\n",
    "            partition_test_data, partition_test_labels = split_into_classes(test_data, test_labels, NEWCLASSES[size_of_task * i : size_of_task * (i + 1)] , NEWCLASSES)\n",
    "            tests.append(partition_test_data)\n",
    "            tests.append(partition_test_labels)\n",
    "        \n",
    "\n",
    "    # Train the model\n",
    "    task = tasknum - 1\n",
    "    print(\"Training task: \", task  + 1)\n",
    "    \n",
    "    x = torch.Tensor(tasks[task][0].reshape(-1, 32*32*3)).float()\n",
    "    y = torch.Tensor(tasks[task][1]).long()\n",
    "    \n",
    "    if args.cuda:\n",
    "        x, y = x.cuda(), y.cuda()\n",
    "\n",
    "    for epoch in range(args.n_epochs):\n",
    "        for j in range(0, len(tasks[task][0]), args.batch_size):\n",
    "            current_data = x[j: j + args.batch_size]\n",
    "            current_labels = y[j: j + args.batch_size]\n",
    "            model.train()\n",
    "            model.observe(current_data, task, current_labels)\n",
    "        #print(\"Epoch: \", epoch)\n",
    "        \n",
    "        #test the model after each epoch\n",
    "        correct = 0\n",
    "        total = len(tasks[task][0])\n",
    "        for j in range(0,len(tasks[task][0]), test_bs):\n",
    "            current_data = x[j: j + test_bs]\n",
    "            current_labels = y[j: j + test_bs]\n",
    "            output = model.forward(current_data, task)\n",
    "            pred = output.data.max(1)[1]\n",
    "            correct += (pred == current_labels).sum().item()\n",
    "        #print(\"Accuracy: \", correct / total)\n",
    "        if correct / total > 0.65:\n",
    "            break\n",
    "        #   output loss only\n",
    "\n",
    "\n",
    "# Test the model after training\n",
    "    for i in range(0, len(tests), 2):\n",
    "        correct = 0\n",
    "        total = len(tests[i])     \n",
    "\n",
    "        # Test the model\n",
    "        #print(\"Testing task: \" , i // 2 + 1)\n",
    "        \n",
    "        x = torch.Tensor(tests[i].reshape(-1, 32*32*3)).float()\n",
    "        y = torch.Tensor(tests[i+1]).long()\n",
    "        if args.cuda:\n",
    "            x, y = x.cuda(), y.cuda()\n",
    "        for j in range(0,len(tests[i]), test_bs):\n",
    "            current_data = x[j: j + test_bs]\n",
    "            current_labels = y[j: j + test_bs]\n",
    "            output = model.forward(current_data, i // 2)\n",
    "            pred = output.data.max(1)[1]\n",
    "            correct += (pred == current_labels).sum().item()\n",
    "        #print(\"Accuracy: \", correct / total)\n",
    "        test_accuracies.append(correct / total)\n",
    "            \n",
    "    print(tasknum)\n",
    "    return model, test_accuracies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_task_accuracies(test_accuracies, num_tasks):\n",
    "    for t in range(num_tasks):\n",
    "        # Calculate the indices for the current set of accuracies\n",
    "        start_idx = t * num_tasks\n",
    "        end_idx = start_idx + num_tasks\n",
    "        # Extract accuracies for all tasks after training task t+1\n",
    "        print (test_accuracies)\n",
    "        accuracies = test_accuracies[start_idx:end_idx]\n",
    "        # Create labels for the tasks\n",
    "        task_labels = [f'{i+1}' for i in range(num_tasks)]\n",
    "        # Plot the accuracies\n",
    "        plt.bar(task_labels, [acc * 100 for acc in accuracies])\n",
    "\n",
    "        # Calculate the y-value for the horizontal line\n",
    "        y_value = 100 / SIZE_OF_TASKS  # or use SIZE_OF_TASKS if it's defined separately\n",
    "\n",
    "        # Add horizontal line across the bar chart\n",
    "        plt.axhline(y=y_value, color='red', linestyle='--', label=f'y = {y_value:.2f}')\n",
    "        \n",
    "        plt.title(f'Test Set Accuracy for All Tasks (Post Task {t+1} Training)')\n",
    "        plt.ylabel('Accuracy (%)')\n",
    "        plt.xlabel('Task')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "def plot_comparison_accuracies(accuracies_list, num_tasks, num_models, model_names):\n",
    "    bar_width = 0.2\n",
    "    index = np.arange(num_tasks)\n",
    "    \n",
    "    for i, accuracies in enumerate(accuracies_list):\n",
    "        start_idx = (num_tasks-1) * num_tasks\n",
    "        end_idx = start_idx + num_tasks\n",
    "        plt.bar(index + i * bar_width, [acc * 100 for acc in accuracies[start_idx:end_idx]], bar_width, label=model_names[i])\n",
    "    \n",
    "    plt.xlabel('Tasks')\n",
    "    plt.ylabel('Accuracy (%)')\n",
    "    plt.title('Comparison of Test Set Accuracies for All Models')\n",
    "    plt.xticks(index + bar_width * (num_models - 1) / 2, [f'{i+1}' for i in range(num_tasks)])\n",
    "    plt.legend()\n",
    "    plt.savefig('comparison_accuracies.png')\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "# Example usage:\n",
    "# plot_comparison_accuracies([average_AGEM_accuracies, average_GEM_accuracies, average_REPLAY_accuracies, average_NAIVE_accuracies], N_TASKS, 4, ['AGEM', 'GEM', 'REPLAY', 'NAIVE'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_classes(classes, dataset):\n",
    "    if dataset == 'cifar-10':\n",
    "        return random.shuffle(classes)\n",
    "    elif dataset == 'cifar-100':\n",
    "        shuffled_classes = []\n",
    "        partitions = [classes[i:i + SIZE_OF_TASKS] for i in range(0, len(classes), SIZE_OF_TASKS)]\n",
    "        random.shuffle(partitions)\n",
    "        for partition in partitions:\n",
    "            shuffled_classes.extend(partition)\n",
    "        return shuffled_classes\n",
    "    else:\n",
    "        return classes  # No shuffling for other datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 1\n",
      "new ordering of classes:  ['possum', 'cattle', 'television', 'couch', 'lion', 'cups', 'apples', 'rabbit', 'tractor', 'beaver', 'house', 'clock', 'chair', 'tank', 'spider', 'poppies', 'squirrel', 'rocket', 'lawn-mower', 'road', 'pears', 'tiger', 'wolf', 'elephant', 'ray', 'beetle', 'plates', 'table', 'bus', 'motorcycle', 'plain', 'lizard', 'woman', 'orchids', 'lobster', 'mouse', 'kangaroo', 'cockroach', 'bicycle', 'whale', 'flatfish', 'castle', 'man', 'snake', 'streetcar', 'mushrooms', 'snail', 'computer keyboard', 'maple', 'otter', 'lamp', 'willow', 'caterpillar', 'butterfly', 'bridge', 'turtle', 'forest', 'train', 'dolphin', 'skunk', 'oak', 'fox', 'cans', 'porcupine', 'tulips', 'cloud', 'palm', 'pine', 'chimpanzee', 'crab', 'skyscraper', 'bottles', 'shark', 'camel', 'hamster', 'sweet peppers', 'seal', 'bed', 'bowls', 'oranges', 'leopard', 'boy', 'girl', 'mountain', 'pickup truck', 'baby', 'crocodile', 'wardrobe', 'sunflowers', 'shrew', 'worm', 'bee', 'trout', 'aquarium fish', 'raccoon', 'dinosaur', 'bear', 'telephone', 'sea', 'roses']\n",
      "Training task:  1\n",
      "Training task:  2\n",
      "Training task:  3\n",
      "Training task:  4\n",
      "Training task:  5\n",
      "Training task:  6\n",
      "Training task:  7\n",
      "Training task:  8\n",
      "Training task:  9\n",
      "Training task:  10\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# every 1 runs: measure the following using confidence bootstrapping\n",
    "# 1. Average confidence of the model on the test set\n",
    "# 2. Average confidence of the model on the test set for each task\n",
    "# 3. Average accuracy of the model on the test set\n",
    "# 4. Average accuracy of the model on the test set for each task\n",
    "# 5. Average accuracy of the model on the test set for each task after training task 1 as it trains on the rest of the tasks\n",
    "# 6. Measure forgetting of the model on the test set for each task after training task 1 as it trains on the rest of the tasks\n",
    "# 7. Measure ECE of the model on the test set\n",
    "# 8. Measure ECE of the model on the test set for each task\n",
    "# 9. take the average of the above metrics over all runs\n",
    "# 10. take the 97.5th percentile of the above metrics over all runs\n",
    "# 11. take the 2.5th percentile of the above metrics over all runs\n",
    "\n",
    "\n",
    "max_runs = 10\n",
    "test_accuracies_AGEM_all = []\n",
    "test_accuracies_GEM_all = []\n",
    "test_accuracies_REPLAY_all = []\n",
    "test_accuracies_NAIVE_all = []\n",
    "\n",
    "prediction_confidence_AGEM_all = []\n",
    "prediction_confidence_GEM_all = []\n",
    "prediction_confidence_REPLAY_all = []\n",
    "prediction_confidence_NAIVE_all = []\n",
    "\n",
    "for i in range(max_runs):\n",
    "    print(f\"Run {i+1}\")\n",
    "    random.shuffle(SHUFFLEDCLASSES)\n",
    "    #shuffle_classes(CLASSES, DATASET)\n",
    "\n",
    "    model, test_accuracies_AGEM, confidence = run_cifar('AGEM', Args())\n",
    "    print(\"AGEM last task confidence: \", confidence)\n",
    "    print(test_accuracies_AGEM)\n",
    "    prediction_confidence_AGEM_all.append(confidence)\n",
    "    test_accuracies_AGEM_all.append(test_accuracies_AGEM)\n",
    "\n",
    "    model, test_accuracies_GEM, confidence = run_cifar('GEM', Args())\n",
    "    print(\"GEM last task confidence: \", confidence)\n",
    "    print(test_accuracies_GEM)\n",
    "    prediction_confidence_GEM_all.append(confidence)\n",
    "    test_accuracies_GEM_all.append(test_accuracies_GEM)\n",
    "    \n",
    "    model, test_accuracies_REPLAY, confidence = run_cifar('REPLAY', Args())\n",
    "    print(\"REPLAY last task confidence: \", confidence)\n",
    "    print(test_accuracies_REPLAY)\n",
    "    prediction_confidence_REPLAY_all.append(confidence)\n",
    "    test_accuracies_REPLAY_all.append(test_accuracies_REPLAY)\n",
    "    \n",
    "    model, test_accuracies_NAIVE, confidence = run_cifar('NAIVE', Args())\n",
    "    print(\"NAIVE last task confidence: \", confidence)\n",
    "    print(test_accuracies_NAIVE)\n",
    "    prediction_confidence_NAIVE_all.append(confidence)\n",
    "    test_accuracies_NAIVE_all.append(test_accuracies_NAIVE)\n",
    "    \n",
    "average_AGEM_accuracies = np.mean(test_accuracies_AGEM_all, axis=0)\n",
    "average_GEM_accuracies = np.mean(test_accuracies_GEM_all, axis=0)\n",
    "average_REPLAY_accuracies = np.mean(test_accuracies_REPLAY_all, axis=0)\n",
    "average_NAIVE_accuracies = np.mean(test_accuracies_NAIVE_all, axis=0)\n",
    "\n",
    "task_1_accuracies_AGEM = []\n",
    "task_1_accuracies_GEM = []\n",
    "task_1_accuracies_REPLAY = []\n",
    "task_1_accuracies_NAIVE = []\n",
    "task_1_accuracies_AGEM.append(0.5)\n",
    "task_1_accuracies_GEM.append(0.5)\n",
    "task_1_accuracies_REPLAY.append(0.5)\n",
    "task_1_accuracies_NAIVE.append(0.5)\n",
    "\n",
    "for i in range(0, N_TASKS * N_TASKS, N_TASKS):\n",
    "    task_1_accuracies_GEM.append(average_GEM_accuracies[i])\n",
    "    task_1_accuracies_AGEM.append(average_AGEM_accuracies[i])\n",
    "    task_1_accuracies_REPLAY.append(average_REPLAY_accuracies[i])\n",
    "    task_1_accuracies_NAIVE.append(average_NAIVE_accuracies[i])\n",
    "\n",
    "plt.plot(task_1_accuracies_AGEM, label='AGEM')\n",
    "plt.plot(task_1_accuracies_GEM, label='GEM')\n",
    "plt.plot(task_1_accuracies_REPLAY, label='REPLAY')\n",
    "plt.plot(task_1_accuracies_NAIVE, label='NAIVE')\n",
    "plt.title('Task 1 Test Set Accuracy Comparison')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.xlabel('Tasks')\n",
    "plt.legend()\n",
    "plt.savefig('task_1_accuracy_comparison.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_task_accuracies(average_AGEM_accuracies, N_TASKS)\n",
    "#plot_task_accuracies(average_GEM_accuracies, N_TASKS)\n",
    "#plot_task_accuracies(average_REPLAY_accuracies, N_TASKS)\n",
    "#plot_task_accuracies(average_NAIVE_accuracies, N_TASKS)\n",
    "\n",
    "#plot_last_task_accuracies(average_AGEM_accuracies, N_TASKS)\n",
    "plot_comparison_accuracies([average_AGEM_accuracies, average_GEM_accuracies, average_REPLAY_accuracies, average_NAIVE_accuracies], N_TASKS, 4, ['AGEM', 'GEM', 'REPLAY', 'NAIVE'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "\n",
    "save_path = '/dcs/large/u2145461/cs407/Machine-Unlearning-x-Continual-Learning/GEM/Results/'\n",
    "\n",
    "def save_accuracies_to_file(name_of_file, accuracies):\n",
    "    completeName = os.path.join(save_path, name_of_file+\".csv\")\n",
    "    file1 = open(completeName, \"w\")\n",
    "    for item in accuracies:\n",
    "        file1.write(\"%s\\n\" % item)\n",
    "    file1.close()\n",
    "    \n",
    "save_accuracies_to_file('task_1_accuracies_AGEM', task_1_accuracies_AGEM)\n",
    "save_accuracies_to_file('task_1_accuracies_GEM', task_1_accuracies_GEM)\n",
    "save_accuracies_to_file('task_1_accuracies_REPLAY', task_1_accuracies_REPLAY)\n",
    "save_accuracies_to_file('task_1_accuracies_NAIVE', task_1_accuracies_NAIVE)\n",
    "\n",
    "save_accuracies_to_file('average_AGEM_accuracies', average_AGEM_accuracies)\n",
    "save_accuracies_to_file('average_GEM_accuracies', average_GEM_accuracies)\n",
    "save_accuracies_to_file('average_REPLAY_accuracies', average_REPLAY_accuracies)\n",
    "save_accuracies_to_file('average_NAIVE_accuracies', average_NAIVE_accuracies)\n",
    "\n",
    "save_accuracies_to_file('all_accuracies_AGEM', test_accuracies_AGEM_all)\n",
    "save_accuracies_to_file('all_accuracies_GEM', test_accuracies_GEM_all)\n",
    "save_accuracies_to_file('all_accuracies_REPLAY', test_accuracies_REPLAY_all)\n",
    "save_accuracies_to_file('all_accuracies_NAIVE', test_accuracies_NAIVE_all)\n",
    "       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIDENCE_SAMPLES = 5\n",
    "def avg_max_min(sample_accuracies_AGEM, sample_accuracies_GEM, sample_accuracies_REPLAY, sample_accuracies_NAIVE, title, ylabel):\n",
    "    averages = []\n",
    "    maxes = []\n",
    "    mins = []\n",
    "    for i in range(4):\n",
    "        if i == 0:\n",
    "            sample_accuracies = sample_accuracies_AGEM\n",
    "        elif i == 1:\n",
    "            sample_accuracies = sample_accuracies_GEM\n",
    "        elif i == 2:\n",
    "            sample_accuracies = sample_accuracies_REPLAY\n",
    "        else:\n",
    "            sample_accuracies = sample_accuracies_NAIVE\n",
    "        average = 0\n",
    "        max = 0\n",
    "        min = 1\n",
    "        for j in range(CONFIDENCE_SAMPLES):\n",
    "            last_20 = sample_accuracies[j]\n",
    "            last_20 = last_20[-20:]\n",
    "            average += np.mean(last_20)\n",
    "            if np.mean(last_20) > max:\n",
    "                max = np.mean(last_20)\n",
    "            if np.mean(last_20) < min:\n",
    "                min = np.mean(last_20)\n",
    "        average /= CONFIDENCE_SAMPLES\n",
    "        averages.append(average)\n",
    "        maxes.append(max)\n",
    "        mins.append(min)\n",
    "    # plot the avg acc with error bars\n",
    "    colors = ['blue', 'green', 'red', 'purple']\n",
    "    plt.bar(['AGEM', 'GEM', 'REPLAY', 'NAIVE'], averages, yerr=[[averages[i] - mins[i] for i in range(4)], [maxes[i] - averages[i] for i in range(4)]], capsize=10, color=colors)\n",
    "    plt.title(title)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.xlabel('Algorithm')\n",
    "    # make plots smaller\n",
    "    plt.rcParams[\"figure.figsize\"] = (3, 2)\n",
    "    # make plots look nice\n",
    "    plt.grid(axis='y')\n",
    "    plt.savefig('avg_acc_error_bars.png')\n",
    "    plt.show()\n",
    "    \n",
    "def plot_ECEs(ece_AGEM, ece_GEM, ece_REPLAY, ece_NAIVE, title):\n",
    "    colors = ['yellow', 'orange', 'purple', 'red']\n",
    "    plt.bar(['AGEM', 'GEM', 'REPLAY', 'NAIVE'], [np.mean(ece_AGEM), np.mean(ece_GEM), np.mean(ece_REPLAY), np.mean(ece_NAIVE)], yerr=[np.std(ece_AGEM), np.std(ece_GEM), np.std(ece_REPLAY), np.std(ece_NAIVE)], capsize=10, color=colors)\n",
    "    plt.title(title)\n",
    "    plt.ylabel('ECE')\n",
    "    plt.xlabel('Algorithm')\n",
    "    plt.grid(axis='y')\n",
    "    plt.savefig('ece.png')\n",
    "    plt.show()\n",
    "    \n",
    "def expected_callibration_error(accuracies, confidences):\n",
    "    ece = 0\n",
    "    for i in range(len(accuracies)):\n",
    "        ece += abs(accuracies[i] - confidences[i])\n",
    "    ece /= len(accuracies)\n",
    "    return ece\n",
    "\n",
    "# define a function to calculate the forgetting of the model on the test set for each task after training task 1 as it trains on the rest of the tasks\n",
    "# the accuracies array is defined as the accuracies for every tasks after each task training instance\n",
    "# for example, we have 20 tasks and 10 runs, the first 20 elements of the accuracies array will be the accuracies of the model on the test set after training task 1\n",
    "# the next 20 elements will be the accuracies of the model on the test set after training task 2, and so on\n",
    "def forgetting(sample_accuracies_AGEM):\n",
    "    sample_sample = sample_accuracies_AGEM\n",
    "    # reshape into 20 x 20 array\n",
    "    sample_sample = np.array(sample_sample).reshape(20, 20)\n",
    "    #find the maximum columnwise values\n",
    "    max_values = np.amax(sample_sample, axis=0)\n",
    "    \n",
    "    #CALCULATE FORGETTING\n",
    "    forgetting = []\n",
    "    sample_sample = sample_sample[N_TASKS - 1]\n",
    "    for i in range(N_TASKS):\n",
    "        forgetting.append(abs(max_values[i] - sample_sample[i]))\n",
    "    forgetting = np.mean(forgetting)\n",
    "    return forgetting\n",
    "    \n",
    "def plot_forgetting(sample_accuracies_AGEM, sample_accuracies_GEM, sample_accuracies_REPLAY, sample_accuracies_NAIVE, title):\n",
    "    forgetting_AGEM = []\n",
    "    forgetting_GEM = []\n",
    "    forgetting_REPLAY = []\n",
    "    forgetting_NAIVE = []\n",
    "    for i in range(CONFIDENCE_SAMPLES):\n",
    "        forgetting_AGEM.append(forgetting(sample_accuracies_AGEM[i]))\n",
    "        forgetting_GEM.append(forgetting(sample_accuracies_GEM[i]))\n",
    "        forgetting_REPLAY.append(forgetting(sample_accuracies_REPLAY[i]))\n",
    "        forgetting_NAIVE.append(forgetting(sample_accuracies_NAIVE[i]))\n",
    "    colors = ['blue', 'green', 'red', 'purple']\n",
    "    plt.bar(['AGEM', 'GEM', 'REPLAY', 'NAIVE'], [np.mean(forgetting_AGEM), np.mean(forgetting_GEM), np.mean(forgetting_REPLAY), np.mean(forgetting_NAIVE)], yerr=[np.std(forgetting_AGEM), np.std(forgetting_GEM), np.std(forgetting_REPLAY), np.std(forgetting_NAIVE)], capsize=10, color=colors)\n",
    "    plt.title(title)\n",
    "    plt.ylabel('Forgetting')\n",
    "    plt.xlabel('Algorithm')\n",
    "    plt.grid(axis='y')\n",
    "    plt.savefig('forgetting.png')\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(int(max_runs / CONFIDENCE_SAMPLES)):\n",
    "    # extract the accuracies for the current sample\n",
    "    sample_AGEM_accuracies = test_accuracies_AGEM_all[i*CONFIDENCE_SAMPLES: (i+1)*CONFIDENCE_SAMPLES]\n",
    "    sample_GEM_accuracies = test_accuracies_GEM_all[i*CONFIDENCE_SAMPLES: (i+1)*CONFIDENCE_SAMPLES]\n",
    "    sample_REPLAY_accuracies = test_accuracies_REPLAY_all[i*CONFIDENCE_SAMPLES: (i+1)*CONFIDENCE_SAMPLES]\n",
    "    sample_NAIVE_accuracies = test_accuracies_NAIVE_all[i*CONFIDENCE_SAMPLES: (i+1)*CONFIDENCE_SAMPLES]\n",
    "    \n",
    "    # extract the last 20 accuracies for the current sample from each sample accuracies\n",
    "    avg_max_min(sample_AGEM_accuracies, sample_GEM_accuracies, sample_REPLAY_accuracies, sample_NAIVE_accuracies, f'Average Test Set Accuracy with Error Bars Sample: {i}', 'Accuracy (%)')\n",
    "    \n",
    "    sample_AGEM_confidences = prediction_confidence_AGEM_all[i*CONFIDENCE_SAMPLES: (i+1)*CONFIDENCE_SAMPLES]\n",
    "    sample_GEM_confidences = prediction_confidence_GEM_all[i*CONFIDENCE_SAMPLES: (i+1)*CONFIDENCE_SAMPLES]\n",
    "    sample_REPLAY_confidences = prediction_confidence_REPLAY_all[i*CONFIDENCE_SAMPLES: (i+1)*CONFIDENCE_SAMPLES]\n",
    "    sample_NAIVE_confidences = prediction_confidence_NAIVE_all[i*CONFIDENCE_SAMPLES: (i+1)*CONFIDENCE_SAMPLES]\n",
    "    \n",
    "    avg_max_min(sample_AGEM_confidences, sample_GEM_confidences, sample_REPLAY_confidences, sample_NAIVE_confidences, f'Average Prediction Confidence with Error Bars Sample: {i}', 'Confidence (%)')\n",
    "\n",
    "    ece_AGEM = []\n",
    "    ece_GEM = []\n",
    "    ece_REPLAY = []\n",
    "    ece_NAIVE = []\n",
    "    # calculate ECE over 5 samples\n",
    "    for j in range(CONFIDENCE_SAMPLES):\n",
    "        ece_AGEM.append(expected_callibration_error(sample_AGEM_accuracies[j][-N_TASKS:], sample_AGEM_confidences[j]))\n",
    "        ece_GEM.append(expected_callibration_error(sample_GEM_accuracies[j][-N_TASKS:], sample_GEM_confidences[j]))\n",
    "        ece_REPLAY.append(expected_callibration_error(sample_REPLAY_accuracies[j][-N_TASKS:], sample_REPLAY_confidences[j]))\n",
    "        ece_NAIVE.append(expected_callibration_error(sample_NAIVE_accuracies[j][-N_TASKS:], sample_NAIVE_confidences[j]))\n",
    "    plot_ECEs(ece_AGEM, ece_GEM, ece_REPLAY, ece_NAIVE, f'Expected Calibration Error Sample: {i}')\n",
    "    \n",
    "    forgetting_AGEM = []\n",
    "    forgetting_GEM = []\n",
    "    forgetting_REPLAY = []\n",
    "    forgetting_NAIVE = []\n",
    "    for j in range(CONFIDENCE_SAMPLES):\n",
    "        forgetting_AGEM.append(forgetting(sample_AGEM_accuracies[j]))\n",
    "        forgetting_GEM.append(forgetting(sample_GEM_accuracies[j]))\n",
    "        forgetting_REPLAY.append(forgetting(sample_REPLAY_accuracies[j]))\n",
    "        forgetting_NAIVE.append(forgetting(sample_NAIVE_accuracies[j]))\n",
    "    plot_forgetting(sample_AGEM_accuracies, sample_GEM_accuracies, sample_REPLAY_accuracies, sample_NAIVE_accuracies, f'Forgetting Sample: {i}')\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
