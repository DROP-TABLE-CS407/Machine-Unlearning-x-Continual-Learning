{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3e8eb68",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.functional import relu, avg_pool2d\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import time\n",
    "import random\n",
    "\n",
    "# from GEM.gem import *\n",
    "from GEM.args import *\n",
    "\n",
    "from cifar import load_cifar10_data, split_into_classes, get_class_indexes \n",
    "\n",
    "# import quadprog\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(\".\"))  # Adds the current directory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6360b5c4aaa0b84a",
   "metadata": {},
   "source": [
    "# CIFAR-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "545fa36453e0dda4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-13T15:16:56.387836Z",
     "start_time": "2024-11-13T15:16:56.266657Z"
    }
   },
   "outputs": [],
   "source": [
    "# Path to the dataset\n",
    "DATASET_PATH = 'cifar-10-python' \n",
    "CLASSES = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "train_data, train_labels, test_data, test_labels = load_cifar10_data(DATASET_PATH)\n",
    "classes = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b849681c0f0bdd16",
   "metadata": {},
   "source": [
    "# PRETRAINED MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b345dbfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet18CIFAR(\n",
       "  (resnet): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): Identity()\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=512, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import time\n",
    "# make cuda available if available\n",
    "\n",
    "from cifar import load_cifar10_data, show_image\n",
    "\n",
    "# we want to create a resnet 18 model for 32x32 images\n",
    "# avoid upscaling, the model will take 32x32 images on input as opposed to 224x224\n",
    "\n",
    "initialisation = time.time()\n",
    "\n",
    "class ResNet18CIFAR(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNet18CIFAR, self).__init__()\n",
    "        self.resnet = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', pretrained=False)\n",
    "        # change the first layer to accept 32x32 images with 3 channels rather than 224x224 images\n",
    "        # check the size of the input layer\n",
    "        print(\"|| conv1 weight size: \", self.resnet.conv1.weight.size())\n",
    "        print(\"|| fc weight size: \", self.resnet.fc.weight.size())\n",
    "        self.resnet.conv1 = torch.nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.resnet.fc = torch.nn.Linear(512, 10)\n",
    "        self.resnet.maxpool = torch.nn.Identity()\n",
    "        # change input layer to accept 32x32 images\n",
    "\n",
    "\n",
    "        \n",
    "        # List all layers in the resnet18 model\n",
    "        for name, layer in self.resnet.named_children():\n",
    "            print(f\"Layer: {name} -> {layer}\")\n",
    "        \n",
    "        #print(\"|| conv1 weight size: \", self.resnet.conv1.weight.size())\n",
    "        #print(\"|| fc weight size: \", self.resnet.fc.weight.size())\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.resnet(x)\n",
    "    \n",
    "model = torch.load('models/resnet18_cifar77ACC.pth',  map_location=torch.device('cpu'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d9dd6044c0b8dfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "||===================START CLASS-BY-CLASS ACCURACY=================||\n",
      "|| Overall Test Accuracy: 77.34% ||\n",
      "|| Accuracy for Class 0: 83.10% ||\n",
      "|| Accuracy for Class 1: 88.00% ||\n",
      "|| Accuracy for Class 2: 63.10% ||\n",
      "|| Accuracy for Class 3: 58.30% ||\n",
      "|| Accuracy for Class 4: 72.60% ||\n",
      "|| Accuracy for Class 5: 66.00% ||\n",
      "|| Accuracy for Class 6: 84.10% ||\n",
      "|| Accuracy for Class 7: 82.50% ||\n",
      "|| Accuracy for Class 8: 87.20% ||\n",
      "|| Accuracy for Class 9: 88.50% ||\n"
     ]
    }
   ],
   "source": [
    "# turn the data into a tensor\n",
    "test_data_tensor = torch.tensor(test_data).float()\n",
    "test_labels_tensor = torch.tensor(test_labels)\n",
    "\n",
    "# Define the number of classes in your dataset\n",
    "num_classes = 10\n",
    "# Initialize counters for each class\n",
    "class_correct = [0] * num_classes\n",
    "class_total = [0] * num_classes\n",
    "\n",
    "print(\"||===================START CLASS-BY-CLASS ACCURACY=================||\")\n",
    "\n",
    "# Move tensors to GPU if available\n",
    "if torch.cuda.is_available():\n",
    "    test_data_tensor = test_data_tensor.cuda()\n",
    "    test_labels_tensor = test_labels_tensor.cuda()\n",
    "\n",
    "# Test the model\n",
    "with torch.no_grad():\n",
    "    for i in range(0, len(test_data), 1000):\n",
    "        # Get the input and output\n",
    "        img = test_data_tensor[i:i + 1000]\n",
    "        label = test_labels_tensor[i:i + 1000]\n",
    "        \n",
    "        model = model.cuda()\n",
    "\n",
    "        # Get the prediction\n",
    "        outputs = model(img)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "        # Update per-class counters\n",
    "        for lbl, pred in zip(label, predicted):\n",
    "            class_total[lbl.item()] += 1\n",
    "            if lbl.item() == pred.item():\n",
    "                class_correct[lbl.item()] += 1\n",
    "\n",
    "        del img\n",
    "\n",
    "# Print overall accuracy\n",
    "overall_accuracy = sum(class_correct) / sum(class_total) * 100\n",
    "print(f\"|| Overall Test Accuracy: {overall_accuracy:.2f}% ||\")\n",
    "\n",
    "# Print accuracy for each class\n",
    "for cls in range(num_classes):\n",
    "    if class_total[cls] > 0:\n",
    "        class_accuracy = class_correct[cls] / class_total[cls] * 100\n",
    "        print(f\"|| Accuracy for Class {cls}: {class_accuracy:.2f}% ||\")\n",
    "    else:\n",
    "        print(f\"|| No samples for Class {cls} ||\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd55059d",
   "metadata": {},
   "source": [
    "# UNLEARNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8c22b66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/dcs/21/u2110391/CS407/Machine-Unlearning-x-Continual-Learning/Unlearning\n"
     ]
    }
   ],
   "source": [
    "%cd Unlearning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e8076b",
   "metadata": {},
   "source": [
    "### Prepare Data and Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8280c00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classes to be Unlearnt\n",
    "classes_to_unlearn = [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c590ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "from unlearn.scrub import train_distill, iterative_unlearn, scrub\n",
    "from utils import DistillKL, AverageMeter, accuracy\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Convert data and labels to PyTorch tensors\n",
    "train_data_tensor = torch.tensor(train_data, dtype=torch.float32).cuda()\n",
    "train_labels_tensor = torch.tensor(train_labels).cuda()\n",
    "\n",
    "test_data_tensor = torch.tensor(test_data, dtype=torch.float32).cuda()\n",
    "test_labels_tensor = torch.tensor(test_labels).cuda()\n",
    "\n",
    "# Split training data into forget and retain sets\n",
    "forget_mask = torch.isin(train_labels_tensor, torch.tensor(classes_to_unlearn).cuda())\n",
    "retain_mask = ~forget_mask\n",
    "\n",
    "# Get the indices of the forget and retain subsets\n",
    "forget_indices = forget_mask.nonzero(as_tuple=True)[0]\n",
    "retain_indices = retain_mask.nonzero(as_tuple=True)[0]\n",
    "\n",
    "# Create the forget and retain datasets using the indices\n",
    "forget_dataset = TensorDataset(train_data_tensor[forget_indices], train_labels_tensor[forget_indices])\n",
    "retain_dataset = TensorDataset(train_data_tensor[retain_indices], train_labels_tensor[retain_indices])\n",
    "test_dataset = TensorDataset(test_data_tensor, test_labels_tensor)\n",
    "\n",
    "# Create DataLoaders\n",
    "data_loaders = OrderedDict(\n",
    "    forget = DataLoader(forget_dataset, batch_size=64, shuffle=True),\n",
    "    retain = DataLoader(retain_dataset, batch_size=64, shuffle=True),\n",
    "    test =  DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be992da",
   "metadata": {},
   "source": [
    "### DEFINE ALGORITHM HYPERPARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78e88c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the criterion and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)\n",
    "\n",
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.unlearn_lr = 0.01         # Learning rate for unlearning\n",
    "        self.momentum = 0.9\n",
    "        self.weight_decay = 5e-4\n",
    "        self.dataset = ''      # Change as needed\n",
    "        self.num_classes = 10         # Number of classes in the dataset\n",
    "        self.batch_size = 64\n",
    "        self.print_freq = 10\n",
    "        self.warmup = 0               # Number of warmup epochs\n",
    "        self.imagenet_arch = False    # Set to True if using ImageNet architecture\n",
    "        self.seed = 42       \n",
    "        \n",
    "        # SCRUB SPECIFIC\n",
    "        self.kd_T = 1\n",
    "        self.msteps = 1\n",
    "        self.gamma = 10\n",
    "        self.beta = 1\n",
    "\n",
    "        # NEGRAD SPECIFIC\n",
    "        self.alpha = 2\n",
    "\n",
    "\n",
    "        # Add the following attributes to ensure compatibility\n",
    "        self.decreasing_lr = '50,75'  # Comma-separated epochs where LR decays\n",
    "        self.rewind_epoch = 0         # Epoch to rewind to; set to 0 if not using rewinding\n",
    "        self.rewind_pth = ''          # Path to the rewind checkpoint\n",
    "        self.gpu = 0                  # GPU ID to use; adjust as needed\n",
    "        self.surgical = False         # Whether to use surgical unlearning\n",
    "        self.unlearn = 'NG'           # Unlearning method, e.g., 'retrain'\n",
    "        self.choice = []              # Layers to unlearn surgically; list of layer names\n",
    "        self.unlearn_epochs = 10      # Number of epochs for unlearning\n",
    "        self.epochs = 100   \n",
    "\n",
    "# args = Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f08fd0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import unlearn\n",
    "\n",
    "def unlearnWithArgs(data_loaders, umodel, criterion, args):\n",
    "    unlearn_method = unlearn.get_unlearn_method(args.unlearn)\n",
    "    if args.unlearn == 'SCRUB':\n",
    "        model_s = copy.deepcopy(umodel)\n",
    "        model_t = copy.deepcopy(umodel)\n",
    "        module_list = nn.ModuleList([model_s, model_t])\n",
    "        unlearn_method(data_loaders, module_list, criterion, args)\n",
    "        umodel = module_list[0]\n",
    "    else:\n",
    "        unlearn_method(data_loaders, umodel, criterion, args)\n",
    "    \n",
    "    return umodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4cb740d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #0, Learning rate: 0.01\n",
      "len(r_loader): 704, len(f_loader): 79\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][9/704]\tLoss 26.0853 (36.7699)\tAccuracy 14.062 (11.250)\tTime 1.91\n",
      "Epoch: [0][19/704]\tLoss 16.6894 (28.4633)\tAccuracy 4.688 (11.016)\tTime 0.44\n",
      "Epoch: [0][29/704]\tLoss 6.9493 (21.9896)\tAccuracy 9.375 (11.094)\tTime 0.44\n",
      "Epoch: [0][39/704]\tLoss 6.3166 (18.0791)\tAccuracy 18.750 (11.836)\tTime 0.44\n",
      "Epoch: [0][49/704]\tLoss 5.6424 (15.6072)\tAccuracy 10.938 (12.406)\tTime 0.44\n",
      "Epoch: [0][59/704]\tLoss 4.9331 (13.8472)\tAccuracy 7.812 (13.047)\tTime 0.44\n",
      "Epoch: [0][69/704]\tLoss 4.7695 (12.5864)\tAccuracy 15.625 (13.795)\tTime 0.44\n",
      "Epoch: [0][79/704]\tLoss 4.5330 (11.6005)\tAccuracy 23.438 (15.391)\tTime 0.43\n",
      "Epoch: [0][89/704]\tLoss 4.6587 (10.8146)\tAccuracy 32.812 (16.528)\tTime 0.44\n",
      "Epoch: [0][99/704]\tLoss 4.0813 (10.1686)\tAccuracy 43.750 (18.094)\tTime 0.44\n",
      "Epoch: [0][109/704]\tLoss 4.3673 (9.6264)\tAccuracy 26.562 (19.219)\tTime 0.44\n",
      "Epoch: [0][119/704]\tLoss 3.6716 (9.1492)\tAccuracy 37.500 (20.521)\tTime 0.44\n",
      "Epoch: [0][129/704]\tLoss 3.7057 (8.7454)\tAccuracy 45.312 (21.575)\tTime 0.44\n",
      "Epoch: [0][139/704]\tLoss 3.5000 (8.3967)\tAccuracy 35.938 (22.422)\tTime 0.44\n",
      "Epoch: [0][149/704]\tLoss 3.9769 (8.0874)\tAccuracy 40.625 (23.229)\tTime 0.44\n",
      "Epoch: [0][159/704]\tLoss 3.4309 (7.8222)\tAccuracy 46.875 (23.994)\tTime 0.42\n",
      "Epoch: [0][169/704]\tLoss 3.4202 (7.5739)\tAccuracy 42.188 (24.779)\tTime 0.44\n",
      "Epoch: [0][179/704]\tLoss 3.6680 (7.3499)\tAccuracy 37.500 (25.460)\tTime 0.44\n",
      "Epoch: [0][189/704]\tLoss 3.4871 (7.1468)\tAccuracy 31.250 (26.127)\tTime 0.44\n",
      "Epoch: [0][199/704]\tLoss 3.6647 (6.9677)\tAccuracy 43.750 (26.766)\tTime 0.44\n",
      "Epoch: [0][209/704]\tLoss 3.4528 (6.8004)\tAccuracy 32.812 (27.188)\tTime 0.44\n",
      "Epoch: [0][219/704]\tLoss 3.3858 (6.6465)\tAccuracy 26.562 (27.642)\tTime 0.44\n",
      "Epoch: [0][229/704]\tLoss 3.2989 (6.5067)\tAccuracy 39.062 (28.118)\tTime 0.44\n",
      "Epoch: [0][239/704]\tLoss 3.4836 (6.3881)\tAccuracy 31.250 (28.464)\tTime 0.42\n",
      "Epoch: [0][249/704]\tLoss 3.9477 (6.2997)\tAccuracy 43.750 (28.725)\tTime 0.44\n",
      "Epoch: [0][259/704]\tLoss 3.4053 (6.1911)\tAccuracy 37.500 (29.105)\tTime 0.44\n",
      "Epoch: [0][269/704]\tLoss 3.5284 (6.0880)\tAccuracy 32.812 (29.462)\tTime 0.44\n",
      "Epoch: [0][279/704]\tLoss 3.5968 (5.9917)\tAccuracy 34.375 (29.855)\tTime 0.44\n",
      "Epoch: [0][289/704]\tLoss 2.8965 (5.9011)\tAccuracy 54.688 (30.232)\tTime 0.44\n",
      "Epoch: [0][299/704]\tLoss 2.9949 (5.8137)\tAccuracy 45.312 (30.531)\tTime 0.44\n",
      "Epoch: [0][309/704]\tLoss 3.1145 (5.7310)\tAccuracy 39.062 (30.862)\tTime 0.44\n",
      "Epoch: [0][319/704]\tLoss 2.7147 (5.6583)\tAccuracy 45.312 (31.084)\tTime 0.42\n",
      "Epoch: [0][329/704]\tLoss 3.0928 (5.5877)\tAccuracy 37.500 (31.307)\tTime 0.44\n",
      "Epoch: [0][339/704]\tLoss 2.6301 (5.5114)\tAccuracy 51.562 (31.746)\tTime 0.44\n",
      "Epoch: [0][349/704]\tLoss 2.7460 (5.4448)\tAccuracy 45.312 (31.982)\tTime 0.44\n",
      "Epoch: [0][359/704]\tLoss 3.3074 (5.3799)\tAccuracy 35.938 (32.266)\tTime 0.44\n",
      "Epoch: [0][369/704]\tLoss 2.9122 (5.3173)\tAccuracy 54.688 (32.584)\tTime 0.44\n",
      "Epoch: [0][379/704]\tLoss 3.0209 (5.2619)\tAccuracy 45.312 (32.854)\tTime 0.44\n",
      "Epoch: [0][389/704]\tLoss 3.0632 (5.2052)\tAccuracy 40.625 (33.109)\tTime 0.44\n",
      "Epoch: [0][399/704]\tLoss 3.5290 (5.1623)\tAccuracy 32.812 (33.203)\tTime 0.42\n",
      "Epoch: [0][409/704]\tLoss 3.5217 (5.1209)\tAccuracy 35.938 (33.342)\tTime 0.44\n",
      "Epoch: [0][419/704]\tLoss 2.9099 (5.0811)\tAccuracy 50.000 (33.471)\tTime 0.44\n",
      "Epoch: [0][429/704]\tLoss 3.6170 (5.0410)\tAccuracy 28.125 (33.714)\tTime 0.44\n",
      "Epoch: [0][439/704]\tLoss 2.5403 (4.9970)\tAccuracy 46.875 (33.942)\tTime 0.44\n",
      "Epoch: [0][449/704]\tLoss 3.3068 (4.9547)\tAccuracy 31.250 (34.115)\tTime 0.44\n",
      "Epoch: [0][459/704]\tLoss 2.9660 (4.9084)\tAccuracy 46.875 (34.412)\tTime 0.44\n",
      "Epoch: [0][469/704]\tLoss 3.1230 (4.8654)\tAccuracy 43.750 (34.704)\tTime 0.44\n",
      "Epoch: [0][479/704]\tLoss 2.9707 (4.8289)\tAccuracy 43.750 (34.928)\tTime 0.43\n",
      "Epoch: [0][489/704]\tLoss 2.8502 (4.7937)\tAccuracy 48.438 (35.112)\tTime 0.44\n",
      "Epoch: [0][499/704]\tLoss 2.3703 (4.7584)\tAccuracy 53.125 (35.359)\tTime 0.44\n",
      "Epoch: [0][509/704]\tLoss 3.3169 (4.7247)\tAccuracy 40.625 (35.588)\tTime 0.44\n",
      "Epoch: [0][519/704]\tLoss 3.0400 (4.6946)\tAccuracy 46.875 (35.718)\tTime 0.44\n",
      "Epoch: [0][529/704]\tLoss 2.2273 (4.6594)\tAccuracy 51.562 (35.940)\tTime 0.44\n",
      "Epoch: [0][539/704]\tLoss 2.9422 (4.6274)\tAccuracy 40.625 (36.100)\tTime 0.44\n",
      "Epoch: [0][549/704]\tLoss 2.4171 (4.5959)\tAccuracy 54.688 (36.278)\tTime 0.44\n",
      "Epoch: [0][559/704]\tLoss 3.0064 (4.5711)\tAccuracy 46.875 (36.378)\tTime 0.43\n",
      "Epoch: [0][569/704]\tLoss 2.8410 (4.5431)\tAccuracy 50.000 (36.565)\tTime 0.44\n",
      "Epoch: [0][579/704]\tLoss 2.9521 (4.5121)\tAccuracy 37.500 (36.767)\tTime 0.44\n",
      "Epoch: [0][589/704]\tLoss 3.1958 (4.4855)\tAccuracy 40.625 (36.933)\tTime 0.44\n",
      "Epoch: [0][599/704]\tLoss 3.0975 (4.4596)\tAccuracy 40.625 (37.057)\tTime 0.44\n",
      "Epoch: [0][609/704]\tLoss 2.6470 (4.4326)\tAccuracy 48.438 (37.246)\tTime 0.44\n",
      "Epoch: [0][619/704]\tLoss 2.7350 (4.4065)\tAccuracy 45.312 (37.394)\tTime 0.44\n",
      "Epoch: [0][629/704]\tLoss 3.1530 (4.3816)\tAccuracy 34.375 (37.520)\tTime 0.44\n",
      "Epoch: [0][639/704]\tLoss 2.5787 (4.3588)\tAccuracy 51.562 (37.681)\tTime 0.43\n",
      "Epoch: [0][649/704]\tLoss 3.5358 (4.3368)\tAccuracy 39.062 (37.810)\tTime 0.44\n",
      "Epoch: [0][659/704]\tLoss 2.5682 (4.3132)\tAccuracy 50.000 (37.985)\tTime 0.44\n",
      "Epoch: [0][669/704]\tLoss 2.9815 (4.2969)\tAccuracy 51.562 (38.097)\tTime 0.44\n",
      "Epoch: [0][679/704]\tLoss 2.9328 (4.2763)\tAccuracy 54.688 (38.270)\tTime 0.44\n",
      "Epoch: [0][689/704]\tLoss 2.8139 (4.2584)\tAccuracy 48.438 (38.372)\tTime 0.44\n",
      "Epoch: [0][699/704]\tLoss 2.4047 (4.2366)\tAccuracy 54.688 (38.522)\tTime 0.44\n",
      "train_accuracy 38.569\n",
      "one epoch duration:32.389777183532715\n",
      "Epoch #1, Learning rate: 0.01\n",
      "len(r_loader): 704, len(f_loader): 79\n",
      "Epoch: [1][9/704]\tLoss 3.0502 (2.9479)\tAccuracy 46.875 (46.562)\tTime 0.45\n",
      "Epoch: [1][19/704]\tLoss 2.7825 (2.8813)\tAccuracy 53.125 (48.438)\tTime 0.45\n",
      "Epoch: [1][29/704]\tLoss 2.5455 (2.8095)\tAccuracy 51.562 (49.062)\tTime 0.45\n",
      "Epoch: [1][39/704]\tLoss 2.7919 (2.8018)\tAccuracy 51.562 (48.359)\tTime 0.45\n",
      "Epoch: [1][49/704]\tLoss 2.7654 (2.7744)\tAccuracy 43.750 (48.969)\tTime 0.45\n",
      "Epoch: [1][59/704]\tLoss 2.5509 (2.7566)\tAccuracy 46.875 (49.062)\tTime 0.45\n",
      "Epoch: [1][69/704]\tLoss 2.5424 (2.7560)\tAccuracy 50.000 (49.263)\tTime 0.45\n",
      "Epoch: [1][79/704]\tLoss 2.8773 (2.7566)\tAccuracy 46.875 (49.121)\tTime 0.43\n",
      "Epoch: [1][89/704]\tLoss 2.8290 (2.7408)\tAccuracy 46.875 (49.375)\tTime 0.44\n",
      "Epoch: [1][99/704]\tLoss 2.3888 (2.7368)\tAccuracy 56.250 (49.516)\tTime 0.44\n",
      "Epoch: [1][109/704]\tLoss 2.2728 (2.7282)\tAccuracy 53.125 (49.602)\tTime 0.44\n",
      "Epoch: [1][119/704]\tLoss 2.5087 (2.7244)\tAccuracy 59.375 (49.831)\tTime 0.44\n",
      "Epoch: [1][129/704]\tLoss 2.8947 (2.7090)\tAccuracy 48.438 (50.144)\tTime 0.44\n",
      "Epoch: [1][139/704]\tLoss 3.0843 (2.7042)\tAccuracy 56.250 (50.335)\tTime 0.44\n",
      "Epoch: [1][149/704]\tLoss 2.5836 (2.7003)\tAccuracy 54.688 (50.323)\tTime 0.44\n",
      "Epoch: [1][159/704]\tLoss 2.3881 (2.6943)\tAccuracy 56.250 (50.322)\tTime 0.43\n",
      "Epoch: [1][169/704]\tLoss 2.2907 (2.6854)\tAccuracy 57.812 (50.469)\tTime 0.44\n",
      "Epoch: [1][179/704]\tLoss 2.4547 (2.6816)\tAccuracy 62.500 (50.677)\tTime 0.44\n",
      "Epoch: [1][189/704]\tLoss 2.3576 (2.6824)\tAccuracy 54.688 (50.691)\tTime 0.44\n",
      "Epoch: [1][199/704]\tLoss 2.7941 (2.6761)\tAccuracy 51.562 (50.781)\tTime 0.44\n",
      "Epoch: [1][209/704]\tLoss 2.7498 (2.6736)\tAccuracy 59.375 (50.871)\tTime 0.44\n",
      "Epoch: [1][219/704]\tLoss 2.3323 (2.6766)\tAccuracy 65.625 (50.831)\tTime 0.44\n",
      "Epoch: [1][229/704]\tLoss 2.1424 (2.6694)\tAccuracy 65.625 (51.073)\tTime 0.44\n",
      "Epoch: [1][239/704]\tLoss 2.3574 (2.6655)\tAccuracy 51.562 (51.094)\tTime 0.43\n",
      "Epoch: [1][249/704]\tLoss 2.3069 (2.6572)\tAccuracy 57.812 (51.312)\tTime 0.44\n",
      "Epoch: [1][259/704]\tLoss 2.6392 (2.6533)\tAccuracy 51.562 (51.400)\tTime 0.44\n",
      "Epoch: [1][269/704]\tLoss 2.5229 (2.6521)\tAccuracy 53.125 (51.539)\tTime 0.44\n",
      "Epoch: [1][279/704]\tLoss 2.8181 (2.6475)\tAccuracy 48.438 (51.607)\tTime 0.44\n",
      "Epoch: [1][289/704]\tLoss 2.3395 (2.6415)\tAccuracy 57.812 (51.746)\tTime 0.44\n",
      "Epoch: [1][299/704]\tLoss 2.1773 (2.6392)\tAccuracy 62.500 (51.797)\tTime 0.44\n",
      "Epoch: [1][309/704]\tLoss 2.5349 (2.6356)\tAccuracy 54.688 (51.850)\tTime 0.44\n",
      "Epoch: [1][319/704]\tLoss 2.5616 (2.6291)\tAccuracy 54.688 (51.973)\tTime 0.43\n",
      "Epoch: [1][329/704]\tLoss 2.4254 (2.6260)\tAccuracy 53.125 (52.036)\tTime 0.44\n",
      "Epoch: [1][339/704]\tLoss 2.2945 (2.6188)\tAccuracy 56.250 (52.155)\tTime 0.44\n",
      "Epoch: [1][349/704]\tLoss 2.7381 (2.6161)\tAccuracy 45.312 (52.214)\tTime 0.44\n",
      "Epoch: [1][359/704]\tLoss 2.3208 (2.6125)\tAccuracy 60.938 (52.283)\tTime 0.44\n",
      "Epoch: [1][369/704]\tLoss 2.1777 (2.6040)\tAccuracy 60.938 (52.407)\tTime 0.45\n",
      "Epoch: [1][379/704]\tLoss 1.9363 (2.5960)\tAccuracy 68.750 (52.586)\tTime 0.45\n",
      "Epoch: [1][389/704]\tLoss 2.1921 (2.5897)\tAccuracy 67.188 (52.740)\tTime 0.44\n",
      "Epoch: [1][399/704]\tLoss 2.2571 (2.5868)\tAccuracy 60.938 (52.852)\tTime 0.43\n",
      "Epoch: [1][409/704]\tLoss 2.0630 (2.5799)\tAccuracy 56.250 (52.973)\tTime 0.45\n",
      "Epoch: [1][419/704]\tLoss 2.1143 (2.5738)\tAccuracy 64.062 (53.043)\tTime 0.45\n",
      "Epoch: [1][429/704]\tLoss 2.1821 (2.5664)\tAccuracy 59.375 (53.209)\tTime 0.45\n",
      "Epoch: [1][439/704]\tLoss 2.5794 (2.5619)\tAccuracy 54.688 (53.313)\tTime 0.45\n",
      "Epoch: [1][449/704]\tLoss 2.1770 (2.5575)\tAccuracy 62.500 (53.434)\tTime 0.45\n",
      "Epoch: [1][459/704]\tLoss 2.2484 (2.5535)\tAccuracy 57.812 (53.529)\tTime 0.45\n",
      "Epoch: [1][469/704]\tLoss 1.9564 (2.5474)\tAccuracy 70.312 (53.670)\tTime 0.45\n",
      "Epoch: [1][479/704]\tLoss 2.6175 (2.5410)\tAccuracy 51.562 (53.799)\tTime 0.43\n",
      "Epoch: [1][489/704]\tLoss 2.1333 (2.5363)\tAccuracy 57.812 (53.900)\tTime 0.45\n",
      "Epoch: [1][499/704]\tLoss 2.2561 (2.5300)\tAccuracy 60.938 (54.003)\tTime 0.45\n",
      "Epoch: [1][509/704]\tLoss 2.1062 (2.5265)\tAccuracy 57.812 (54.038)\tTime 0.45\n",
      "Epoch: [1][519/704]\tLoss 1.9003 (2.5208)\tAccuracy 75.000 (54.165)\tTime 0.45\n",
      "Epoch: [1][529/704]\tLoss 2.5719 (2.5162)\tAccuracy 53.125 (54.290)\tTime 0.45\n",
      "Epoch: [1][539/704]\tLoss 2.3552 (2.5139)\tAccuracy 59.375 (54.369)\tTime 0.45\n",
      "Epoch: [1][549/704]\tLoss 2.0270 (2.5070)\tAccuracy 65.625 (54.500)\tTime 0.45\n",
      "Epoch: [1][559/704]\tLoss 2.3183 (2.5010)\tAccuracy 62.500 (54.660)\tTime 0.43\n",
      "Epoch: [1][569/704]\tLoss 2.1415 (2.4966)\tAccuracy 62.500 (54.734)\tTime 0.45\n",
      "Epoch: [1][579/704]\tLoss 2.1144 (2.4911)\tAccuracy 59.375 (54.828)\tTime 0.45\n",
      "Epoch: [1][589/704]\tLoss 1.6211 (2.4852)\tAccuracy 71.875 (54.979)\tTime 0.45\n",
      "Epoch: [1][599/704]\tLoss 1.9639 (2.4819)\tAccuracy 65.625 (55.060)\tTime 0.45\n",
      "Epoch: [1][609/704]\tLoss 1.6092 (2.4726)\tAccuracy 71.875 (55.259)\tTime 0.45\n",
      "Epoch: [1][619/704]\tLoss 2.6490 (2.4678)\tAccuracy 54.688 (55.378)\tTime 0.45\n",
      "Epoch: [1][629/704]\tLoss 1.9707 (2.4604)\tAccuracy 65.625 (55.526)\tTime 0.45\n",
      "Epoch: [1][639/704]\tLoss 2.1460 (2.4554)\tAccuracy 60.938 (55.576)\tTime 0.43\n",
      "Epoch: [1][649/704]\tLoss 1.9572 (2.4485)\tAccuracy 67.188 (55.721)\tTime 0.45\n",
      "Epoch: [1][659/704]\tLoss 2.0301 (2.4434)\tAccuracy 62.500 (55.824)\tTime 0.45\n",
      "Epoch: [1][669/704]\tLoss 2.1188 (2.4388)\tAccuracy 59.375 (55.886)\tTime 0.45\n",
      "Epoch: [1][679/704]\tLoss 1.9232 (2.4335)\tAccuracy 67.188 (56.020)\tTime 0.45\n",
      "Epoch: [1][689/704]\tLoss 1.7653 (2.4260)\tAccuracy 68.750 (56.166)\tTime 0.45\n",
      "Epoch: [1][699/704]\tLoss 2.3220 (2.4229)\tAccuracy 56.250 (56.254)\tTime 0.45\n",
      "train_accuracy 56.276\n",
      "one epoch duration:31.228317260742188\n",
      "Epoch #2, Learning rate: 0.01\n",
      "len(r_loader): 704, len(f_loader): 79\n",
      "Epoch: [2][9/704]\tLoss 1.9277 (1.9977)\tAccuracy 68.750 (63.750)\tTime 0.45\n",
      "Epoch: [2][19/704]\tLoss 1.8058 (1.9610)\tAccuracy 64.062 (64.453)\tTime 0.45\n",
      "Epoch: [2][29/704]\tLoss 2.1291 (1.9648)\tAccuracy 67.188 (64.844)\tTime 0.45\n",
      "Epoch: [2][39/704]\tLoss 1.7582 (1.9659)\tAccuracy 67.188 (64.961)\tTime 0.45\n",
      "Epoch: [2][49/704]\tLoss 2.0368 (1.9723)\tAccuracy 64.062 (64.938)\tTime 0.45\n",
      "Epoch: [2][59/704]\tLoss 1.8213 (1.9699)\tAccuracy 65.625 (64.870)\tTime 0.45\n",
      "Epoch: [2][69/704]\tLoss 1.8433 (1.9628)\tAccuracy 73.438 (65.089)\tTime 0.45\n",
      "Epoch: [2][79/704]\tLoss 2.2094 (1.9831)\tAccuracy 57.812 (64.727)\tTime 0.43\n",
      "Epoch: [2][89/704]\tLoss 2.3316 (1.9753)\tAccuracy 60.938 (64.878)\tTime 0.45\n",
      "Epoch: [2][99/704]\tLoss 1.7402 (1.9708)\tAccuracy 70.312 (64.969)\tTime 0.45\n",
      "Epoch: [2][109/704]\tLoss 1.6944 (1.9636)\tAccuracy 68.750 (64.986)\tTime 0.45\n",
      "Epoch: [2][119/704]\tLoss 1.7873 (1.9468)\tAccuracy 73.438 (65.469)\tTime 0.45\n",
      "Epoch: [2][129/704]\tLoss 1.8877 (1.9376)\tAccuracy 60.938 (65.577)\tTime 0.45\n",
      "Epoch: [2][139/704]\tLoss 1.7283 (1.9331)\tAccuracy 65.625 (65.402)\tTime 0.45\n",
      "Epoch: [2][149/704]\tLoss 1.9394 (1.9338)\tAccuracy 65.625 (65.406)\tTime 0.45\n",
      "Epoch: [2][159/704]\tLoss 2.1479 (1.9373)\tAccuracy 60.938 (65.381)\tTime 0.43\n",
      "Epoch: [2][169/704]\tLoss 1.6948 (1.9407)\tAccuracy 67.188 (65.257)\tTime 0.45\n",
      "Epoch: [2][179/704]\tLoss 1.9768 (1.9378)\tAccuracy 62.500 (65.339)\tTime 0.45\n",
      "Epoch: [2][189/704]\tLoss 2.0057 (1.9288)\tAccuracy 65.625 (65.518)\tTime 0.45\n",
      "Epoch: [2][199/704]\tLoss 1.6865 (1.9183)\tAccuracy 73.438 (65.766)\tTime 0.45\n",
      "Epoch: [2][209/704]\tLoss 1.6696 (1.9166)\tAccuracy 70.312 (65.751)\tTime 0.45\n",
      "Epoch: [2][219/704]\tLoss 1.8561 (1.9103)\tAccuracy 59.375 (65.710)\tTime 0.45\n",
      "Epoch: [2][229/704]\tLoss 1.5973 (1.9104)\tAccuracy 71.875 (65.802)\tTime 0.45\n",
      "Epoch: [2][239/704]\tLoss 1.3786 (1.9047)\tAccuracy 78.125 (65.859)\tTime 0.43\n",
      "Epoch: [2][249/704]\tLoss 1.7845 (1.8989)\tAccuracy 68.750 (65.963)\tTime 0.45\n",
      "Epoch: [2][259/704]\tLoss 1.3086 (1.8912)\tAccuracy 79.688 (66.082)\tTime 0.45\n",
      "Epoch: [2][269/704]\tLoss 2.1049 (1.8858)\tAccuracy 54.688 (66.186)\tTime 0.45\n",
      "Epoch: [2][279/704]\tLoss 1.7348 (1.8818)\tAccuracy 71.875 (66.323)\tTime 0.45\n",
      "Epoch: [2][289/704]\tLoss 1.7792 (1.8808)\tAccuracy 64.062 (66.342)\tTime 0.45\n",
      "Epoch: [2][299/704]\tLoss 1.6746 (1.8748)\tAccuracy 70.312 (66.495)\tTime 0.45\n",
      "Epoch: [2][309/704]\tLoss 1.9112 (1.8743)\tAccuracy 65.625 (66.497)\tTime 0.45\n",
      "Epoch: [2][319/704]\tLoss 2.3273 (1.9124)\tAccuracy 62.500 (66.235)\tTime 0.43\n",
      "Epoch: [2][329/704]\tLoss 2.2671 (1.9270)\tAccuracy 65.625 (66.089)\tTime 0.45\n",
      "Epoch: [2][339/704]\tLoss 1.8678 (1.9322)\tAccuracy 68.750 (65.960)\tTime 0.45\n",
      "Epoch: [2][349/704]\tLoss 1.9762 (1.9314)\tAccuracy 64.062 (65.951)\tTime 0.45\n",
      "Epoch: [2][359/704]\tLoss 1.7935 (1.9298)\tAccuracy 67.188 (65.994)\tTime 0.45\n",
      "Epoch: [2][369/704]\tLoss 1.8556 (1.9325)\tAccuracy 64.062 (65.887)\tTime 0.45\n",
      "Epoch: [2][379/704]\tLoss 1.9142 (1.9298)\tAccuracy 64.062 (65.946)\tTime 0.45\n",
      "Epoch: [2][389/704]\tLoss 1.9102 (1.9298)\tAccuracy 70.312 (65.998)\tTime 0.45\n",
      "Epoch: [2][399/704]\tLoss 1.5436 (1.9246)\tAccuracy 75.000 (66.090)\tTime 0.43\n",
      "Epoch: [2][409/704]\tLoss 1.6418 (1.9207)\tAccuracy 67.188 (66.181)\tTime 0.45\n",
      "Epoch: [2][419/704]\tLoss 1.6198 (1.9187)\tAccuracy 76.562 (66.231)\tTime 0.45\n",
      "Epoch: [2][429/704]\tLoss 2.0379 (1.9124)\tAccuracy 54.688 (66.363)\tTime 0.45\n",
      "Epoch: [2][439/704]\tLoss 1.9041 (1.9061)\tAccuracy 62.500 (66.445)\tTime 0.45\n",
      "Epoch: [2][449/704]\tLoss 1.7360 (1.8996)\tAccuracy 67.188 (66.583)\tTime 0.45\n",
      "Epoch: [2][459/704]\tLoss 1.6057 (1.8931)\tAccuracy 73.438 (66.698)\tTime 0.45\n",
      "Epoch: [2][469/704]\tLoss 1.4253 (1.8860)\tAccuracy 73.438 (66.818)\tTime 0.45\n",
      "Epoch: [2][479/704]\tLoss 1.9082 (1.8795)\tAccuracy 62.500 (66.976)\tTime 0.43\n",
      "Epoch: [2][489/704]\tLoss 1.9745 (1.8757)\tAccuracy 60.938 (66.999)\tTime 0.45\n",
      "Epoch: [2][499/704]\tLoss 1.4934 (1.8719)\tAccuracy 79.688 (67.072)\tTime 0.45\n",
      "Epoch: [2][509/704]\tLoss 1.4605 (1.8665)\tAccuracy 78.125 (67.200)\tTime 0.45\n",
      "Epoch: [2][519/704]\tLoss 1.5113 (1.8608)\tAccuracy 75.000 (67.302)\tTime 0.45\n",
      "Epoch: [2][529/704]\tLoss 2.0028 (1.8557)\tAccuracy 62.500 (67.406)\tTime 0.45\n",
      "Epoch: [2][539/704]\tLoss 1.9853 (1.8516)\tAccuracy 70.312 (67.494)\tTime 0.45\n",
      "Epoch: [2][549/704]\tLoss 1.5346 (1.8457)\tAccuracy 71.875 (67.611)\tTime 0.45\n",
      "Epoch: [2][559/704]\tLoss 1.4406 (1.8416)\tAccuracy 71.875 (67.656)\tTime 0.43\n",
      "Epoch: [2][569/704]\tLoss 2.0029 (1.8401)\tAccuracy 64.062 (67.654)\tTime 0.45\n",
      "Epoch: [2][579/704]\tLoss 1.8066 (1.8365)\tAccuracy 71.875 (67.734)\tTime 0.45\n",
      "Epoch: [2][589/704]\tLoss 1.0665 (1.8315)\tAccuracy 79.688 (67.823)\tTime 0.45\n",
      "Epoch: [2][599/704]\tLoss 1.8853 (1.8279)\tAccuracy 68.750 (67.898)\tTime 0.45\n",
      "Epoch: [2][609/704]\tLoss 1.3668 (1.8217)\tAccuracy 71.875 (68.025)\tTime 0.45\n",
      "Epoch: [2][619/704]\tLoss 1.6974 (1.8196)\tAccuracy 70.312 (68.072)\tTime 0.45\n",
      "Epoch: [2][629/704]\tLoss 1.5566 (1.8149)\tAccuracy 76.562 (68.147)\tTime 0.45\n",
      "Epoch: [2][639/704]\tLoss 1.7371 (1.8126)\tAccuracy 71.875 (68.184)\tTime 0.43\n",
      "Epoch: [2][649/704]\tLoss 1.3007 (1.8081)\tAccuracy 76.562 (68.274)\tTime 0.45\n",
      "Epoch: [2][659/704]\tLoss 1.9140 (1.8050)\tAccuracy 67.188 (68.338)\tTime 0.45\n",
      "Epoch: [2][669/704]\tLoss 1.7335 (1.8027)\tAccuracy 70.312 (68.386)\tTime 0.45\n",
      "Epoch: [2][679/704]\tLoss 1.5423 (1.7991)\tAccuracy 75.000 (68.477)\tTime 0.45\n",
      "Epoch: [2][689/704]\tLoss 1.5091 (1.7960)\tAccuracy 71.875 (68.533)\tTime 0.45\n",
      "Epoch: [2][699/704]\tLoss 1.8031 (1.7921)\tAccuracy 71.875 (68.618)\tTime 0.45\n",
      "train_accuracy 68.627\n",
      "one epoch duration:31.417977809906006\n",
      "Epoch #3, Learning rate: 0.01\n",
      "len(r_loader): 704, len(f_loader): 79\n",
      "Epoch: [3][9/704]\tLoss 1.8664 (1.4657)\tAccuracy 64.062 (72.969)\tTime 0.45\n",
      "Epoch: [3][19/704]\tLoss 1.5059 (1.5132)\tAccuracy 76.562 (72.969)\tTime 0.45\n",
      "Epoch: [3][29/704]\tLoss 1.3800 (1.4696)\tAccuracy 71.875 (74.219)\tTime 0.45\n",
      "Epoch: [3][39/704]\tLoss 1.3311 (1.4777)\tAccuracy 76.562 (74.141)\tTime 0.45\n",
      "Epoch: [3][49/704]\tLoss 1.5831 (1.4645)\tAccuracy 73.438 (74.344)\tTime 0.45\n",
      "Epoch: [3][59/704]\tLoss 1.3545 (1.4312)\tAccuracy 75.000 (74.948)\tTime 0.45\n",
      "Epoch: [3][69/704]\tLoss 1.5157 (1.4336)\tAccuracy 73.438 (74.955)\tTime 0.45\n",
      "Epoch: [3][79/704]\tLoss 1.3333 (1.4314)\tAccuracy 76.562 (75.137)\tTime 0.43\n",
      "Epoch: [3][89/704]\tLoss 1.4948 (1.4156)\tAccuracy 71.875 (75.330)\tTime 0.45\n",
      "Epoch: [3][99/704]\tLoss 1.1677 (1.4262)\tAccuracy 76.562 (75.141)\tTime 0.45\n",
      "Epoch: [3][109/704]\tLoss 1.2430 (1.4213)\tAccuracy 76.562 (75.298)\tTime 0.45\n",
      "Epoch: [3][119/704]\tLoss 1.0056 (1.4262)\tAccuracy 82.812 (75.247)\tTime 0.45\n",
      "Epoch: [3][129/704]\tLoss 1.5249 (1.4218)\tAccuracy 70.312 (75.264)\tTime 0.45\n",
      "Epoch: [3][139/704]\tLoss 1.2944 (1.4213)\tAccuracy 76.562 (75.156)\tTime 0.45\n",
      "Epoch: [3][149/704]\tLoss 1.8585 (1.4182)\tAccuracy 68.750 (75.083)\tTime 0.45\n",
      "Epoch: [3][159/704]\tLoss 1.5488 (1.4109)\tAccuracy 73.438 (75.195)\tTime 0.43\n",
      "Epoch: [3][169/704]\tLoss 1.3003 (1.4083)\tAccuracy 76.562 (75.312)\tTime 0.45\n",
      "Epoch: [3][179/704]\tLoss 1.5384 (1.4070)\tAccuracy 71.875 (75.321)\tTime 0.45\n",
      "Epoch: [3][189/704]\tLoss 1.2339 (1.4056)\tAccuracy 82.812 (75.362)\tTime 0.45\n",
      "Epoch: [3][199/704]\tLoss 1.0913 (1.4012)\tAccuracy 79.688 (75.336)\tTime 0.45\n",
      "Epoch: [3][209/704]\tLoss 1.4284 (1.4021)\tAccuracy 81.250 (75.357)\tTime 0.45\n",
      "Epoch: [3][219/704]\tLoss 1.4531 (1.4011)\tAccuracy 75.000 (75.369)\tTime 0.45\n",
      "Epoch: [3][229/704]\tLoss 1.1381 (1.4057)\tAccuracy 84.375 (75.333)\tTime 0.45\n",
      "Epoch: [3][239/704]\tLoss 1.3200 (1.4019)\tAccuracy 78.125 (75.371)\tTime 0.43\n",
      "Epoch: [3][249/704]\tLoss 1.3392 (1.3976)\tAccuracy 71.875 (75.419)\tTime 0.45\n",
      "Epoch: [3][259/704]\tLoss 1.5595 (1.3925)\tAccuracy 68.750 (75.535)\tTime 0.45\n",
      "Epoch: [3][269/704]\tLoss 0.8360 (1.3864)\tAccuracy 81.250 (75.637)\tTime 0.45\n",
      "Epoch: [3][279/704]\tLoss 1.7385 (1.3872)\tAccuracy 73.438 (75.619)\tTime 0.45\n",
      "Epoch: [3][289/704]\tLoss 1.2328 (1.3841)\tAccuracy 79.688 (75.657)\tTime 0.45\n",
      "Epoch: [3][299/704]\tLoss 1.5755 (1.3817)\tAccuracy 71.875 (75.682)\tTime 0.45\n",
      "Epoch: [3][309/704]\tLoss 0.8964 (1.3783)\tAccuracy 89.062 (75.736)\tTime 0.45\n",
      "Epoch: [3][319/704]\tLoss 1.0572 (1.3754)\tAccuracy 82.812 (75.781)\tTime 0.43\n",
      "Epoch: [3][329/704]\tLoss 1.0939 (1.3727)\tAccuracy 79.688 (75.866)\tTime 0.45\n",
      "Epoch: [3][339/704]\tLoss 1.3547 (1.3751)\tAccuracy 79.688 (75.832)\tTime 0.45\n",
      "Epoch: [3][349/704]\tLoss 1.5116 (1.3746)\tAccuracy 64.062 (75.768)\tTime 0.45\n",
      "Epoch: [3][359/704]\tLoss 1.1730 (1.3704)\tAccuracy 79.688 (75.885)\tTime 0.45\n",
      "Epoch: [3][369/704]\tLoss 1.6459 (1.3708)\tAccuracy 67.188 (75.819)\tTime 0.45\n",
      "Epoch: [3][379/704]\tLoss 1.6720 (1.3723)\tAccuracy 78.125 (75.851)\tTime 0.45\n",
      "Epoch: [3][389/704]\tLoss 1.3144 (1.3746)\tAccuracy 76.562 (75.789)\tTime 0.45\n",
      "Epoch: [3][399/704]\tLoss 1.5193 (1.3758)\tAccuracy 75.000 (75.750)\tTime 0.43\n",
      "Epoch: [3][409/704]\tLoss 1.2623 (1.3745)\tAccuracy 71.875 (75.789)\tTime 0.45\n",
      "Epoch: [3][419/704]\tLoss 1.3698 (1.3707)\tAccuracy 71.875 (75.867)\tTime 0.45\n",
      "Epoch: [3][429/704]\tLoss 1.1273 (1.3707)\tAccuracy 78.125 (75.850)\tTime 0.45\n",
      "Epoch: [3][439/704]\tLoss 1.5083 (1.3702)\tAccuracy 78.125 (75.852)\tTime 0.45\n",
      "Epoch: [3][449/704]\tLoss 1.0095 (1.3681)\tAccuracy 82.812 (75.910)\tTime 0.45\n",
      "Epoch: [3][459/704]\tLoss 1.3832 (1.3660)\tAccuracy 76.562 (75.921)\tTime 0.45\n",
      "Epoch: [3][469/704]\tLoss 1.2204 (1.3633)\tAccuracy 76.562 (75.941)\tTime 0.45\n",
      "Epoch: [3][479/704]\tLoss 1.7056 (1.3646)\tAccuracy 65.625 (75.924)\tTime 0.43\n",
      "Epoch: [3][489/704]\tLoss 0.9113 (1.3603)\tAccuracy 85.938 (76.027)\tTime 0.45\n",
      "Epoch: [3][499/704]\tLoss 1.5002 (1.3590)\tAccuracy 67.188 (76.031)\tTime 0.45\n",
      "Epoch: [3][509/704]\tLoss 1.2215 (1.3580)\tAccuracy 78.125 (76.063)\tTime 0.45\n",
      "Epoch: [3][519/704]\tLoss 1.3914 (1.3569)\tAccuracy 76.562 (76.067)\tTime 0.45\n",
      "Epoch: [3][529/704]\tLoss 1.2549 (1.3564)\tAccuracy 78.125 (76.079)\tTime 0.45\n",
      "Epoch: [3][539/704]\tLoss 0.9869 (1.3546)\tAccuracy 85.938 (76.120)\tTime 0.45\n",
      "Epoch: [3][549/704]\tLoss 1.2622 (1.3537)\tAccuracy 75.000 (76.142)\tTime 0.45\n",
      "Epoch: [3][559/704]\tLoss 1.0792 (1.3521)\tAccuracy 84.375 (76.189)\tTime 0.43\n",
      "Epoch: [3][569/704]\tLoss 1.0880 (1.3500)\tAccuracy 78.125 (76.220)\tTime 0.45\n",
      "Epoch: [3][579/704]\tLoss 1.3843 (1.3491)\tAccuracy 73.438 (76.231)\tTime 0.45\n",
      "Epoch: [3][589/704]\tLoss 1.3945 (1.3491)\tAccuracy 70.312 (76.221)\tTime 0.45\n",
      "Epoch: [3][599/704]\tLoss 1.5941 (1.3492)\tAccuracy 70.312 (76.240)\tTime 0.45\n",
      "Epoch: [3][609/704]\tLoss 1.4532 (1.3475)\tAccuracy 75.000 (76.286)\tTime 0.45\n",
      "Epoch: [3][619/704]\tLoss 1.3099 (1.3472)\tAccuracy 76.562 (76.280)\tTime 0.45\n",
      "Epoch: [3][629/704]\tLoss 1.2418 (1.3447)\tAccuracy 75.000 (76.314)\tTime 0.45\n",
      "Epoch: [3][639/704]\tLoss 1.5252 (1.3437)\tAccuracy 78.125 (76.355)\tTime 0.43\n",
      "Epoch: [3][649/704]\tLoss 1.2946 (1.3424)\tAccuracy 84.375 (76.392)\tTime 0.45\n",
      "Epoch: [3][659/704]\tLoss 1.2126 (1.3408)\tAccuracy 78.125 (76.432)\tTime 0.45\n",
      "Epoch: [3][669/704]\tLoss 1.1552 (1.3400)\tAccuracy 81.250 (76.483)\tTime 0.45\n",
      "Epoch: [3][679/704]\tLoss 1.4869 (1.3388)\tAccuracy 71.875 (76.510)\tTime 0.45\n",
      "Epoch: [3][689/704]\tLoss 1.5245 (1.3365)\tAccuracy 68.750 (76.574)\tTime 0.45\n",
      "Epoch: [3][699/704]\tLoss 1.1905 (1.3350)\tAccuracy 81.250 (76.569)\tTime 0.45\n",
      "train_accuracy 76.567\n",
      "one epoch duration:31.514988660812378\n",
      "Epoch #4, Learning rate: 0.01\n",
      "len(r_loader): 704, len(f_loader): 79\n",
      "Epoch: [4][9/704]\tLoss 0.7817 (1.1016)\tAccuracy 90.625 (81.875)\tTime 0.45\n",
      "Epoch: [4][19/704]\tLoss 1.3480 (1.1475)\tAccuracy 76.562 (80.859)\tTime 0.45\n",
      "Epoch: [4][29/704]\tLoss 0.7593 (1.1339)\tAccuracy 92.188 (80.885)\tTime 0.45\n",
      "Epoch: [4][39/704]\tLoss 0.8272 (1.1240)\tAccuracy 85.938 (80.977)\tTime 0.45\n",
      "Epoch: [4][49/704]\tLoss 1.3666 (1.1314)\tAccuracy 79.688 (80.531)\tTime 0.45\n",
      "Epoch: [4][59/704]\tLoss 1.0267 (1.1221)\tAccuracy 82.812 (80.938)\tTime 0.45\n",
      "Epoch: [4][69/704]\tLoss 1.0624 (1.1285)\tAccuracy 78.125 (80.692)\tTime 0.45\n",
      "Epoch: [4][79/704]\tLoss 1.4685 (1.1408)\tAccuracy 79.688 (80.508)\tTime 0.44\n",
      "Epoch: [4][89/704]\tLoss 1.3597 (1.1471)\tAccuracy 75.000 (80.330)\tTime 0.45\n",
      "Epoch: [4][99/704]\tLoss 0.8533 (1.1374)\tAccuracy 78.125 (80.594)\tTime 0.45\n",
      "Epoch: [4][109/704]\tLoss 1.2776 (1.1492)\tAccuracy 73.438 (80.426)\tTime 0.45\n",
      "Epoch: [4][119/704]\tLoss 1.1085 (1.1524)\tAccuracy 82.812 (80.234)\tTime 0.45\n",
      "Epoch: [4][129/704]\tLoss 1.4194 (1.1539)\tAccuracy 73.438 (80.192)\tTime 0.45\n",
      "Epoch: [4][139/704]\tLoss 1.1927 (1.1486)\tAccuracy 78.125 (80.268)\tTime 0.45\n",
      "Epoch: [4][149/704]\tLoss 1.0424 (1.1470)\tAccuracy 84.375 (80.323)\tTime 0.45\n",
      "Epoch: [4][159/704]\tLoss 1.0044 (1.1433)\tAccuracy 85.938 (80.381)\tTime 0.44\n",
      "Epoch: [4][169/704]\tLoss 1.0665 (1.1393)\tAccuracy 84.375 (80.515)\tTime 0.45\n",
      "Epoch: [4][179/704]\tLoss 1.1462 (1.1370)\tAccuracy 82.812 (80.582)\tTime 0.45\n",
      "Epoch: [4][189/704]\tLoss 1.0612 (1.1293)\tAccuracy 79.688 (80.674)\tTime 0.45\n",
      "Epoch: [4][199/704]\tLoss 1.3852 (1.1309)\tAccuracy 75.000 (80.586)\tTime 0.45\n",
      "Epoch: [4][209/704]\tLoss 1.2494 (1.1306)\tAccuracy 76.562 (80.588)\tTime 0.45\n",
      "Epoch: [4][219/704]\tLoss 0.9321 (1.1312)\tAccuracy 79.688 (80.490)\tTime 0.45\n",
      "Epoch: [4][229/704]\tLoss 1.0479 (1.1310)\tAccuracy 84.375 (80.503)\tTime 0.45\n",
      "Epoch: [4][239/704]\tLoss 1.5729 (1.1299)\tAccuracy 75.000 (80.566)\tTime 0.44\n",
      "Epoch: [4][249/704]\tLoss 0.9378 (1.1298)\tAccuracy 89.062 (80.612)\tTime 0.45\n",
      "Epoch: [4][259/704]\tLoss 0.7606 (1.1272)\tAccuracy 92.188 (80.673)\tTime 0.46\n",
      "Epoch: [4][269/704]\tLoss 1.0797 (1.1281)\tAccuracy 81.250 (80.666)\tTime 0.45\n",
      "Epoch: [4][279/704]\tLoss 0.9218 (1.1260)\tAccuracy 84.375 (80.670)\tTime 0.45\n",
      "Epoch: [4][289/704]\tLoss 1.3032 (1.1254)\tAccuracy 79.688 (80.668)\tTime 0.45\n",
      "Epoch: [4][299/704]\tLoss 1.3048 (1.1237)\tAccuracy 78.125 (80.703)\tTime 0.45\n",
      "Epoch: [4][309/704]\tLoss 1.2860 (1.1260)\tAccuracy 78.125 (80.685)\tTime 0.45\n",
      "Epoch: [4][319/704]\tLoss 1.0112 (1.1257)\tAccuracy 79.688 (80.664)\tTime 0.44\n",
      "Epoch: [4][329/704]\tLoss 0.8768 (1.1255)\tAccuracy 84.375 (80.720)\tTime 0.45\n",
      "Epoch: [4][339/704]\tLoss 1.0051 (1.1217)\tAccuracy 82.812 (80.749)\tTime 0.45\n",
      "Epoch: [4][349/704]\tLoss 1.7113 (1.1240)\tAccuracy 65.625 (80.688)\tTime 0.45\n",
      "Epoch: [4][359/704]\tLoss 1.1369 (1.1216)\tAccuracy 79.688 (80.755)\tTime 0.45\n",
      "Epoch: [4][369/704]\tLoss 1.0347 (1.1204)\tAccuracy 78.125 (80.773)\tTime 0.45\n",
      "Epoch: [4][379/704]\tLoss 1.3540 (1.1211)\tAccuracy 78.125 (80.724)\tTime 0.45\n",
      "Epoch: [4][389/704]\tLoss 0.8475 (1.1244)\tAccuracy 89.062 (80.677)\tTime 0.46\n",
      "Epoch: [4][399/704]\tLoss 1.2012 (1.1249)\tAccuracy 84.375 (80.680)\tTime 0.44\n",
      "Epoch: [4][409/704]\tLoss 1.1022 (1.1240)\tAccuracy 82.812 (80.705)\tTime 0.46\n",
      "Epoch: [4][419/704]\tLoss 0.8612 (1.1242)\tAccuracy 85.938 (80.685)\tTime 0.45\n",
      "Epoch: [4][429/704]\tLoss 1.2632 (1.1252)\tAccuracy 82.812 (80.683)\tTime 0.45\n",
      "Epoch: [4][439/704]\tLoss 0.9679 (1.1236)\tAccuracy 87.500 (80.742)\tTime 0.46\n",
      "Epoch: [4][449/704]\tLoss 1.4043 (1.1203)\tAccuracy 75.000 (80.788)\tTime 0.46\n",
      "Epoch: [4][459/704]\tLoss 0.7057 (1.1177)\tAccuracy 87.500 (80.825)\tTime 0.45\n",
      "Epoch: [4][469/704]\tLoss 0.8040 (1.1185)\tAccuracy 85.938 (80.805)\tTime 0.45\n",
      "Epoch: [4][479/704]\tLoss 0.6883 (1.1161)\tAccuracy 85.938 (80.869)\tTime 0.44\n",
      "Epoch: [4][489/704]\tLoss 1.0479 (1.1149)\tAccuracy 82.812 (80.890)\tTime 0.45\n",
      "Epoch: [4][499/704]\tLoss 1.3460 (1.1151)\tAccuracy 73.438 (80.881)\tTime 0.45\n",
      "Epoch: [4][509/704]\tLoss 1.1388 (1.1133)\tAccuracy 79.688 (80.913)\tTime 0.45\n",
      "Epoch: [4][519/704]\tLoss 0.9740 (1.1141)\tAccuracy 79.688 (80.916)\tTime 0.46\n",
      "Epoch: [4][529/704]\tLoss 1.5860 (1.1161)\tAccuracy 76.562 (80.887)\tTime 0.45\n",
      "Epoch: [4][539/704]\tLoss 1.2755 (1.1166)\tAccuracy 79.688 (80.859)\tTime 0.45\n",
      "Epoch: [4][549/704]\tLoss 1.2202 (1.1188)\tAccuracy 76.562 (80.812)\tTime 0.45\n",
      "Epoch: [4][559/704]\tLoss 1.5433 (1.1215)\tAccuracy 71.875 (80.784)\tTime 0.44\n",
      "Epoch: [4][569/704]\tLoss 0.7250 (1.1181)\tAccuracy 87.500 (80.861)\tTime 0.45\n",
      "Epoch: [4][579/704]\tLoss 0.8158 (1.1191)\tAccuracy 81.250 (80.822)\tTime 0.45\n",
      "Epoch: [4][589/704]\tLoss 1.2342 (1.1173)\tAccuracy 79.688 (80.847)\tTime 0.46\n",
      "Epoch: [4][599/704]\tLoss 1.2804 (1.1178)\tAccuracy 76.562 (80.849)\tTime 0.45\n",
      "Epoch: [4][609/704]\tLoss 1.1165 (1.1165)\tAccuracy 82.812 (80.902)\tTime 0.45\n",
      "Epoch: [4][619/704]\tLoss 1.1563 (1.1154)\tAccuracy 79.688 (80.927)\tTime 0.45\n",
      "Epoch: [4][629/704]\tLoss 1.1367 (1.1154)\tAccuracy 81.250 (80.960)\tTime 0.46\n",
      "Epoch: [4][639/704]\tLoss 2.0091 (1.1395)\tAccuracy 70.312 (80.747)\tTime 0.44\n",
      "Epoch: [4][649/704]\tLoss 1.8247 (1.1749)\tAccuracy 70.312 (80.481)\tTime 0.45\n",
      "Epoch: [4][659/704]\tLoss 1.5647 (1.1857)\tAccuracy 75.000 (80.424)\tTime 0.46\n",
      "Epoch: [4][669/704]\tLoss 1.4629 (1.1914)\tAccuracy 78.125 (80.375)\tTime 0.46\n",
      "Epoch: [4][679/704]\tLoss 1.3422 (1.1936)\tAccuracy 82.812 (80.363)\tTime 0.45\n",
      "Epoch: [4][689/704]\tLoss 1.1387 (1.1942)\tAccuracy 84.375 (80.376)\tTime 0.46\n",
      "Epoch: [4][699/704]\tLoss 1.3243 (1.1948)\tAccuracy 79.688 (80.382)\tTime 0.45\n",
      "train_accuracy 80.384\n",
      "one epoch duration:31.77829384803772\n",
      "Epoch #5, Learning rate: 0.01\n",
      "len(r_loader): 704, len(f_loader): 79\n",
      "Epoch: [5][9/704]\tLoss 1.4736 (1.2453)\tAccuracy 73.438 (79.375)\tTime 0.46\n",
      "Epoch: [5][19/704]\tLoss 1.3966 (1.1941)\tAccuracy 73.438 (80.547)\tTime 0.46\n",
      "Epoch: [5][29/704]\tLoss 1.1602 (1.1821)\tAccuracy 81.250 (80.260)\tTime 0.46\n",
      "Epoch: [5][39/704]\tLoss 1.5849 (1.1767)\tAccuracy 78.125 (80.977)\tTime 0.46\n",
      "Epoch: [5][49/704]\tLoss 0.8737 (1.1376)\tAccuracy 87.500 (81.594)\tTime 0.46\n",
      "Epoch: [5][59/704]\tLoss 1.4845 (1.1255)\tAccuracy 75.000 (81.641)\tTime 0.46\n",
      "Epoch: [5][69/704]\tLoss 0.7203 (1.1175)\tAccuracy 85.938 (81.696)\tTime 0.46\n",
      "Epoch: [5][79/704]\tLoss 1.1449 (1.1112)\tAccuracy 82.812 (81.895)\tTime 0.44\n",
      "Epoch: [5][89/704]\tLoss 0.7968 (1.1016)\tAccuracy 85.938 (81.875)\tTime 0.45\n",
      "Epoch: [5][99/704]\tLoss 1.0169 (1.1024)\tAccuracy 87.500 (81.844)\tTime 0.46\n",
      "Epoch: [5][109/704]\tLoss 0.9245 (1.0892)\tAccuracy 85.938 (82.074)\tTime 0.45\n",
      "Epoch: [5][119/704]\tLoss 0.9758 (1.0891)\tAccuracy 85.938 (81.914)\tTime 0.45\n",
      "Epoch: [5][129/704]\tLoss 1.0471 (1.0838)\tAccuracy 81.250 (81.935)\tTime 0.45\n",
      "Epoch: [5][139/704]\tLoss 0.9136 (1.0778)\tAccuracy 79.688 (81.975)\tTime 0.46\n",
      "Epoch: [5][149/704]\tLoss 0.9892 (1.0756)\tAccuracy 79.688 (81.917)\tTime 0.45\n",
      "Epoch: [5][159/704]\tLoss 0.6394 (1.0718)\tAccuracy 87.500 (81.885)\tTime 0.44\n",
      "Epoch: [5][169/704]\tLoss 1.1485 (1.0657)\tAccuracy 75.000 (81.976)\tTime 0.46\n",
      "Epoch: [5][179/704]\tLoss 1.0837 (1.0617)\tAccuracy 79.688 (82.014)\tTime 0.46\n",
      "Epoch: [5][189/704]\tLoss 0.7984 (1.0570)\tAccuracy 84.375 (82.056)\tTime 0.46\n",
      "Epoch: [5][199/704]\tLoss 0.7584 (1.0526)\tAccuracy 90.625 (82.102)\tTime 0.45\n",
      "Epoch: [5][209/704]\tLoss 0.8249 (1.0489)\tAccuracy 85.938 (82.068)\tTime 0.46\n",
      "Epoch: [5][219/704]\tLoss 0.8967 (1.0447)\tAccuracy 84.375 (82.131)\tTime 0.46\n",
      "Epoch: [5][229/704]\tLoss 0.6467 (1.0424)\tAccuracy 92.188 (82.201)\tTime 0.45\n",
      "Epoch: [5][239/704]\tLoss 0.6981 (1.0386)\tAccuracy 90.625 (82.285)\tTime 0.44\n",
      "Epoch: [5][249/704]\tLoss 0.7078 (1.0351)\tAccuracy 87.500 (82.338)\tTime 0.45\n",
      "Epoch: [5][259/704]\tLoss 1.0625 (1.0335)\tAccuracy 81.250 (82.410)\tTime 0.46\n",
      "Epoch: [5][269/704]\tLoss 0.6339 (1.0320)\tAccuracy 89.062 (82.483)\tTime 0.45\n",
      "Epoch: [5][279/704]\tLoss 0.6085 (1.0291)\tAccuracy 93.750 (82.522)\tTime 0.45\n",
      "Epoch: [5][289/704]\tLoss 0.9097 (1.0246)\tAccuracy 85.938 (82.581)\tTime 0.46\n",
      "Epoch: [5][299/704]\tLoss 0.9942 (1.0212)\tAccuracy 82.812 (82.698)\tTime 0.45\n",
      "Epoch: [5][309/704]\tLoss 0.6961 (1.0183)\tAccuracy 85.938 (82.686)\tTime 0.45\n",
      "Epoch: [5][319/704]\tLoss 0.7916 (1.0168)\tAccuracy 84.375 (82.695)\tTime 0.44\n",
      "Epoch: [5][329/704]\tLoss 1.0742 (1.0190)\tAccuracy 79.688 (82.614)\tTime 0.46\n",
      "Epoch: [5][339/704]\tLoss 0.9487 (1.0163)\tAccuracy 84.375 (82.638)\tTime 0.46\n",
      "Epoch: [5][349/704]\tLoss 0.6786 (1.0123)\tAccuracy 87.500 (82.723)\tTime 0.45\n",
      "Epoch: [5][359/704]\tLoss 0.6764 (1.0099)\tAccuracy 85.938 (82.769)\tTime 0.46\n",
      "Epoch: [5][369/704]\tLoss 0.7334 (1.0069)\tAccuracy 87.500 (82.791)\tTime 0.46\n",
      "Epoch: [5][379/704]\tLoss 1.3715 (1.0103)\tAccuracy 75.000 (82.710)\tTime 0.46\n",
      "Epoch: [5][389/704]\tLoss 1.1820 (1.0115)\tAccuracy 82.812 (82.676)\tTime 0.46\n",
      "Epoch: [5][399/704]\tLoss 0.8830 (1.0084)\tAccuracy 84.375 (82.727)\tTime 0.43\n",
      "Epoch: [5][409/704]\tLoss 0.7832 (1.0076)\tAccuracy 87.500 (82.752)\tTime 0.46\n",
      "Epoch: [5][419/704]\tLoss 0.9425 (1.0074)\tAccuracy 82.812 (82.783)\tTime 0.46\n",
      "Epoch: [5][429/704]\tLoss 0.9728 (1.0047)\tAccuracy 82.812 (82.812)\tTime 0.45\n",
      "Epoch: [5][439/704]\tLoss 0.9222 (1.0054)\tAccuracy 82.812 (82.795)\tTime 0.46\n",
      "Epoch: [5][449/704]\tLoss 1.1940 (1.0030)\tAccuracy 79.688 (82.854)\tTime 0.46\n",
      "Epoch: [5][459/704]\tLoss 1.0663 (1.0019)\tAccuracy 81.250 (82.877)\tTime 0.46\n",
      "Epoch: [5][469/704]\tLoss 0.9429 (1.0016)\tAccuracy 87.500 (82.909)\tTime 0.46\n",
      "Epoch: [5][479/704]\tLoss 0.8116 (0.9995)\tAccuracy 84.375 (82.982)\tTime 0.44\n",
      "Epoch: [5][489/704]\tLoss 1.1621 (0.9977)\tAccuracy 81.250 (82.997)\tTime 0.45\n",
      "Epoch: [5][499/704]\tLoss 0.8363 (0.9966)\tAccuracy 84.375 (83.006)\tTime 0.45\n",
      "Epoch: [5][509/704]\tLoss 0.9509 (0.9957)\tAccuracy 82.812 (83.027)\tTime 0.46\n",
      "Epoch: [5][519/704]\tLoss 1.8286 (0.9949)\tAccuracy 71.875 (83.068)\tTime 0.45\n",
      "Epoch: [5][529/704]\tLoss 0.7391 (0.9944)\tAccuracy 87.500 (83.040)\tTime 0.46\n",
      "Epoch: [5][539/704]\tLoss 0.7031 (0.9923)\tAccuracy 87.500 (83.058)\tTime 0.46\n",
      "Epoch: [5][549/704]\tLoss 0.4649 (0.9882)\tAccuracy 92.188 (83.136)\tTime 0.46\n",
      "Epoch: [5][559/704]\tLoss 0.8702 (0.9869)\tAccuracy 84.375 (83.125)\tTime 0.45\n",
      "Epoch: [5][569/704]\tLoss 1.1417 (0.9866)\tAccuracy 85.938 (83.122)\tTime 0.46\n",
      "Epoch: [5][579/704]\tLoss 0.9097 (0.9830)\tAccuracy 85.938 (83.198)\tTime 0.46\n",
      "Epoch: [5][589/704]\tLoss 0.7235 (0.9806)\tAccuracy 89.062 (83.228)\tTime 0.46\n",
      "Epoch: [5][599/704]\tLoss 0.4933 (0.9782)\tAccuracy 90.625 (83.263)\tTime 0.46\n",
      "Epoch: [5][609/704]\tLoss 0.7480 (0.9763)\tAccuracy 92.188 (83.309)\tTime 0.46\n",
      "Epoch: [5][619/704]\tLoss 0.6096 (0.9752)\tAccuracy 87.500 (83.281)\tTime 0.46\n",
      "Epoch: [5][629/704]\tLoss 0.5661 (0.9728)\tAccuracy 89.062 (83.338)\tTime 0.46\n",
      "Epoch: [5][639/704]\tLoss 1.0257 (0.9726)\tAccuracy 81.250 (83.337)\tTime 0.44\n",
      "Epoch: [5][649/704]\tLoss 1.2690 (0.9730)\tAccuracy 73.438 (83.339)\tTime 0.46\n",
      "Epoch: [5][659/704]\tLoss 0.9016 (0.9710)\tAccuracy 87.500 (83.388)\tTime 0.46\n",
      "Epoch: [5][669/704]\tLoss 1.1555 (0.9707)\tAccuracy 71.875 (83.377)\tTime 0.45\n",
      "Epoch: [5][679/704]\tLoss 1.0529 (0.9699)\tAccuracy 82.812 (83.396)\tTime 0.45\n",
      "Epoch: [5][689/704]\tLoss 0.6543 (0.9681)\tAccuracy 92.188 (83.444)\tTime 0.46\n",
      "Epoch: [5][699/704]\tLoss 0.7610 (0.9662)\tAccuracy 87.500 (83.464)\tTime 0.46\n",
      "train_accuracy 83.476\n",
      "one epoch duration:31.98268961906433\n",
      "Epoch #6, Learning rate: 0.01\n",
      "len(r_loader): 704, len(f_loader): 79\n",
      "Epoch: [6][9/704]\tLoss 0.5539 (0.8021)\tAccuracy 92.188 (86.094)\tTime 0.46\n",
      "Epoch: [6][19/704]\tLoss 0.6951 (0.8495)\tAccuracy 92.188 (85.547)\tTime 0.46\n",
      "Epoch: [6][29/704]\tLoss 0.5411 (0.8092)\tAccuracy 95.312 (86.667)\tTime 0.46\n",
      "Epoch: [6][39/704]\tLoss 0.9028 (0.7853)\tAccuracy 84.375 (87.461)\tTime 0.46\n",
      "Epoch: [6][49/704]\tLoss 0.6012 (0.7775)\tAccuracy 89.062 (87.344)\tTime 0.46\n",
      "Epoch: [6][59/704]\tLoss 0.6005 (0.7723)\tAccuracy 92.188 (87.188)\tTime 0.46\n",
      "Epoch: [6][69/704]\tLoss 0.6697 (0.7676)\tAccuracy 89.062 (87.232)\tTime 0.46\n",
      "Epoch: [6][79/704]\tLoss 0.7027 (0.7805)\tAccuracy 87.500 (86.992)\tTime 0.44\n",
      "Epoch: [6][89/704]\tLoss 0.5700 (0.7729)\tAccuracy 95.312 (87.031)\tTime 0.46\n",
      "Epoch: [6][99/704]\tLoss 0.5950 (0.7690)\tAccuracy 87.500 (86.875)\tTime 0.46\n",
      "Epoch: [6][109/704]\tLoss 0.5933 (0.7838)\tAccuracy 89.062 (86.378)\tTime 0.46\n",
      "Epoch: [6][119/704]\tLoss 1.0407 (0.7872)\tAccuracy 84.375 (86.289)\tTime 0.46\n",
      "Epoch: [6][129/704]\tLoss 0.6817 (0.7880)\tAccuracy 85.938 (86.214)\tTime 0.46\n",
      "Epoch: [6][139/704]\tLoss 1.3041 (0.7909)\tAccuracy 78.125 (86.161)\tTime 0.46\n",
      "Epoch: [6][149/704]\tLoss 0.8499 (0.7889)\tAccuracy 84.375 (86.115)\tTime 0.46\n",
      "Epoch: [6][159/704]\tLoss 0.7656 (0.7873)\tAccuracy 85.938 (86.289)\tTime 0.44\n",
      "Epoch: [6][169/704]\tLoss 1.2262 (0.7919)\tAccuracy 79.688 (86.241)\tTime 0.46\n",
      "Epoch: [6][179/704]\tLoss 0.6560 (0.7925)\tAccuracy 90.625 (86.259)\tTime 0.46\n",
      "Epoch: [6][189/704]\tLoss 0.9482 (0.7960)\tAccuracy 85.938 (86.184)\tTime 0.46\n",
      "Epoch: [6][199/704]\tLoss 1.1623 (0.7994)\tAccuracy 81.250 (86.180)\tTime 0.45\n",
      "Epoch: [6][209/704]\tLoss 0.6124 (0.7955)\tAccuracy 89.062 (86.243)\tTime 0.45\n",
      "Epoch: [6][219/704]\tLoss 0.9148 (0.8014)\tAccuracy 82.812 (86.186)\tTime 0.46\n",
      "Epoch: [6][229/704]\tLoss 0.6476 (0.8005)\tAccuracy 85.938 (86.209)\tTime 0.45\n",
      "Epoch: [6][239/704]\tLoss 0.8581 (0.7984)\tAccuracy 85.938 (86.257)\tTime 0.44\n",
      "Epoch: [6][249/704]\tLoss 0.6364 (0.7978)\tAccuracy 82.812 (86.213)\tTime 0.46\n",
      "Epoch: [6][259/704]\tLoss 0.7131 (0.8024)\tAccuracy 79.688 (86.070)\tTime 0.46\n",
      "Epoch: [6][269/704]\tLoss 0.5107 (0.8048)\tAccuracy 92.188 (86.059)\tTime 0.46\n",
      "Epoch: [6][279/704]\tLoss 0.5441 (0.8081)\tAccuracy 92.188 (85.977)\tTime 0.46\n",
      "Epoch: [6][289/704]\tLoss 1.1489 (0.8082)\tAccuracy 81.250 (86.029)\tTime 0.46\n",
      "Epoch: [6][299/704]\tLoss 0.7973 (0.8073)\tAccuracy 89.062 (86.078)\tTime 0.45\n",
      "Epoch: [6][309/704]\tLoss 0.5549 (0.8065)\tAccuracy 90.625 (86.089)\tTime 0.46\n",
      "Epoch: [6][319/704]\tLoss 0.7937 (0.8029)\tAccuracy 84.375 (86.147)\tTime 0.44\n",
      "Epoch: [6][329/704]\tLoss 0.7533 (0.8025)\tAccuracy 90.625 (86.184)\tTime 0.45\n",
      "Epoch: [6][339/704]\tLoss 1.1800 (0.8049)\tAccuracy 76.562 (86.186)\tTime 0.47\n",
      "Epoch: [6][349/704]\tLoss 0.8554 (0.8049)\tAccuracy 89.062 (86.246)\tTime 0.46\n",
      "Epoch: [6][359/704]\tLoss 0.6613 (0.8038)\tAccuracy 90.625 (86.298)\tTime 0.46\n",
      "Epoch: [6][369/704]\tLoss 0.5907 (0.8027)\tAccuracy 90.625 (86.326)\tTime 0.45\n",
      "Epoch: [6][379/704]\tLoss 0.5427 (0.7992)\tAccuracy 90.625 (86.386)\tTime 0.46\n",
      "Epoch: [6][389/704]\tLoss 0.8504 (0.8023)\tAccuracy 82.812 (86.318)\tTime 0.46\n",
      "Epoch: [6][399/704]\tLoss 0.6256 (0.7999)\tAccuracy 87.500 (86.367)\tTime 0.45\n",
      "Epoch: [6][409/704]\tLoss 0.8108 (0.8002)\tAccuracy 85.938 (86.368)\tTime 0.46\n",
      "Epoch: [6][419/704]\tLoss 0.5452 (0.7994)\tAccuracy 92.188 (86.399)\tTime 0.46\n",
      "Epoch: [6][429/704]\tLoss 0.8099 (0.7981)\tAccuracy 85.938 (86.406)\tTime 0.45\n",
      "Epoch: [6][439/704]\tLoss 0.9808 (0.8003)\tAccuracy 84.375 (86.403)\tTime 0.45\n",
      "Epoch: [6][449/704]\tLoss 0.9630 (0.8016)\tAccuracy 85.938 (86.396)\tTime 0.46\n",
      "Epoch: [6][459/704]\tLoss 0.4507 (0.7981)\tAccuracy 92.188 (86.430)\tTime 0.45\n",
      "Epoch: [6][469/704]\tLoss 0.8427 (0.7978)\tAccuracy 85.938 (86.456)\tTime 0.46\n",
      "Epoch: [6][479/704]\tLoss 0.7776 (0.7985)\tAccuracy 87.500 (86.455)\tTime 0.44\n",
      "Epoch: [6][489/704]\tLoss 0.6862 (0.7970)\tAccuracy 89.062 (86.492)\tTime 0.46\n",
      "Epoch: [6][499/704]\tLoss 0.7194 (0.7967)\tAccuracy 87.500 (86.478)\tTime 0.45\n",
      "Epoch: [6][509/704]\tLoss 1.2055 (0.7953)\tAccuracy 76.562 (86.507)\tTime 0.46\n",
      "Epoch: [6][519/704]\tLoss 0.5021 (0.7947)\tAccuracy 90.625 (86.508)\tTime 0.45\n",
      "Epoch: [6][529/704]\tLoss 0.9124 (0.7950)\tAccuracy 82.812 (86.498)\tTime 0.46\n",
      "Epoch: [6][539/704]\tLoss 0.7348 (0.7965)\tAccuracy 84.375 (86.467)\tTime 0.46\n",
      "Epoch: [6][549/704]\tLoss 1.0137 (0.7964)\tAccuracy 79.688 (86.466)\tTime 0.45\n",
      "Epoch: [6][559/704]\tLoss 0.4616 (0.7952)\tAccuracy 93.750 (86.493)\tTime 0.44\n",
      "Epoch: [6][569/704]\tLoss 0.9370 (0.7959)\tAccuracy 84.375 (86.467)\tTime 0.46\n",
      "Epoch: [6][579/704]\tLoss 0.6998 (0.7942)\tAccuracy 85.938 (86.490)\tTime 0.46\n",
      "Epoch: [6][589/704]\tLoss 0.4656 (0.7941)\tAccuracy 93.750 (86.486)\tTime 0.46\n",
      "Epoch: [6][599/704]\tLoss 0.8493 (0.7937)\tAccuracy 85.938 (86.487)\tTime 0.45\n",
      "Epoch: [6][609/704]\tLoss 0.8176 (0.7951)\tAccuracy 84.375 (86.460)\tTime 0.46\n",
      "Epoch: [6][619/704]\tLoss 0.6452 (0.7944)\tAccuracy 89.062 (86.487)\tTime 0.45\n",
      "Epoch: [6][629/704]\tLoss 0.6496 (0.7945)\tAccuracy 92.188 (86.486)\tTime 0.46\n",
      "Epoch: [6][639/704]\tLoss 0.5863 (0.7930)\tAccuracy 85.938 (86.516)\tTime 0.44\n",
      "Epoch: [6][649/704]\tLoss 0.7060 (0.7927)\tAccuracy 89.062 (86.526)\tTime 0.46\n",
      "Epoch: [6][659/704]\tLoss 1.2879 (0.7913)\tAccuracy 78.125 (86.553)\tTime 0.46\n",
      "Epoch: [6][669/704]\tLoss 0.6665 (0.7907)\tAccuracy 90.625 (86.569)\tTime 0.45\n",
      "Epoch: [6][679/704]\tLoss 0.8370 (0.7913)\tAccuracy 85.938 (86.574)\tTime 0.46\n",
      "Epoch: [6][689/704]\tLoss 1.1116 (0.7911)\tAccuracy 81.250 (86.592)\tTime 0.46\n",
      "Epoch: [6][699/704]\tLoss 0.8029 (0.7905)\tAccuracy 87.500 (86.614)\tTime 0.46\n",
      "train_accuracy 86.616\n",
      "one epoch duration:32.082281827926636\n",
      "Epoch #7, Learning rate: 0.01\n",
      "len(r_loader): 704, len(f_loader): 79\n",
      "Epoch: [7][9/704]\tLoss 1.0583 (0.6383)\tAccuracy 81.250 (89.062)\tTime 0.46\n",
      "Epoch: [7][19/704]\tLoss 0.7998 (0.6810)\tAccuracy 84.375 (88.594)\tTime 0.46\n",
      "Epoch: [7][29/704]\tLoss 0.4826 (0.6870)\tAccuracy 93.750 (88.333)\tTime 0.46\n",
      "Epoch: [7][39/704]\tLoss 0.8578 (0.7099)\tAccuracy 89.062 (88.125)\tTime 0.46\n",
      "Epoch: [7][49/704]\tLoss 1.1611 (0.7120)\tAccuracy 73.438 (88.031)\tTime 0.46\n",
      "Epoch: [7][59/704]\tLoss 0.5893 (0.7151)\tAccuracy 90.625 (88.177)\tTime 0.46\n",
      "Epoch: [7][69/704]\tLoss 0.4787 (0.7189)\tAccuracy 92.188 (88.214)\tTime 0.46\n",
      "Epoch: [7][79/704]\tLoss 0.6273 (0.7067)\tAccuracy 90.625 (88.262)\tTime 0.44\n",
      "Epoch: [7][89/704]\tLoss 0.7572 (0.7018)\tAccuracy 85.938 (88.212)\tTime 0.46\n",
      "Epoch: [7][99/704]\tLoss 0.7366 (0.6998)\tAccuracy 89.062 (88.266)\tTime 0.45\n",
      "Epoch: [7][109/704]\tLoss 0.4659 (0.6939)\tAccuracy 92.188 (88.438)\tTime 0.47\n",
      "Epoch: [7][119/704]\tLoss 0.6611 (0.6973)\tAccuracy 87.500 (88.281)\tTime 0.46\n",
      "Epoch: [7][129/704]\tLoss 0.7250 (0.6918)\tAccuracy 87.500 (88.498)\tTime 0.46\n",
      "Epoch: [7][139/704]\tLoss 0.4323 (0.6869)\tAccuracy 93.750 (88.627)\tTime 0.46\n",
      "Epoch: [7][149/704]\tLoss 0.7995 (0.6901)\tAccuracy 85.938 (88.552)\tTime 0.46\n",
      "Epoch: [7][159/704]\tLoss 0.8679 (0.6850)\tAccuracy 87.500 (88.730)\tTime 0.44\n",
      "Epoch: [7][169/704]\tLoss 0.4970 (0.6786)\tAccuracy 96.875 (88.860)\tTime 0.46\n",
      "Epoch: [7][179/704]\tLoss 0.7444 (0.6724)\tAccuracy 85.938 (88.984)\tTime 0.46\n",
      "Epoch: [7][189/704]\tLoss 0.5897 (0.6709)\tAccuracy 87.500 (89.021)\tTime 0.45\n",
      "Epoch: [7][199/704]\tLoss 0.7319 (0.6728)\tAccuracy 92.188 (89.031)\tTime 0.46\n",
      "Epoch: [7][209/704]\tLoss 0.5147 (0.6694)\tAccuracy 93.750 (89.129)\tTime 0.46\n",
      "Epoch: [7][219/704]\tLoss 0.5256 (0.6679)\tAccuracy 90.625 (89.176)\tTime 0.46\n",
      "Epoch: [7][229/704]\tLoss 0.6526 (0.6663)\tAccuracy 92.188 (89.246)\tTime 0.46\n",
      "Epoch: [7][239/704]\tLoss 0.6065 (0.6690)\tAccuracy 89.062 (89.160)\tTime 0.44\n",
      "Epoch: [7][249/704]\tLoss 0.6427 (0.6725)\tAccuracy 85.938 (89.094)\tTime 0.46\n",
      "Epoch: [7][259/704]\tLoss 0.5361 (0.6725)\tAccuracy 95.312 (89.099)\tTime 0.45\n",
      "Epoch: [7][269/704]\tLoss 0.8585 (0.6720)\tAccuracy 84.375 (89.097)\tTime 0.46\n",
      "Epoch: [7][279/704]\tLoss 0.5087 (0.6678)\tAccuracy 96.875 (89.169)\tTime 0.46\n",
      "Epoch: [7][289/704]\tLoss 0.4958 (0.6661)\tAccuracy 90.625 (89.143)\tTime 0.45\n",
      "Epoch: [7][299/704]\tLoss 0.5501 (0.6638)\tAccuracy 87.500 (89.141)\tTime 0.46\n",
      "Epoch: [7][309/704]\tLoss 0.5484 (0.6660)\tAccuracy 89.062 (89.133)\tTime 0.46\n",
      "Epoch: [7][319/704]\tLoss 0.5135 (0.6657)\tAccuracy 87.500 (89.087)\tTime 0.45\n",
      "Epoch: [7][329/704]\tLoss 0.7044 (0.6638)\tAccuracy 89.062 (89.138)\tTime 0.46\n",
      "Epoch: [7][339/704]\tLoss 1.0674 (0.6656)\tAccuracy 82.812 (89.067)\tTime 0.46\n",
      "Epoch: [7][349/704]\tLoss 0.6996 (0.6653)\tAccuracy 89.062 (89.058)\tTime 0.45\n",
      "Epoch: [7][359/704]\tLoss 0.7944 (0.6644)\tAccuracy 84.375 (89.076)\tTime 0.46\n",
      "Epoch: [7][369/704]\tLoss 0.9782 (0.6661)\tAccuracy 82.812 (89.033)\tTime 0.46\n",
      "Epoch: [7][379/704]\tLoss 0.6622 (0.6643)\tAccuracy 89.062 (89.075)\tTime 0.47\n",
      "Epoch: [7][389/704]\tLoss 0.3988 (0.6633)\tAccuracy 95.312 (89.091)\tTime 0.45\n",
      "Epoch: [7][399/704]\tLoss 0.7715 (0.6636)\tAccuracy 87.500 (89.051)\tTime 0.44\n",
      "Epoch: [7][409/704]\tLoss 0.5784 (0.6644)\tAccuracy 85.938 (89.032)\tTime 0.46\n",
      "Epoch: [7][419/704]\tLoss 0.5606 (0.6630)\tAccuracy 87.500 (89.036)\tTime 0.46\n",
      "Epoch: [7][429/704]\tLoss 0.4351 (0.6607)\tAccuracy 93.750 (89.055)\tTime 0.46\n",
      "Epoch: [7][439/704]\tLoss 0.7124 (0.6603)\tAccuracy 87.500 (89.034)\tTime 0.45\n",
      "Epoch: [7][449/704]\tLoss 0.6016 (0.6592)\tAccuracy 93.750 (89.076)\tTime 0.46\n",
      "Epoch: [7][459/704]\tLoss 0.9371 (0.6609)\tAccuracy 82.812 (89.049)\tTime 0.45\n",
      "Epoch: [7][469/704]\tLoss 0.3986 (0.6596)\tAccuracy 92.188 (89.062)\tTime 0.47\n",
      "Epoch: [7][479/704]\tLoss 0.5683 (0.6587)\tAccuracy 87.500 (89.076)\tTime 0.44\n",
      "Epoch: [7][489/704]\tLoss 0.7340 (0.6597)\tAccuracy 85.938 (89.062)\tTime 0.46\n",
      "Epoch: [7][499/704]\tLoss 0.6966 (0.6604)\tAccuracy 87.500 (89.047)\tTime 0.46\n",
      "Epoch: [7][509/704]\tLoss 0.7191 (0.6602)\tAccuracy 89.062 (89.072)\tTime 0.46\n",
      "Epoch: [7][519/704]\tLoss 0.3374 (0.6604)\tAccuracy 92.188 (89.066)\tTime 0.46\n",
      "Epoch: [7][529/704]\tLoss 0.7973 (0.6604)\tAccuracy 81.250 (89.042)\tTime 0.45\n",
      "Epoch: [7][539/704]\tLoss 0.7776 (0.6611)\tAccuracy 87.500 (89.036)\tTime 0.46\n",
      "Epoch: [7][549/704]\tLoss 0.5278 (0.6605)\tAccuracy 90.625 (89.048)\tTime 0.46\n",
      "Epoch: [7][559/704]\tLoss 0.8867 (0.6613)\tAccuracy 87.500 (89.032)\tTime 0.44\n",
      "Epoch: [7][569/704]\tLoss 0.6361 (0.6615)\tAccuracy 89.062 (89.021)\tTime 0.46\n",
      "Epoch: [7][579/704]\tLoss 0.5694 (0.6620)\tAccuracy 92.188 (89.009)\tTime 0.46\n",
      "Epoch: [7][589/704]\tLoss 0.6745 (0.6611)\tAccuracy 85.938 (88.983)\tTime 0.46\n",
      "Epoch: [7][599/704]\tLoss 0.5341 (0.6612)\tAccuracy 92.188 (88.971)\tTime 0.46\n",
      "Epoch: [7][609/704]\tLoss 0.3892 (0.6595)\tAccuracy 92.188 (89.024)\tTime 0.46\n",
      "Epoch: [7][619/704]\tLoss 0.3895 (0.6595)\tAccuracy 92.188 (88.997)\tTime 0.45\n",
      "Epoch: [7][629/704]\tLoss 0.7450 (0.6603)\tAccuracy 87.500 (88.991)\tTime 0.46\n",
      "Epoch: [7][639/704]\tLoss 0.5170 (0.6597)\tAccuracy 89.062 (89.006)\tTime 0.44\n",
      "Epoch: [7][649/704]\tLoss 0.4542 (0.6597)\tAccuracy 96.875 (89.019)\tTime 0.47\n",
      "Epoch: [7][659/704]\tLoss 0.7540 (0.6592)\tAccuracy 82.812 (89.032)\tTime 0.45\n",
      "Epoch: [7][669/704]\tLoss 0.4713 (0.6580)\tAccuracy 96.875 (89.062)\tTime 0.46\n",
      "Epoch: [7][679/704]\tLoss 0.7073 (0.6591)\tAccuracy 84.375 (89.028)\tTime 0.46\n",
      "Epoch: [7][689/704]\tLoss 0.6145 (0.6587)\tAccuracy 90.625 (89.044)\tTime 0.46\n",
      "Epoch: [7][699/704]\tLoss 0.5897 (0.6573)\tAccuracy 92.188 (89.078)\tTime 0.46\n",
      "train_accuracy 89.078\n",
      "one epoch duration:32.16009306907654\n",
      "Epoch #8, Learning rate: 0.01\n",
      "len(r_loader): 704, len(f_loader): 79\n",
      "Epoch: [8][9/704]\tLoss 0.5011 (0.5008)\tAccuracy 89.062 (92.188)\tTime 0.47\n",
      "Epoch: [8][19/704]\tLoss 0.3483 (0.4573)\tAccuracy 96.875 (93.516)\tTime 0.45\n",
      "Epoch: [8][29/704]\tLoss 0.6122 (0.5187)\tAccuracy 85.938 (92.135)\tTime 0.47\n",
      "Epoch: [8][39/704]\tLoss 0.6510 (0.5061)\tAccuracy 89.062 (92.070)\tTime 0.46\n",
      "Epoch: [8][49/704]\tLoss 0.4511 (0.5009)\tAccuracy 93.750 (92.281)\tTime 0.46\n",
      "Epoch: [8][59/704]\tLoss 0.6081 (0.5093)\tAccuracy 85.938 (91.797)\tTime 0.46\n",
      "Epoch: [8][69/704]\tLoss 0.3964 (0.5065)\tAccuracy 96.875 (91.987)\tTime 0.47\n",
      "Epoch: [8][79/704]\tLoss 0.8415 (0.5087)\tAccuracy 87.500 (91.953)\tTime 0.45\n",
      "Epoch: [8][89/704]\tLoss 0.4939 (0.5086)\tAccuracy 90.625 (92.031)\tTime 0.46\n",
      "Epoch: [8][99/704]\tLoss 0.2836 (0.5080)\tAccuracy 96.875 (92.016)\tTime 0.46\n",
      "Epoch: [8][109/704]\tLoss 0.8875 (0.5113)\tAccuracy 81.250 (91.818)\tTime 0.46\n",
      "Epoch: [8][119/704]\tLoss 0.5890 (0.5185)\tAccuracy 92.188 (91.615)\tTime 0.46\n",
      "Epoch: [8][129/704]\tLoss 0.4657 (0.5223)\tAccuracy 92.188 (91.587)\tTime 0.46\n",
      "Epoch: [8][139/704]\tLoss 0.5779 (0.5235)\tAccuracy 90.625 (91.574)\tTime 0.45\n",
      "Epoch: [8][149/704]\tLoss 0.6210 (0.5212)\tAccuracy 89.062 (91.625)\tTime 0.46\n",
      "Epoch: [8][159/704]\tLoss 0.4923 (0.5214)\tAccuracy 92.188 (91.592)\tTime 0.44\n",
      "Epoch: [8][169/704]\tLoss 0.3361 (0.5184)\tAccuracy 96.875 (91.664)\tTime 0.46\n",
      "Epoch: [8][179/704]\tLoss 0.4050 (0.5195)\tAccuracy 92.188 (91.632)\tTime 0.46\n",
      "Epoch: [8][189/704]\tLoss 0.6082 (0.5221)\tAccuracy 90.625 (91.513)\tTime 0.46\n",
      "Epoch: [8][199/704]\tLoss 0.9101 (0.5207)\tAccuracy 84.375 (91.508)\tTime 0.46\n",
      "Epoch: [8][209/704]\tLoss 0.6246 (0.5222)\tAccuracy 85.938 (91.451)\tTime 0.46\n",
      "Epoch: [8][219/704]\tLoss 0.7815 (0.5217)\tAccuracy 89.062 (91.499)\tTime 0.46\n",
      "Epoch: [8][229/704]\tLoss 0.6814 (0.5250)\tAccuracy 87.500 (91.433)\tTime 0.46\n",
      "Epoch: [8][239/704]\tLoss 0.4776 (0.5246)\tAccuracy 90.625 (91.471)\tTime 0.44\n",
      "Epoch: [8][249/704]\tLoss 0.3485 (0.5261)\tAccuracy 95.312 (91.444)\tTime 0.46\n",
      "Epoch: [8][259/704]\tLoss 0.8494 (0.5297)\tAccuracy 84.375 (91.328)\tTime 0.46\n",
      "Epoch: [8][269/704]\tLoss 0.5595 (0.5317)\tAccuracy 92.188 (91.314)\tTime 0.46\n",
      "Epoch: [8][279/704]\tLoss 0.6706 (0.5322)\tAccuracy 87.500 (91.278)\tTime 0.46\n",
      "Epoch: [8][289/704]\tLoss 0.5193 (0.5343)\tAccuracy 85.938 (91.164)\tTime 0.46\n",
      "Epoch: [8][299/704]\tLoss 0.5898 (0.5343)\tAccuracy 90.625 (91.151)\tTime 0.46\n",
      "Epoch: [8][309/704]\tLoss 0.5260 (0.5353)\tAccuracy 89.062 (91.134)\tTime 0.46\n",
      "Epoch: [8][319/704]\tLoss 0.4938 (0.5360)\tAccuracy 92.188 (91.128)\tTime 0.45\n",
      "Epoch: [8][329/704]\tLoss 0.4088 (0.5344)\tAccuracy 93.750 (91.151)\tTime 0.45\n",
      "Epoch: [8][339/704]\tLoss 0.4862 (0.5343)\tAccuracy 92.188 (91.158)\tTime 0.46\n",
      "Epoch: [8][349/704]\tLoss 0.5693 (0.5363)\tAccuracy 90.625 (91.103)\tTime 0.46\n",
      "Epoch: [8][359/704]\tLoss 0.7643 (0.5383)\tAccuracy 87.500 (91.042)\tTime 0.46\n",
      "Epoch: [8][369/704]\tLoss 0.6120 (0.5393)\tAccuracy 93.750 (91.035)\tTime 0.46\n",
      "Epoch: [8][379/704]\tLoss 0.5414 (0.5410)\tAccuracy 89.062 (91.003)\tTime 0.46\n",
      "Epoch: [8][389/704]\tLoss 0.3963 (0.5418)\tAccuracy 92.188 (90.978)\tTime 0.46\n",
      "Epoch: [8][399/704]\tLoss 0.4829 (0.5404)\tAccuracy 90.625 (90.992)\tTime 0.44\n",
      "Epoch: [8][409/704]\tLoss 0.3375 (0.5411)\tAccuracy 98.438 (91.006)\tTime 0.46\n",
      "Epoch: [8][419/704]\tLoss 0.6438 (0.5405)\tAccuracy 87.500 (91.023)\tTime 0.46\n",
      "Epoch: [8][429/704]\tLoss 0.7158 (0.5403)\tAccuracy 84.375 (91.010)\tTime 0.46\n",
      "Epoch: [8][439/704]\tLoss 0.4409 (0.5391)\tAccuracy 90.625 (91.030)\tTime 0.46\n",
      "Epoch: [8][449/704]\tLoss 0.7209 (0.5389)\tAccuracy 90.625 (91.049)\tTime 0.46\n",
      "Epoch: [8][459/704]\tLoss 0.2779 (0.5387)\tAccuracy 96.875 (91.036)\tTime 0.46\n",
      "Epoch: [8][469/704]\tLoss 0.6464 (0.5382)\tAccuracy 87.500 (91.051)\tTime 0.46\n",
      "Epoch: [8][479/704]\tLoss 1.0240 (0.5379)\tAccuracy 82.812 (91.051)\tTime 0.45\n",
      "Epoch: [8][489/704]\tLoss 0.4201 (0.5359)\tAccuracy 93.750 (91.097)\tTime 0.46\n",
      "Epoch: [8][499/704]\tLoss 0.6880 (0.5350)\tAccuracy 85.938 (91.100)\tTime 0.46\n",
      "Epoch: [8][509/704]\tLoss 0.7731 (0.5348)\tAccuracy 85.938 (91.088)\tTime 0.46\n",
      "Epoch: [8][519/704]\tLoss 0.2848 (0.5337)\tAccuracy 95.312 (91.100)\tTime 0.46\n",
      "Epoch: [8][529/704]\tLoss 0.4510 (0.5334)\tAccuracy 93.750 (91.111)\tTime 0.46\n",
      "Epoch: [8][539/704]\tLoss 0.8996 (0.5345)\tAccuracy 85.938 (91.102)\tTime 0.46\n",
      "Epoch: [8][549/704]\tLoss 0.8103 (0.5347)\tAccuracy 84.375 (91.102)\tTime 0.46\n",
      "Epoch: [8][559/704]\tLoss 0.5761 (0.5345)\tAccuracy 89.062 (91.110)\tTime 0.44\n",
      "Epoch: [8][569/704]\tLoss 0.5844 (0.5339)\tAccuracy 90.625 (91.121)\tTime 0.46\n",
      "Epoch: [8][579/704]\tLoss 0.6158 (0.5353)\tAccuracy 89.062 (91.086)\tTime 0.45\n",
      "Epoch: [8][589/704]\tLoss 0.3339 (0.5345)\tAccuracy 95.312 (91.107)\tTime 0.46\n",
      "Epoch: [8][599/704]\tLoss 0.5404 (0.5356)\tAccuracy 92.188 (91.104)\tTime 0.46\n",
      "Epoch: [8][609/704]\tLoss 0.3673 (0.5347)\tAccuracy 93.750 (91.124)\tTime 0.46\n",
      "Epoch: [8][619/704]\tLoss 0.6203 (0.5364)\tAccuracy 90.625 (91.081)\tTime 0.46\n",
      "Epoch: [8][629/704]\tLoss 0.5895 (0.5357)\tAccuracy 93.750 (91.121)\tTime 0.46\n",
      "Epoch: [8][639/704]\tLoss 0.8493 (0.5374)\tAccuracy 82.812 (91.099)\tTime 0.44\n",
      "Epoch: [8][649/704]\tLoss 0.5924 (0.5374)\tAccuracy 89.062 (91.101)\tTime 0.46\n",
      "Epoch: [8][659/704]\tLoss 0.3617 (0.5388)\tAccuracy 95.312 (91.077)\tTime 0.46\n",
      "Epoch: [8][669/704]\tLoss 0.6027 (0.5383)\tAccuracy 93.750 (91.089)\tTime 0.46\n",
      "Epoch: [8][679/704]\tLoss 0.8362 (0.5386)\tAccuracy 89.062 (91.082)\tTime 0.46\n",
      "Epoch: [8][689/704]\tLoss 0.2571 (0.5377)\tAccuracy 98.438 (91.101)\tTime 0.46\n",
      "Epoch: [8][699/704]\tLoss 0.6744 (0.5374)\tAccuracy 87.500 (91.089)\tTime 0.46\n",
      "train_accuracy 91.104\n",
      "one epoch duration:32.171157360076904\n",
      "Epoch #9, Learning rate: 0.01\n",
      "len(r_loader): 704, len(f_loader): 79\n",
      "Epoch: [9][9/704]\tLoss 0.4639 (0.4476)\tAccuracy 90.625 (92.344)\tTime 0.46\n",
      "Epoch: [9][19/704]\tLoss 0.4341 (0.4411)\tAccuracy 93.750 (93.047)\tTime 0.46\n",
      "Epoch: [9][29/704]\tLoss 0.2495 (0.4348)\tAccuracy 98.438 (93.385)\tTime 0.46\n",
      "Epoch: [9][39/704]\tLoss 0.5342 (0.4351)\tAccuracy 95.312 (93.555)\tTime 0.46\n",
      "Epoch: [9][49/704]\tLoss 0.4450 (0.4384)\tAccuracy 92.188 (93.594)\tTime 0.46\n",
      "Epoch: [9][59/704]\tLoss 0.3681 (0.4409)\tAccuracy 95.312 (93.411)\tTime 0.46\n",
      "Epoch: [9][69/704]\tLoss 0.3616 (0.4446)\tAccuracy 95.312 (93.304)\tTime 0.46\n",
      "Epoch: [9][79/704]\tLoss 0.4602 (0.4416)\tAccuracy 92.188 (93.223)\tTime 0.44\n",
      "Epoch: [9][89/704]\tLoss 0.1948 (0.4432)\tAccuracy 100.000 (93.194)\tTime 0.46\n",
      "Epoch: [9][99/704]\tLoss 0.5047 (0.4495)\tAccuracy 95.312 (93.031)\tTime 0.46\n",
      "Epoch: [9][109/704]\tLoss 0.5134 (0.4494)\tAccuracy 93.750 (93.111)\tTime 0.46\n",
      "Epoch: [9][119/704]\tLoss 0.6129 (0.4874)\tAccuracy 87.500 (92.708)\tTime 0.45\n",
      "Epoch: [9][129/704]\tLoss 0.4815 (0.5708)\tAccuracy 93.750 (91.839)\tTime 0.46\n",
      "Epoch: [9][139/704]\tLoss 1.1871 (0.6228)\tAccuracy 89.062 (91.116)\tTime 0.46\n",
      "Epoch: [9][149/704]\tLoss 0.5224 (0.6265)\tAccuracy 93.750 (90.979)\tTime 0.46\n",
      "Epoch: [9][159/704]\tLoss 0.4573 (0.6237)\tAccuracy 90.625 (90.967)\tTime 0.44\n",
      "Epoch: [9][169/704]\tLoss 0.3205 (0.6118)\tAccuracy 96.875 (91.103)\tTime 0.46\n",
      "Epoch: [9][179/704]\tLoss 0.4820 (0.6067)\tAccuracy 92.188 (91.111)\tTime 0.46\n",
      "Epoch: [9][189/704]\tLoss 0.6425 (0.6023)\tAccuracy 93.750 (91.094)\tTime 0.45\n",
      "Epoch: [9][199/704]\tLoss 0.3167 (0.5957)\tAccuracy 96.875 (91.164)\tTime 0.46\n",
      "Epoch: [9][209/704]\tLoss 0.3963 (0.5889)\tAccuracy 92.188 (91.205)\tTime 0.46\n",
      "Epoch: [9][219/704]\tLoss 0.4901 (0.5882)\tAccuracy 93.750 (91.207)\tTime 0.46\n",
      "Epoch: [9][229/704]\tLoss 0.7527 (0.5846)\tAccuracy 87.500 (91.257)\tTime 0.46\n",
      "Epoch: [9][239/704]\tLoss 0.4577 (0.5776)\tAccuracy 93.750 (91.361)\tTime 0.44\n",
      "Epoch: [9][249/704]\tLoss 0.3625 (0.5703)\tAccuracy 93.750 (91.444)\tTime 0.46\n",
      "Epoch: [9][259/704]\tLoss 0.6171 (0.5666)\tAccuracy 89.062 (91.436)\tTime 0.46\n",
      "Epoch: [9][269/704]\tLoss 0.4742 (0.5660)\tAccuracy 92.188 (91.429)\tTime 0.46\n",
      "Epoch: [9][279/704]\tLoss 0.1630 (0.5595)\tAccuracy 98.438 (91.512)\tTime 0.45\n",
      "Epoch: [9][289/704]\tLoss 0.3733 (0.5563)\tAccuracy 93.750 (91.519)\tTime 0.46\n",
      "Epoch: [9][299/704]\tLoss 0.4389 (0.5520)\tAccuracy 87.500 (91.557)\tTime 0.45\n",
      "Epoch: [9][309/704]\tLoss 0.4204 (0.5459)\tAccuracy 89.062 (91.658)\tTime 0.46\n",
      "Epoch: [9][319/704]\tLoss 0.3815 (0.5419)\tAccuracy 95.312 (91.714)\tTime 0.44\n",
      "Epoch: [9][329/704]\tLoss 0.3580 (0.5369)\tAccuracy 96.875 (91.795)\tTime 0.46\n",
      "Epoch: [9][339/704]\tLoss 0.6036 (0.5331)\tAccuracy 87.500 (91.829)\tTime 0.46\n",
      "Epoch: [9][349/704]\tLoss 0.4481 (0.5283)\tAccuracy 92.188 (91.875)\tTime 0.46\n",
      "Epoch: [9][359/704]\tLoss 0.4381 (0.5245)\tAccuracy 92.188 (91.944)\tTime 0.46\n",
      "Epoch: [9][369/704]\tLoss 0.2579 (0.5212)\tAccuracy 96.875 (92.014)\tTime 0.46\n",
      "Epoch: [9][379/704]\tLoss 0.4925 (0.5216)\tAccuracy 92.188 (91.994)\tTime 0.45\n",
      "Epoch: [9][389/704]\tLoss 0.4919 (0.5207)\tAccuracy 90.625 (91.999)\tTime 0.46\n",
      "Epoch: [9][399/704]\tLoss 0.2575 (0.5182)\tAccuracy 96.875 (92.027)\tTime 0.44\n",
      "Epoch: [9][409/704]\tLoss 0.4095 (0.5168)\tAccuracy 95.312 (92.039)\tTime 0.46\n",
      "Epoch: [9][419/704]\tLoss 0.3931 (0.5140)\tAccuracy 93.750 (92.094)\tTime 0.46\n",
      "Epoch: [9][429/704]\tLoss 0.3286 (0.5123)\tAccuracy 95.312 (92.100)\tTime 0.45\n",
      "Epoch: [9][439/704]\tLoss 0.5327 (0.5099)\tAccuracy 87.500 (92.120)\tTime 0.46\n",
      "Epoch: [9][449/704]\tLoss 0.1958 (0.5076)\tAccuracy 98.438 (92.167)\tTime 0.45\n",
      "Epoch: [9][459/704]\tLoss 0.4352 (0.5047)\tAccuracy 95.312 (92.221)\tTime 0.46\n",
      "Epoch: [9][469/704]\tLoss 0.4777 (0.5051)\tAccuracy 90.625 (92.178)\tTime 0.46\n",
      "Epoch: [9][479/704]\tLoss 0.6263 (0.5043)\tAccuracy 92.188 (92.178)\tTime 0.44\n",
      "Epoch: [9][489/704]\tLoss 0.4724 (0.5022)\tAccuracy 93.750 (92.184)\tTime 0.46\n",
      "Epoch: [9][499/704]\tLoss 0.7010 (0.5006)\tAccuracy 87.500 (92.169)\tTime 0.46\n",
      "Epoch: [9][509/704]\tLoss 0.4566 (0.4991)\tAccuracy 92.188 (92.203)\tTime 0.46\n",
      "Epoch: [9][519/704]\tLoss 0.2879 (0.4990)\tAccuracy 98.438 (92.212)\tTime 0.46\n",
      "Epoch: [9][529/704]\tLoss 0.4118 (0.4985)\tAccuracy 93.750 (92.211)\tTime 0.46\n",
      "Epoch: [9][539/704]\tLoss 0.3399 (0.4967)\tAccuracy 93.750 (92.234)\tTime 0.45\n",
      "Epoch: [9][549/704]\tLoss 0.3868 (0.4946)\tAccuracy 92.188 (92.261)\tTime 0.46\n",
      "Epoch: [9][559/704]\tLoss 0.3479 (0.4937)\tAccuracy 95.312 (92.266)\tTime 0.45\n",
      "Epoch: [9][569/704]\tLoss 0.2884 (0.4926)\tAccuracy 96.875 (92.281)\tTime 0.45\n",
      "Epoch: [9][579/704]\tLoss 0.5926 (0.4933)\tAccuracy 87.500 (92.241)\tTime 0.46\n",
      "Epoch: [9][589/704]\tLoss 0.4651 (0.4927)\tAccuracy 92.188 (92.233)\tTime 0.45\n",
      "Epoch: [9][599/704]\tLoss 0.4604 (0.4917)\tAccuracy 89.062 (92.237)\tTime 0.46\n",
      "Epoch: [9][609/704]\tLoss 0.4754 (0.4907)\tAccuracy 92.188 (92.244)\tTime 0.46\n",
      "Epoch: [9][619/704]\tLoss 0.3288 (0.4894)\tAccuracy 92.188 (92.266)\tTime 0.46\n",
      "Epoch: [9][629/704]\tLoss 0.2440 (0.4890)\tAccuracy 96.875 (92.259)\tTime 0.46\n",
      "Epoch: [9][639/704]\tLoss 0.4451 (0.4884)\tAccuracy 92.188 (92.263)\tTime 0.43\n",
      "Epoch: [9][649/704]\tLoss 0.6737 (0.4878)\tAccuracy 85.938 (92.276)\tTime 0.46\n",
      "Epoch: [9][659/704]\tLoss 0.5265 (0.4881)\tAccuracy 93.750 (92.287)\tTime 0.46\n",
      "Epoch: [9][669/704]\tLoss 0.4399 (0.4862)\tAccuracy 93.750 (92.327)\tTime 0.46\n",
      "Epoch: [9][679/704]\tLoss 0.2714 (0.4864)\tAccuracy 95.312 (92.337)\tTime 0.45\n",
      "Epoch: [9][689/704]\tLoss 0.3619 (0.4857)\tAccuracy 93.750 (92.348)\tTime 0.47\n",
      "Epoch: [9][699/704]\tLoss 0.2496 (0.4849)\tAccuracy 96.875 (92.366)\tTime 0.45\n",
      "train_accuracy 92.373\n",
      "one epoch duration:32.120190382003784\n"
     ]
    }
   ],
   "source": [
    "umodel = copy.deepcopy(model)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "umodel.to(device)\n",
    "umodel.train()\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "args = Args()\n",
    "\n",
    "umodel = unlearnWithArgs(data_loaders, umodel, criterion, args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0431fe87",
   "metadata": {},
   "source": [
    "### Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8995a6ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall accuracy of the unlearned model on the test data: 69.51%\n",
      "Accuracy for class 0: 84.80%\n",
      "Accuracy for class 1: 86.20%\n",
      "Accuracy for class 2: 46.20%\n",
      "Accuracy for class 3: 50.20%\n",
      "Accuracy for class 4: 74.90%\n",
      "Accuracy for class 5: 69.10%\n",
      "Accuracy for class 6: 75.30%\n",
      "Accuracy for class 7: 74.20%\n",
      "Accuracy for class 8: 55.60%\n",
      "Accuracy for class 9: 78.60%\n",
      "forget acc: 91.34\n",
      "retain acc: 81.9888888888889\n",
      "test acc: 69.51\n"
     ]
    }
   ],
   "source": [
    "# Initialize counters for each class\n",
    "from Unlearning import utils\n",
    "from Unlearning.trainer.val import validate\n",
    "\n",
    "\n",
    "class_correct = [0] * 10\n",
    "class_total = [0] * 10\n",
    "\n",
    "# Evaluate the unlearned model\n",
    "umodel.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in data_loaders[\"test\"]:\n",
    "        inputs = inputs.to(device).float()\n",
    "        labels = labels.to(device).long()\n",
    "        outputs = umodel(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "        # Update total and correct counts for each class\n",
    "        for label, prediction in zip(labels, predicted):\n",
    "            class_total[label.item()] += 1\n",
    "            if label.item() == prediction.item():\n",
    "                class_correct[label.item()] += 1\n",
    "\n",
    "# Print overall accuracy\n",
    "overall_accuracy = 100 * sum(class_correct) / sum(class_total)\n",
    "print('Overall accuracy of the unlearned model on the test data: {:.2f}%'.format(overall_accuracy))\n",
    "\n",
    "# Print accuracy for each class\n",
    "for i in range(10):\n",
    "    if class_total[i] > 0:\n",
    "        class_accuracy = 100 * class_correct[i] / class_total[i]\n",
    "        print('Accuracy for class {}: {:.2f}%'.format(i, class_accuracy))\n",
    "    else:\n",
    "        print('No samples for class {}'.format(i))\n",
    "\n",
    "\n",
    "for name, loader in data_loaders.items():\n",
    "        utils.dataset_convert_to_test(loader.dataset, args)\n",
    "        val_acc = validate(loader, umodel, criterion, args)\n",
    "        print(f\"{name} acc: {val_acc}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79564f8",
   "metadata": {},
   "source": [
    "### Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c958d258",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import itertools\n",
    "# import csv\n",
    "# from Unlearning import utils\n",
    "# from Unlearning.trainer.val import validate\n",
    " \n",
    "\n",
    "# param_grid = {\n",
    "#     'lr': [0.0001, 0.001, 0.01, 0.1],\n",
    "#     'momentum': [0.8, 0.9, 0.99],\n",
    "#     'weight_decay': [0.0, 1e-4, 1e-3],\n",
    "#     'unlearn_epochs': [5],\n",
    "# }\n",
    " \n",
    "\n",
    "# grid_combinations = list(itertools.product(*param_grid.values()))\n",
    " \n",
    "# results = []\n",
    " \n",
    "# for idx, (lr, momentum, weight_decay, unlearn_epochs) in enumerate(grid_combinations):\n",
    "\n",
    "#     print(f\"Running configuration {idx + 1}/{len(grid_combinations)}: \"\n",
    "#     f\"lr={lr}, momentum={momentum}, weight_decay={weight_decay}, unlearn_epochs={unlearn_epochs}\")\n",
    " \n",
    "\n",
    "#     umodel = copy.deepcopy(model)\n",
    "#     device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#     umodel.to(device)\n",
    "\n",
    "\n",
    "#     criterion = torch.nn.CrossEntropyLoss()\n",
    " \n",
    "\n",
    "#     args = Args()\n",
    "#     args.unlearn_lr = lr\n",
    "#     args.momentum = momentum\n",
    "#     args.weight_decay = weight_decay\n",
    "#     args.unlearn_epochs = unlearn_epochs\n",
    " \n",
    "#     umodel = unlearnWithArgs(data_loaders, umodel, criterion, args)\n",
    " \n",
    "#     floader = data_loaders['forget']\n",
    "#     utils.dataset_convert_to_test(floader.dataset, args)\n",
    "#     val_acc = validate(floader, umodel, criterion, args)\n",
    "#     forget_acc = val_acc\n",
    "\n",
    "#     rloader = data_loaders['retain']\n",
    "#     utils.dataset_convert_to_test(rloader.dataset, args)\n",
    "#     val_acc = validate(rloader, umodel, criterion, args)\n",
    "#     retain_acc = val_acc\n",
    "\n",
    "#     tloader = data_loaders['test']\n",
    "#     utils.dataset_convert_to_test(tloader.dataset, args)\n",
    "#     val_acc = validate(tloader, umodel, criterion, args)\n",
    "#     test_acc = val_acc\n",
    " \n",
    "#     # Store results\n",
    "\n",
    "#     results.append({\n",
    "\n",
    "#         'lr': lr,\n",
    "#         'momentum': momentum,\n",
    "#         'weight_decay': weight_decay,\n",
    "#         'unlearn_epochs': unlearn_epochs,\n",
    "#         'retain_accuracy': retain_acc,\n",
    "#         'forget_accuracy': forget_acc,\n",
    "#         'test_acccuracy': test_acc,\n",
    "#         'metric': retain_acc - forget_acc \n",
    "\n",
    "#     })\n",
    " \n",
    "\n",
    "#     with open('grid_search_results.csv', 'w') as csvfile:\n",
    "#         writer = csv.DictWriter(csvfile, fieldnames=results[0].keys())\n",
    "#         writer.writeheader()\n",
    "#         writer.writerows(results)\n",
    " \n",
    "# print(\"Grid search complete. Results saved to 'grid_search_results.csv'.\")\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
