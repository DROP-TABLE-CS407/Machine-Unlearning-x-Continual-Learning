{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3e8eb68",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.functional import relu, avg_pool2d\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import time\n",
    "import random\n",
    "\n",
    "# from GEM.gem import *\n",
    "from GEM.args import *\n",
    "\n",
    "from cifar import load_cifar10_data, split_into_classes, get_class_indexes \n",
    "\n",
    "# import quadprog\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(\".\"))  # Adds the current directory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6360b5c4aaa0b84a",
   "metadata": {},
   "source": [
    "# CIFAR-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "545fa36453e0dda4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-13T15:16:56.387836Z",
     "start_time": "2024-11-13T15:16:56.266657Z"
    }
   },
   "outputs": [],
   "source": [
    "# Path to the dataset\n",
    "DATASET_PATH = 'cifar-10-batches-py' \n",
    "CLASSES = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "train_data, train_labels, test_data, test_labels = load_cifar10_data(DATASET_PATH)\n",
    "classes = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "# split the data into 10 classes by doing sort by key where in the keys are the labels and the values are the data\n",
    "train_split = {cls: [] for cls in CLASSES}\n",
    "for img, label in zip(train_data, train_labels):\n",
    "    train_split[CLASSES[label]].append(img)\n",
    "    \n",
    "# this makes more sense to me, effectively indexes 0-5000 are all airplanes, 5000-10000 are all automobiles etc\n",
    "test_split = {cls: [] for cls in CLASSES}\n",
    "for img, label in zip(test_data, test_labels):\n",
    "    test_split[CLASSES[label]].append(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b849681c0f0bdd16",
   "metadata": {},
   "source": [
    "# PRETRAINED MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b345dbfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet18CIFAR(\n",
       "  (resnet): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): Identity()\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=512, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import time\n",
    "# make cuda available if available\n",
    "\n",
    "from cifar import load_cifar10_data, show_image\n",
    "\n",
    "# we want to create a resnet 18 model for 32x32 images\n",
    "# avoid upscaling, the model will take 32x32 images on input as opposed to 224x224\n",
    "\n",
    "initialisation = time.time()\n",
    "\n",
    "class ResNet18CIFAR(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNet18CIFAR, self).__init__()\n",
    "        self.resnet = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', pretrained=False)\n",
    "        # change the first layer to accept 32x32 images with 3 channels rather than 224x224 images\n",
    "        # check the size of the input layer\n",
    "        print(\"|| conv1 weight size: \", self.resnet.conv1.weight.size())\n",
    "        print(\"|| fc weight size: \", self.resnet.fc.weight.size())\n",
    "        self.resnet.conv1 = torch.nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.resnet.fc = torch.nn.Linear(512, 10)\n",
    "        self.resnet.maxpool = torch.nn.Identity()\n",
    "        # change input layer to accept 32x32 images\n",
    "\n",
    "\n",
    "        \n",
    "        # List all layers in the resnet18 model\n",
    "        for name, layer in self.resnet.named_children():\n",
    "            print(f\"Layer: {name} -> {layer}\")\n",
    "        \n",
    "        #print(\"|| conv1 weight size: \", self.resnet.conv1.weight.size())\n",
    "        #print(\"|| fc weight size: \", self.resnet.fc.weight.size())\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.resnet(x)\n",
    "    \n",
    "model = torch.load('models/resnet18_cifar77ACC.pth',  map_location=torch.device('cpu'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d9dd6044c0b8dfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "||===================START CLASS-BY-CLASS ACCURACY=================||\n",
      "|| Overall Test Accuracy: 77.34% ||\n",
      "|| Accuracy for Class 0: 83.10% ||\n",
      "|| Accuracy for Class 1: 88.00% ||\n",
      "|| Accuracy for Class 2: 63.10% ||\n",
      "|| Accuracy for Class 3: 58.30% ||\n",
      "|| Accuracy for Class 4: 72.60% ||\n",
      "|| Accuracy for Class 5: 66.00% ||\n",
      "|| Accuracy for Class 6: 84.10% ||\n",
      "|| Accuracy for Class 7: 82.50% ||\n",
      "|| Accuracy for Class 8: 87.20% ||\n",
      "|| Accuracy for Class 9: 88.50% ||\n"
     ]
    }
   ],
   "source": [
    "# turn the data into a tensor\n",
    "test_data_tensor = torch.tensor(test_data).float()\n",
    "test_labels_tensor = torch.tensor(test_labels)\n",
    "\n",
    "# Define the number of classes in your dataset\n",
    "num_classes = 10\n",
    "# Initialize counters for each class\n",
    "class_correct = [0] * num_classes\n",
    "class_total = [0] * num_classes\n",
    "\n",
    "print(\"||===================START CLASS-BY-CLASS ACCURACY=================||\")\n",
    "\n",
    "# Move tensors to GPU if available\n",
    "if torch.cuda.is_available():\n",
    "    test_data_tensor = test_data_tensor.cuda()\n",
    "    test_labels_tensor = test_labels_tensor.cuda()\n",
    "\n",
    "# Test the model\n",
    "with torch.no_grad():\n",
    "    for i in range(0, len(test_data), 1000):\n",
    "        # Get the input and output\n",
    "        img = test_data_tensor[i:i + 1000]\n",
    "        label = test_labels_tensor[i:i + 1000]\n",
    "        \n",
    "        model = model.cuda()\n",
    "\n",
    "        # Get the prediction\n",
    "        outputs = model(img)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "        # Update per-class counters\n",
    "        for lbl, pred in zip(label, predicted):\n",
    "            class_total[lbl.item()] += 1\n",
    "            if lbl.item() == pred.item():\n",
    "                class_correct[lbl.item()] += 1\n",
    "\n",
    "        del img\n",
    "\n",
    "# Print overall accuracy\n",
    "overall_accuracy = sum(class_correct) / sum(class_total) * 100\n",
    "print(f\"|| Overall Test Accuracy: {overall_accuracy:.2f}% ||\")\n",
    "\n",
    "# Print accuracy for each class\n",
    "for cls in range(num_classes):\n",
    "    if class_total[cls] > 0:\n",
    "        class_accuracy = class_correct[cls] / class_total[cls] * 100\n",
    "        print(f\"|| Accuracy for Class {cls}: {class_accuracy:.2f}% ||\")\n",
    "    else:\n",
    "        print(f\"|| No samples for Class {cls} ||\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd55059d",
   "metadata": {},
   "source": [
    "# UNLEARNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8c22b66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/dcs/21/u2110391/CS407/Machine-Unlearning-x-Continual-Learning/Unlearning\n"
     ]
    }
   ],
   "source": [
    "%cd Unlearning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e8076b",
   "metadata": {},
   "source": [
    "### Prepare Data and Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8280c00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classes to be Unlearnt\n",
    "classes_to_unlearn = [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8c590ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "from unlearn.scrub import train_distill, iterative_unlearn, scrub\n",
    "from utils import DistillKL, AverageMeter, accuracy\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Convert data and labels to PyTorch tensors\n",
    "train_data_tensor = torch.tensor(train_data, dtype=torch.float32).cuda()\n",
    "train_labels_tensor = torch.tensor(train_labels).cuda()\n",
    "\n",
    "test_data_tensor = torch.tensor(test_data, dtype=torch.float32).cuda()\n",
    "test_labels_tensor = torch.tensor(test_labels).cuda()\n",
    "\n",
    "# Split training data into forget and retain sets\n",
    "forget_mask = torch.isin(train_labels_tensor, torch.tensor(classes_to_unlearn).cuda())\n",
    "retain_mask = ~forget_mask\n",
    "\n",
    "# Get the indices of the forget and retain subsets\n",
    "forget_indices = forget_mask.nonzero(as_tuple=True)[0]\n",
    "retain_indices = retain_mask.nonzero(as_tuple=True)[0]\n",
    "\n",
    "# Create the forget and retain datasets using the indices\n",
    "forget_dataset = TensorDataset(train_data_tensor[forget_indices], train_labels_tensor[forget_indices])\n",
    "retain_dataset = TensorDataset(train_data_tensor[retain_indices], train_labels_tensor[retain_indices])\n",
    "test_dataset = TensorDataset(test_data_tensor, test_labels_tensor)\n",
    "\n",
    "# Create DataLoaders\n",
    "data_loaders = OrderedDict(\n",
    "    forget = DataLoader(forget_dataset, batch_size=64, shuffle=True),\n",
    "    retain = DataLoader(retain_dataset, batch_size=64, shuffle=True),\n",
    "    test =  DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e1726b04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet18CIFAR(\n",
       "  (resnet): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): Identity()\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=512, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Move the model to device\n",
    "import copy\n",
    "umodel = copy.deepcopy(model)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "umodel.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be992da",
   "metadata": {},
   "source": [
    "### DEFINE ALGORITHM HYPERPARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "78e88c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the criterion and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)\n",
    "\n",
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.unlearn_lr = 0.0001         # Learning rate for unlearning\n",
    "        self.momentum = 0.9\n",
    "        self.weight_decay = 0.0005\n",
    "        self.dataset = ''      # Change as needed\n",
    "        self.num_classes = 10         # Number of classes in the dataset\n",
    "        self.batch_size = 64\n",
    "        self.print_freq = 10\n",
    "        self.warmup = 0               # Number of warmup epochs\n",
    "        self.imagenet_arch = False    # Set to True if using ImageNet architecture\n",
    "        self.seed = 42       \n",
    "        \n",
    "        # SCRUB SPECIFIC\n",
    "        self.kd_T = 1\n",
    "        self.msteps = 1\n",
    "        self.gamma = 10\n",
    "        self.beta = 1\n",
    "\n",
    "\n",
    "        # Add the following attributes to ensure compatibility\n",
    "        self.decreasing_lr = '50,75'  # Comma-separated epochs where LR decays\n",
    "        self.rewind_epoch = 0         # Epoch to rewind to; set to 0 if not using rewinding\n",
    "        self.rewind_pth = ''          # Path to the rewind checkpoint\n",
    "        self.gpu = 0                  # GPU ID to use; adjust as needed\n",
    "        self.surgical = False         # Whether to use surgical unlearning\n",
    "        self.unlearn = 'SCRUB'      # Unlearning method, e.g., 'retrain'\n",
    "        self.choice = []              # Layers to unlearn surgically; list of layer names\n",
    "        self.unlearn_epochs = 20     # Number of epochs for unlearning\n",
    "        self.epochs = 100   \n",
    "\n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79564f8",
   "metadata": {},
   "source": [
    "### Apply Unlearning Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f08fd0ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #0, Learning rate: 0.0001\n",
      "len(r_loader): 704, len(f_loader): 79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/java/python-ml/22-12-21-python3.9/lib64/python3.9/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Maximize step ***\n",
      "Epoch: [0][78/79]\tTime 0.019 (0.024)\tData 0.000 (0.000)\tLoss -68.3701 (-48.7146)\tForget_Acc@1 0.000 (0.000)\n",
      "*** Minimize step ***\n",
      "Epoch: [0][703/704]\tTime 0.017 (0.024)\tData 0.002 (0.000)\tLoss 22.2693 (30.8770)\tRetain_Acc@1 25.000 (33.667)\n",
      "Epoch: [0]\t train-acc:\t33.666666666666664\t train-loss: 30.87696835530599\n",
      "one epoch duration:18.920036554336548\n",
      "Epoch #1, Learning rate: 0.0001\n",
      "len(r_loader): 704, len(f_loader): 79\n",
      "*** Maximize step ***\n",
      "Epoch: [1][78/79]\tTime 0.017 (0.024)\tData 0.000 (0.000)\tLoss -52.8861 (-41.1761)\tForget_Acc@1 0.000 (0.000)\n",
      "*** Minimize step ***\n",
      "Epoch: [1][703/704]\tTime 0.016 (0.024)\tData 0.002 (0.000)\tLoss 11.0808 (17.1504)\tRetain_Acc@1 50.000 (42.584)\n",
      "Epoch: [1]\t train-acc:\t42.58444444444444\t train-loss: 17.15043731129964\n",
      "one epoch duration:18.969279289245605\n",
      "Epoch #2, Learning rate: 0.0001\n",
      "len(r_loader): 704, len(f_loader): 79\n",
      "*** Minimize step ***\n",
      "Epoch: [2][703/704]\tTime 0.017 (0.024)\tData 0.002 (0.000)\tLoss 17.4551 (15.6738)\tRetain_Acc@1 25.000 (47.440)\n",
      "Epoch: [2]\t train-acc:\t47.44\t train-loss: 15.67379503818088\n",
      "one epoch duration:17.08683180809021\n",
      "Epoch #3, Learning rate: 0.0001\n",
      "len(r_loader): 704, len(f_loader): 79\n",
      "*** Minimize step ***\n",
      "Epoch: [3][703/704]\tTime 0.017 (0.024)\tData 0.001 (0.000)\tLoss 15.9793 (14.7178)\tRetain_Acc@1 50.000 (50.769)\n",
      "Epoch: [3]\t train-acc:\t50.76888888888889\t train-loss: 14.717838047451442\n",
      "one epoch duration:17.155065774917603\n",
      "Epoch #4, Learning rate: 0.0001\n",
      "len(r_loader): 704, len(f_loader): 79\n",
      "*** Minimize step ***\n",
      "Epoch: [4][703/704]\tTime 0.017 (0.024)\tData 0.002 (0.000)\tLoss 16.4854 (13.8921)\tRetain_Acc@1 62.500 (54.140)\n",
      "Epoch: [4]\t train-acc:\t54.14\t train-loss: 13.89210299343533\n",
      "one epoch duration:17.19275164604187\n",
      "Epoch #5, Learning rate: 0.0001\n",
      "len(r_loader): 704, len(f_loader): 79\n",
      "*** Minimize step ***\n",
      "Epoch: [5][703/704]\tTime 0.017 (0.024)\tData 0.002 (0.000)\tLoss 6.0231 (13.1237)\tRetain_Acc@1 87.500 (56.811)\n",
      "Epoch: [5]\t train-acc:\t56.81111111111111\t train-loss: 13.123669919755724\n",
      "one epoch duration:17.22385287284851\n",
      "Epoch #6, Learning rate: 0.0001\n",
      "len(r_loader): 704, len(f_loader): 79\n",
      "*** Minimize step ***\n",
      "Epoch: [6][703/704]\tTime 0.017 (0.024)\tData 0.002 (0.000)\tLoss 12.5592 (12.3872)\tRetain_Acc@1 75.000 (59.751)\n",
      "Epoch: [6]\t train-acc:\t59.75111111111111\t train-loss: 12.387196152411567\n",
      "one epoch duration:17.219539880752563\n",
      "Epoch #7, Learning rate: 0.0001\n",
      "len(r_loader): 704, len(f_loader): 79\n",
      "*** Minimize step ***\n",
      "Epoch: [7][703/704]\tTime 0.017 (0.024)\tData 0.002 (0.000)\tLoss 13.6412 (11.8072)\tRetain_Acc@1 75.000 (61.553)\n",
      "Epoch: [7]\t train-acc:\t61.553333333333335\t train-loss: 11.807171336873372\n",
      "one epoch duration:17.20316433906555\n",
      "Epoch #8, Learning rate: 0.0001\n",
      "len(r_loader): 704, len(f_loader): 79\n",
      "*** Minimize step ***\n",
      "Epoch: [8][703/704]\tTime 0.017 (0.024)\tData 0.002 (0.000)\tLoss 16.2323 (11.2486)\tRetain_Acc@1 37.500 (63.707)\n",
      "Epoch: [8]\t train-acc:\t63.70666666666666\t train-loss: 11.248623604668511\n",
      "one epoch duration:17.222790002822876\n",
      "Epoch #9, Learning rate: 0.0001\n",
      "len(r_loader): 704, len(f_loader): 79\n",
      "*** Minimize step ***\n",
      "Epoch: [9][703/704]\tTime 0.017 (0.024)\tData 0.002 (0.000)\tLoss 8.3526 (10.7962)\tRetain_Acc@1 87.500 (65.318)\n",
      "Epoch: [9]\t train-acc:\t65.31777777777778\t train-loss: 10.796195969306098\n",
      "one epoch duration:17.237278699874878\n",
      "Epoch #10, Learning rate: 0.0001\n",
      "len(r_loader): 704, len(f_loader): 79\n",
      "*** Minimize step ***\n",
      "Epoch: [10][703/704]\tTime 0.017 (0.024)\tData 0.002 (0.000)\tLoss 16.6151 (10.3728)\tRetain_Acc@1 50.000 (67.020)\n",
      "Epoch: [10]\t train-acc:\t67.02\t train-loss: 10.372833230929905\n",
      "one epoch duration:17.243983507156372\n",
      "Epoch #11, Learning rate: 0.0001\n",
      "len(r_loader): 704, len(f_loader): 79\n",
      "*** Minimize step ***\n",
      "Epoch: [11][703/704]\tTime 0.017 (0.025)\tData 0.002 (0.000)\tLoss 10.7103 (10.0283)\tRetain_Acc@1 62.500 (68.176)\n",
      "Epoch: [11]\t train-acc:\t68.17555555555556\t train-loss: 10.028251037767198\n",
      "one epoch duration:17.255074977874756\n",
      "Epoch #12, Learning rate: 0.0001\n",
      "len(r_loader): 704, len(f_loader): 79\n",
      "*** Minimize step ***\n",
      "Epoch: [12][703/704]\tTime 0.017 (0.025)\tData 0.002 (0.000)\tLoss 10.3891 (9.6703)\tRetain_Acc@1 50.000 (69.264)\n",
      "Epoch: [12]\t train-acc:\t69.26444444444445\t train-loss: 9.670343740844727\n",
      "one epoch duration:17.257646083831787\n",
      "Epoch #13, Learning rate: 0.0001\n",
      "len(r_loader): 704, len(f_loader): 79\n",
      "*** Minimize step ***\n",
      "Epoch: [13][703/704]\tTime 0.017 (0.025)\tData 0.002 (0.000)\tLoss 6.6959 (9.3910)\tRetain_Acc@1 75.000 (70.102)\n",
      "Epoch: [13]\t train-acc:\t70.10222222222222\t train-loss: 9.391015095689562\n",
      "one epoch duration:17.261877298355103\n",
      "Epoch #14, Learning rate: 0.0001\n",
      "len(r_loader): 704, len(f_loader): 79\n",
      "*** Minimize step ***\n",
      "Epoch: [14][703/704]\tTime 0.017 (0.025)\tData 0.001 (0.000)\tLoss 8.5324 (9.1034)\tRetain_Acc@1 75.000 (70.991)\n",
      "Epoch: [14]\t train-acc:\t70.99111111111111\t train-loss: 9.103354520670573\n",
      "one epoch duration:17.266733646392822\n",
      "Epoch #15, Learning rate: 0.0001\n",
      "len(r_loader): 704, len(f_loader): 79\n",
      "*** Minimize step ***\n",
      "Epoch: [15][703/704]\tTime 0.017 (0.025)\tData 0.002 (0.000)\tLoss 8.8674 (8.8568)\tRetain_Acc@1 62.500 (71.851)\n",
      "Epoch: [15]\t train-acc:\t71.85111111111111\t train-loss: 8.856783240932888\n",
      "one epoch duration:17.275417804718018\n",
      "Epoch #16, Learning rate: 0.0001\n",
      "len(r_loader): 704, len(f_loader): 79\n",
      "*** Minimize step ***\n",
      "Epoch: [16][703/704]\tTime 0.017 (0.025)\tData 0.002 (0.000)\tLoss 6.6990 (8.6191)\tRetain_Acc@1 75.000 (72.669)\n",
      "Epoch: [16]\t train-acc:\t72.66888888888889\t train-loss: 8.619103599209256\n",
      "one epoch duration:17.28347086906433\n",
      "Epoch #17, Learning rate: 0.0001\n",
      "len(r_loader): 704, len(f_loader): 79\n",
      "*** Minimize step ***\n",
      "Epoch: [17][703/704]\tTime 0.017 (0.025)\tData 0.002 (0.000)\tLoss 9.6550 (8.4558)\tRetain_Acc@1 62.500 (73.327)\n",
      "Epoch: [17]\t train-acc:\t73.32666666666667\t train-loss: 8.455812802293565\n",
      "one epoch duration:17.28929853439331\n",
      "Epoch #18, Learning rate: 0.0001\n",
      "len(r_loader): 704, len(f_loader): 79\n",
      "*** Minimize step ***\n",
      "Epoch: [18][703/704]\tTime 0.017 (0.025)\tData 0.002 (0.000)\tLoss 4.7893 (8.2434)\tRetain_Acc@1 87.500 (73.949)\n",
      "Epoch: [18]\t train-acc:\t73.94888888888889\t train-loss: 8.243372742970784\n",
      "one epoch duration:17.294011116027832\n",
      "Epoch #19, Learning rate: 0.0001\n",
      "len(r_loader): 704, len(f_loader): 79\n",
      "*** Minimize step ***\n",
      "Epoch: [19][703/704]\tTime 0.017 (0.025)\tData 0.002 (0.000)\tLoss 7.0885 (8.0782)\tRetain_Acc@1 75.000 (74.449)\n",
      "Epoch: [19]\t train-acc:\t74.44888888888889\t train-loss: 8.078176910569933\n",
      "one epoch duration:17.295066118240356\n"
     ]
    }
   ],
   "source": [
    "import unlearn\n",
    "unlearn_method = unlearn.get_unlearn_method(args.unlearn)\n",
    "if args.unlearn == 'SCRUB':\n",
    "    model_s = copy.deepcopy(umodel)\n",
    "    model_t = copy.deepcopy(umodel)\n",
    "    module_list = nn.ModuleList([model_s, model_t])\n",
    "    unlearn_method(data_loaders, module_list, criterion, args)\n",
    "    umodel = module_list[0]\n",
    "else:\n",
    "    unlearn_method(data_loaders, umodel, criterion, args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0431fe87",
   "metadata": {},
   "source": [
    "### Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8995a6ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall accuracy of the unlearned model on the test data: 63.33%\n",
      "Accuracy for class 0: 0.00%\n",
      "Accuracy for class 1: 87.60%\n",
      "Accuracy for class 2: 68.00%\n",
      "Accuracy for class 3: 43.60%\n",
      "Accuracy for class 4: 66.20%\n",
      "Accuracy for class 5: 53.20%\n",
      "Accuracy for class 6: 81.60%\n",
      "Accuracy for class 7: 71.60%\n",
      "Accuracy for class 8: 85.70%\n",
      "Accuracy for class 9: 75.80%\n",
      "forget acc: 0.0\n",
      "retain acc: 74.96444444444444\n",
      "test acc: 63.33\n"
     ]
    }
   ],
   "source": [
    "# Initialize counters for each class\n",
    "from Unlearning import utils\n",
    "from Unlearning.trainer.val import validate\n",
    "\n",
    "\n",
    "class_correct = [0] * 10\n",
    "class_total = [0] * 10\n",
    "\n",
    "# Evaluate the unlearned model\n",
    "umodel.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in data_loaders[\"test\"]:\n",
    "        inputs = inputs.to(device).float()\n",
    "        labels = labels.to(device).long()\n",
    "        outputs = umodel(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "        # Update total and correct counts for each class\n",
    "        for label, prediction in zip(labels, predicted):\n",
    "            class_total[label.item()] += 1\n",
    "            if label.item() == prediction.item():\n",
    "                class_correct[label.item()] += 1\n",
    "\n",
    "# Print overall accuracy\n",
    "overall_accuracy = 100 * sum(class_correct) / sum(class_total)\n",
    "print('Overall accuracy of the unlearned model on the test data: {:.2f}%'.format(overall_accuracy))\n",
    "\n",
    "# Print accuracy for each class\n",
    "for i in range(10):\n",
    "    if class_total[i] > 0:\n",
    "        class_accuracy = 100 * class_correct[i] / class_total[i]\n",
    "        print('Accuracy for class {}: {:.2f}%'.format(i, class_accuracy))\n",
    "    else:\n",
    "        print('No samples for class {}'.format(i))\n",
    "\n",
    "\n",
    "for name, loader in data_loaders.items():\n",
    "        utils.dataset_convert_to_test(loader.dataset, args)\n",
    "        val_acc = validate(loader, umodel, criterion, args)\n",
    "        print(f\"{name} acc: {val_acc}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
