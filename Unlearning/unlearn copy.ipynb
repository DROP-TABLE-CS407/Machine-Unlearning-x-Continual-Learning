{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3e8eb68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/dcs/21/u2110391/CS407/Machine-Unlearning-x-Continual-Learning\n",
      "/dcs/21/u2110391/CS407/Machine-Unlearning-x-Continual-Learning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/dcs/21/u2110391/CS407/Machine-Unlearning-x-Continual-Learning/.venv/lib64/python3.9/site-packages/IPython/core/magics/osm.py:417: UserWarning: using dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%cd ..\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50571c4",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/dcs/21/u2110391/CS407/Machine-Unlearning-x-Continual-Learning/.venv/lib64/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import time\n",
    "from cifar import load_cifar10_data, split_into_classes, get_class_indexes \n",
    "from torch.utils.data import DataLoader\n",
    "import random\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(\".\"))  # Adds the current directory\n",
    "# from GEM.gem import *\n",
    "from GEM.args import *\n",
    "from torch.nn.functional import relu, avg_pool2d\n",
    "import torch.nn as nn\n",
    "import quadprog"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6360b5c4aaa0b84a",
   "metadata": {},
   "source": [
    "# CIFAR-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "545fa36453e0dda4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-13T15:16:56.387836Z",
     "start_time": "2024-11-13T15:16:56.266657Z"
    }
   },
   "outputs": [],
   "source": [
    "# Path to the dataset\n",
    "DATASET_PATH = 'cifar-10-batches-py' \n",
    "CLASSES = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "train_data, train_labels, test_data, test_labels = load_cifar10_data(DATASET_PATH)\n",
    "classes = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "# split the data into 10 classes by doing sort by key where in the keys are the labels and the values are the data\n",
    "train_split = {cls: [] for cls in CLASSES}\n",
    "for img, label in zip(train_data, train_labels):\n",
    "    train_split[CLASSES[label]].append(img)\n",
    "    \n",
    "# this makes more sense to me, effectively indexes 0-5000 are all airplanes, 5000-10000 are all automobiles etc\n",
    "test_split = {cls: [] for cls in CLASSES}\n",
    "for img, label in zip(test_data, test_labels):\n",
    "    test_split[CLASSES[label]].append(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b849681c0f0bdd16",
   "metadata": {},
   "source": [
    "# PRETRAINED MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b345dbfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import time\n",
    "# make cuda available if available\n",
    "\n",
    "from cifar import load_cifar10_data, show_image\n",
    "\n",
    "# we want to create a resnet 18 model for 32x32 images\n",
    "# avoid upscaling, the model will take 32x32 images on input as opposed to 224x224\n",
    "\n",
    "initialisation = time.time()\n",
    "\n",
    "class ResNet18CIFAR(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNet18CIFAR, self).__init__()\n",
    "        self.resnet = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', pretrained=False)\n",
    "        # change the first layer to accept 32x32 images with 3 channels rather than 224x224 images\n",
    "        # check the size of the input layer\n",
    "        print(\"|| conv1 weight size: \", self.resnet.conv1.weight.size())\n",
    "        print(\"|| fc weight size: \", self.resnet.fc.weight.size())\n",
    "        self.resnet.conv1 = torch.nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.resnet.fc = torch.nn.Linear(512, 10)\n",
    "        self.resnet.maxpool = torch.nn.Identity()\n",
    "        # change input layer to accept 32x32 images\n",
    "\n",
    "\n",
    "        \n",
    "        # List all layers in the resnet18 model\n",
    "        for name, layer in self.resnet.named_children():\n",
    "            print(f\"Layer: {name} -> {layer}\")\n",
    "        \n",
    "        #print(\"|| conv1 weight size: \", self.resnet.conv1.weight.size())\n",
    "        #print(\"|| fc weight size: \", self.resnet.fc.weight.size())\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.resnet(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b7e1518a20b7df4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet18CIFAR(\n",
       "  (resnet): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): Identity()\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=512, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.load('models/resnet18_cifar77ACC.pth',  map_location=torch.device('cpu'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fbe76d5",
   "metadata": {},
   "source": [
    "# INITIAL MODEL EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d9dd6044c0b8dfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "||===================START TEST/TRAIN ACCURACY=================||\n",
      "|| Test Set Accuracy: 77.34%\n",
      "||==============================END==========================||\n",
      "|| Time to load data: 1731559331.98s\n",
      "|| Time to get accuracy: 57.80s\n",
      "|| Total time: 1731559389.78s\n",
      "||==============================END==========================||\n"
     ]
    }
   ],
   "source": [
    "# turn the data into a tensor\n",
    "test_data_tensor = torch.tensor(test_data).float()\n",
    "test_labels_tensor = torch.tensor(test_labels)\n",
    "\n",
    "# keep track of accuracy\n",
    "correct1 = 0\n",
    "correct2 = 0\n",
    "total1 = len(train_data)\n",
    "total2 = len(test_data)\n",
    "\n",
    "# start test/train accuracy timer\n",
    "accuracy = time.time()\n",
    "\n",
    "print(\"||===================START TEST/TRAIN ACCURACY=================||\")\n",
    "\n",
    "# move tensors to GPU if available\n",
    "if torch.cuda.is_available():\n",
    "    test_data_tensor = test_data_tensor.cuda()\n",
    "    test_labels_tensor = test_labels_tensor.cuda()\n",
    "    \n",
    "            \n",
    "# test the model\n",
    "with torch.no_grad():\n",
    "    for i in range(0, len(test_data), 1000):\n",
    "        # get the input and output\n",
    "        img = test_data_tensor[i:i+1000]\n",
    "        label = test_labels_tensor[i:i+1000]\n",
    "        \n",
    "\n",
    "        # normalise the image\n",
    "        #img = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])(img)\n",
    "\n",
    "        # get the prediction\n",
    "        outputs = model(img)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "        # get the number of correct predictions\n",
    "        correct2 += (predicted == label).sum().item()\n",
    "        \n",
    "        del img\n",
    "\n",
    "# print the accuracy\n",
    "print(f\"|| Test Set Accuracy: {correct2 / total2 * 100:.2f}%\")\n",
    "\n",
    "print(\"||==============================END==========================||\")\n",
    "\n",
    "# calculate the time taken to get the accuracy\n",
    "accuracy = time.time() - accuracy\n",
    "\n",
    "# print timing information\n",
    "print(f\"|| Time to load data: {initialisation:.2f}s\")\n",
    "print(f\"|| Time to get accuracy: {accuracy:.2f}s\")\n",
    "print(f\"|| Total time: {initialisation + accuracy:.2f}s\")\n",
    "\n",
    "print(\"||==============================END==========================||\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd55059d",
   "metadata": {},
   "source": [
    "# UNLEARNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8c22b66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/dcs/21/u2110391/CS407/Machine-Unlearning-x-Continual-Learning/Unlearning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/dcs/21/u2110391/CS407/Machine-Unlearning-x-Continual-Learning/.venv/lib64/python3.9/site-packages/IPython/core/magics/osm.py:417: UserWarning: using dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "umodel = copy.deepcopy(model)\n",
    "%cd Unlearning/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c590ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from unlearn.scrub import train_distill, iterative_unlearn, scrub\n",
    "from utils import DistillKL, AverageMeter, accuracy\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset, random_split, ConcatDataset, Subset\n",
    "\n",
    "# Convert the data to PyTorch tensors\n",
    "train_dataset = TensorDataset(torch.tensor(train_data), torch.tensor(train_labels))\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "test_dataset = TensorDataset(torch.tensor(test_data), torch.tensor(test_labels))\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "78e88c19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #0, Learning rate: 0.1\n",
      "Epoch: [0][79/783]\tLoss 24.1387 (24.1387)\tAccuracy 15.625 (15.625)\tTime 4.11\n",
      "Epoch: [0][89/783]\tLoss 9.2955 (13.4318)\tAccuracy 10.938 (13.494)\tTime 21.10\n",
      "Epoch: [0][99/783]\tLoss 2.7789 (8.8655)\tAccuracy 10.938 (14.807)\tTime 17.30\n",
      "Epoch: [0][109/783]\tLoss 2.3270 (6.7921)\tAccuracy 21.875 (16.129)\tTime 19.10\n",
      "Epoch: [0][119/783]\tLoss 2.0193 (5.6517)\tAccuracy 26.562 (17.416)\tTime 18.10\n",
      "Epoch: [0][129/783]\tLoss 1.8982 (4.9412)\tAccuracy 34.375 (19.210)\tTime 18.30\n",
      "Epoch: [0][139/783]\tLoss 2.0551 (4.4597)\tAccuracy 20.312 (20.338)\tTime 25.00\n",
      "Epoch: [0][149/783]\tLoss 1.7866 (4.0964)\tAccuracy 32.812 (21.391)\tTime 18.60\n",
      "Epoch: [0][159/783]\tLoss 1.9054 (3.8224)\tAccuracy 25.000 (22.319)\tTime 20.00\n",
      "Epoch: [0][169/783]\tLoss 1.6450 (3.5990)\tAccuracy 45.312 (23.420)\tTime 18.80\n",
      "Epoch: [0][179/783]\tLoss 1.7083 (3.4277)\tAccuracy 35.938 (24.134)\tTime 19.00\n",
      "Epoch: [0][189/783]\tLoss 2.0131 (3.2855)\tAccuracy 15.625 (24.634)\tTime 18.10\n",
      "Epoch: [0][199/783]\tLoss 1.8735 (3.1651)\tAccuracy 26.562 (25.271)\tTime 18.20\n",
      "Epoch: [0][209/783]\tLoss 1.7972 (3.0603)\tAccuracy 32.812 (25.740)\tTime 18.60\n",
      "Epoch: [0][219/783]\tLoss 1.9263 (2.9703)\tAccuracy 35.938 (26.396)\tTime 17.40\n",
      "Epoch: [0][229/783]\tLoss 1.7212 (2.8907)\tAccuracy 31.250 (26.832)\tTime 18.00\n",
      "Epoch: [0][239/783]\tLoss 1.7069 (2.8172)\tAccuracy 39.062 (27.378)\tTime 17.90\n",
      "Epoch: [0][249/783]\tLoss 1.8032 (2.7533)\tAccuracy 39.062 (27.979)\tTime 17.70\n",
      "Epoch: [0][259/783]\tLoss 1.6973 (2.6974)\tAccuracy 31.250 (28.324)\tTime 18.90\n",
      "Epoch: [0][269/783]\tLoss 1.7515 (2.6462)\tAccuracy 37.500 (28.730)\tTime 20.60\n",
      "Epoch: [0][279/783]\tLoss 1.7880 (2.5984)\tAccuracy 32.812 (29.174)\tTime 18.50\n",
      "Epoch: [0][289/783]\tLoss 1.7755 (2.5552)\tAccuracy 32.812 (29.562)\tTime 17.50\n",
      "Epoch: [0][299/783]\tLoss 1.7207 (2.5154)\tAccuracy 35.938 (30.006)\tTime 18.30\n",
      "Epoch: [0][309/783]\tLoss 1.8412 (2.4798)\tAccuracy 29.688 (30.296)\tTime 21.20\n",
      "Epoch: [0][319/783]\tLoss 1.5846 (2.4458)\tAccuracy 43.750 (30.634)\tTime 18.30\n",
      "Epoch: [0][329/783]\tLoss 1.5340 (2.4119)\tAccuracy 40.625 (31.213)\tTime 16.80\n",
      "Epoch: [0][339/783]\tLoss 1.7365 (2.3834)\tAccuracy 35.938 (31.448)\tTime 18.90\n",
      "Epoch: [0][349/783]\tLoss 1.5650 (2.3561)\tAccuracy 50.000 (31.769)\tTime 18.20\n",
      "Epoch: [0][359/783]\tLoss 1.4660 (2.3300)\tAccuracy 48.438 (32.079)\tTime 19.10\n",
      "Epoch: [0][369/783]\tLoss 1.7748 (2.3043)\tAccuracy 39.062 (32.388)\tTime 18.40\n",
      "Epoch: [0][379/783]\tLoss 1.4058 (2.2782)\tAccuracy 46.875 (32.693)\tTime 17.80\n",
      "Epoch: [0][389/783]\tLoss 1.6218 (2.2566)\tAccuracy 35.938 (32.958)\tTime 17.20\n",
      "Epoch: [0][399/783]\tLoss 1.6229 (2.2352)\tAccuracy 40.625 (33.251)\tTime 17.10\n",
      "Epoch: [0][409/783]\tLoss 1.4027 (2.2157)\tAccuracy 53.125 (33.492)\tTime 18.70\n",
      "Epoch: [0][419/783]\tLoss 1.5180 (2.1958)\tAccuracy 42.188 (33.734)\tTime 18.30\n",
      "Epoch: [0][429/783]\tLoss 1.4702 (2.1761)\tAccuracy 50.000 (34.001)\tTime 18.00\n",
      "Epoch: [0][439/783]\tLoss 1.3926 (2.1583)\tAccuracy 59.375 (34.345)\tTime 21.30\n",
      "Epoch: [0][449/783]\tLoss 1.4225 (2.1413)\tAccuracy 51.562 (34.607)\tTime 18.60\n",
      "Epoch: [0][459/783]\tLoss 1.5898 (2.1264)\tAccuracy 46.875 (34.789)\tTime 19.10\n",
      "Epoch: [0][469/783]\tLoss 1.5876 (2.1105)\tAccuracy 35.938 (35.010)\tTime 16.90\n",
      "Epoch: [0][479/783]\tLoss 1.5586 (2.0977)\tAccuracy 42.188 (35.197)\tTime 22.00\n",
      "Epoch: [0][489/783]\tLoss 1.4886 (2.0831)\tAccuracy 50.000 (35.477)\tTime 18.40\n",
      "Epoch: [0][499/783]\tLoss 1.5548 (2.0695)\tAccuracy 34.375 (35.626)\tTime 17.30\n",
      "Epoch: [0][509/783]\tLoss 1.4159 (2.0563)\tAccuracy 42.188 (35.840)\tTime 19.80\n",
      "Epoch: [0][519/783]\tLoss 1.4547 (2.0448)\tAccuracy 42.188 (36.083)\tTime 18.50\n",
      "Epoch: [0][529/783]\tLoss 1.2868 (2.0296)\tAccuracy 54.688 (36.426)\tTime 19.00\n",
      "Epoch: [0][539/783]\tLoss 1.3660 (2.0171)\tAccuracy 51.562 (36.673)\tTime 19.20\n",
      "Epoch: [0][549/783]\tLoss 1.3527 (2.0068)\tAccuracy 53.125 (36.817)\tTime 18.20\n",
      "Epoch: [0][559/783]\tLoss 1.2777 (1.9944)\tAccuracy 56.250 (37.045)\tTime 20.60\n",
      "Epoch: [0][569/783]\tLoss 1.1670 (1.9828)\tAccuracy 59.375 (37.236)\tTime 18.21\n",
      "Epoch: [0][579/783]\tLoss 1.3025 (1.9715)\tAccuracy 46.875 (37.428)\tTime 17.70\n",
      "Epoch: [0][589/783]\tLoss 1.5825 (1.9601)\tAccuracy 34.375 (37.616)\tTime 18.80\n",
      "Epoch: [0][599/783]\tLoss 1.1128 (1.9501)\tAccuracy 64.062 (37.803)\tTime 19.00\n",
      "Epoch: [0][609/783]\tLoss 1.4138 (1.9404)\tAccuracy 53.125 (37.994)\tTime 17.60\n",
      "Epoch: [0][619/783]\tLoss 1.5840 (1.9307)\tAccuracy 45.312 (38.219)\tTime 18.00\n",
      "Epoch: [0][629/783]\tLoss 1.1604 (1.9205)\tAccuracy 51.562 (38.444)\tTime 18.20\n",
      "Epoch: [0][639/783]\tLoss 1.4044 (1.9112)\tAccuracy 51.562 (38.650)\tTime 18.20\n",
      "Epoch: [0][649/783]\tLoss 1.1871 (1.9010)\tAccuracy 60.938 (38.917)\tTime 19.70\n",
      "Epoch: [0][659/783]\tLoss 1.3106 (1.8923)\tAccuracy 53.125 (39.116)\tTime 19.80\n",
      "Epoch: [0][669/783]\tLoss 1.4287 (1.8831)\tAccuracy 48.438 (39.345)\tTime 18.80\n",
      "Epoch: [0][679/783]\tLoss 1.2209 (1.8753)\tAccuracy 59.375 (39.533)\tTime 18.40\n",
      "Epoch: [0][689/783]\tLoss 1.3550 (1.8670)\tAccuracy 45.312 (39.717)\tTime 17.40\n",
      "Epoch: [0][699/783]\tLoss 1.5457 (1.8581)\tAccuracy 43.750 (39.931)\tTime 18.30\n",
      "Epoch: [0][709/783]\tLoss 1.2776 (1.8501)\tAccuracy 54.688 (40.115)\tTime 18.80\n",
      "Epoch: [0][719/783]\tLoss 1.4590 (1.8433)\tAccuracy 45.312 (40.242)\tTime 17.70\n",
      "Epoch: [0][729/783]\tLoss 1.1836 (1.8341)\tAccuracy 62.500 (40.474)\tTime 18.40\n",
      "Epoch: [0][739/783]\tLoss 1.1583 (1.8257)\tAccuracy 56.250 (40.682)\tTime 19.00\n",
      "Epoch: [0][749/783]\tLoss 1.2610 (1.8184)\tAccuracy 59.375 (40.879)\tTime 17.60\n",
      "Epoch: [0][759/783]\tLoss 1.2339 (1.8104)\tAccuracy 56.250 (41.072)\tTime 19.50\n",
      "Epoch: [0][769/783]\tLoss 1.1336 (1.8015)\tAccuracy 53.125 (41.292)\tTime 17.90\n",
      "Epoch: [0][779/783]\tLoss 1.1746 (1.7936)\tAccuracy 53.125 (41.488)\tTime 18.70\n",
      "Epoch: [0][789/783]\tLoss 1.5749 (1.7855)\tAccuracy 53.125 (41.682)\tTime 21.30\n",
      "Epoch: [0][799/783]\tLoss 1.1717 (1.7790)\tAccuracy 56.250 (41.845)\tTime 18.30\n",
      "Epoch: [0][809/783]\tLoss 1.0276 (1.7721)\tAccuracy 67.188 (42.040)\tTime 19.90\n",
      "Epoch: [0][819/783]\tLoss 1.0103 (1.7641)\tAccuracy 68.750 (42.289)\tTime 18.70\n",
      "Epoch: [0][829/783]\tLoss 1.2980 (1.7563)\tAccuracy 51.562 (42.477)\tTime 22.10\n",
      "Epoch: [0][839/783]\tLoss 1.4652 (1.7492)\tAccuracy 42.188 (42.623)\tTime 18.80\n",
      "Epoch: [0][849/783]\tLoss 1.1894 (1.7424)\tAccuracy 62.500 (42.798)\tTime 20.90\n",
      "Epoch: [0][859/783]\tLoss 1.2403 (1.7348)\tAccuracy 57.812 (43.024)\tTime 22.00\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'logger' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 81\u001b[0m\n\u001b[1;32m     78\u001b[0m args \u001b[38;5;241m=\u001b[39m Args()\n\u001b[1;32m     80\u001b[0m \u001b[38;5;66;03m# Now, call the RL function with adjusted arguments\u001b[39;00m\n\u001b[0;32m---> 81\u001b[0m \u001b[43mRL\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_loaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;66;03m# The unlearned model is now in 'model'\u001b[39;00m\n\u001b[1;32m     84\u001b[0m unlearned_model \u001b[38;5;241m=\u001b[39m model\n",
      "File \u001b[0;32m~/CS407/Machine-Unlearning-x-Continual-Learning/Unlearning/unlearn/impl.py:250\u001b[0m, in \u001b[0;36m_iterative_unlearn_impl.<locals>._wrapped\u001b[0;34m(data_loaders, model, criterion, args, mask, **kwargs)\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    244\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    245\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch #\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, Learning rate: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    246\u001b[0m             epoch, optimizer\u001b[38;5;241m.\u001b[39mstate_dict()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparam_groups\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    247\u001b[0m         )\n\u001b[1;32m    248\u001b[0m     )\n\u001b[0;32m--> 250\u001b[0m train_acc \u001b[38;5;241m=\u001b[39m \u001b[43munlearn_iter_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_loaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    253\u001b[0m scheduler\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mone epoch duration:\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time))\n",
      "File \u001b[0;32m~/CS407/Machine-Unlearning-x-Continual-Learning/Unlearning/unlearn/RL.py:100\u001b[0m, in \u001b[0;36mRL\u001b[0;34m(data_loaders, model, criterion, optimizer, epoch, args, mask)\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m     91\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch: [\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m][\u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     92\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoss \u001b[39m\u001b[38;5;132;01m{loss.val:.4f}\u001b[39;00m\u001b[38;5;124m (\u001b[39m\u001b[38;5;132;01m{loss.avg:.4f}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     96\u001b[0m             )\n\u001b[1;32m     97\u001b[0m         )\n\u001b[1;32m     98\u001b[0m         start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 100\u001b[0m \u001b[43mlogger\u001b[49m\u001b[38;5;241m.\u001b[39mlog({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_acc\u001b[39m\u001b[38;5;124m\"\u001b[39m: top1\u001b[38;5;241m.\u001b[39mavg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m: losses\u001b[38;5;241m.\u001b[39mavg})\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m top1\u001b[38;5;241m.\u001b[39mavg\n",
      "\u001b[0;31mNameError\u001b[0m: name 'logger' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from unlearn.RL import RL\n",
    "\n",
    "# Assume 'train_data' and 'train_labels' are your training data and labels\n",
    "# 'test_data' and 'test_labels' are your test data and labels\n",
    "# 'model' is your pretrained ResNet model\n",
    "\n",
    "# Define the class you want to unlearn\n",
    "class_to_unlearn = 0  # Change this to the class you want to unlearn\n",
    "\n",
    "\n",
    "# Convert data and labels to tensors if they aren't already\n",
    "train_data_tensor = torch.tensor(train_data, dtype=torch.float32)\n",
    "train_labels_tensor = torch.tensor(train_labels)\n",
    "test_data_tensor = torch.tensor(test_data, dtype=torch.float32)\n",
    "test_labels_tensor = torch.tensor(test_labels)\n",
    "\n",
    "# Create TensorDatasets directly for 'forget' and 'retain' subsets\n",
    "forget_indices = (train_labels_tensor == class_to_unlearn).nonzero(as_tuple=True)[0]\n",
    "retain_indices = (train_labels_tensor != class_to_unlearn).nonzero(as_tuple=True)[0]\n",
    "\n",
    "# Create 'forget' dataset\n",
    "forget_data = train_data_tensor[forget_indices]\n",
    "forget_labels = train_labels_tensor[forget_indices]\n",
    "forget_dataset = TensorDataset(forget_data, forget_labels)\n",
    "\n",
    "# Create 'retain' dataset\n",
    "retain_data = train_data_tensor[retain_indices]\n",
    "retain_labels = train_labels_tensor[retain_indices]\n",
    "retain_dataset = TensorDataset(retain_data, retain_labels)\n",
    "\n",
    "# Create DataLoaders\n",
    "forget_loader = DataLoader(forget_dataset, batch_size=64, shuffle=True)\n",
    "retain_loader = DataLoader(retain_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Prepare the data_loaders dictionary\n",
    "data_loaders = {'forget': forget_loader, 'retain': retain_loader}\n",
    "\n",
    "# Create the test DataLoader\n",
    "test_dataset = TensorDataset(test_data_tensor, test_labels_tensor)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# Move the model to device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "# Define the criterion and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)\n",
    "\n",
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.unlearn_lr = 0.1         # Learning rate for unlearning\n",
    "        self.momentum = 0.9\n",
    "        self.weight_decay = 5e-4\n",
    "        self.dataset = ''      # Change as needed\n",
    "        self.num_classes = 10         # Number of classes in the dataset\n",
    "        self.batch_size = 64\n",
    "        self.print_freq = 10\n",
    "        self.warmup = 0               # Number of warmup epochs\n",
    "        self.imagenet_arch = False    # Set to True if using ImageNet architecture\n",
    "        self.seed = 42                # For reproducibility\n",
    "\n",
    "\n",
    "        # Add the following attributes to ensure compatibility\n",
    "        self.decreasing_lr = '50,75'  # Comma-separated epochs where LR decays\n",
    "        self.rewind_epoch = 0         # Epoch to rewind to; set to 0 if not using rewinding\n",
    "        self.rewind_pth = ''          # Path to the rewind checkpoint\n",
    "        self.gpu = 0                  # GPU ID to use; adjust as needed\n",
    "        self.surgical = False         # Whether to use surgical unlearning\n",
    "        self.choice = []              # Layers to unlearn surgically; list of layer names\n",
    "        self.unlearn = 'retrain'      # Unlearning method, e.g., 'retrain'\n",
    "        self.unlearn_epochs = 10     # Number of epochs for unlearning\n",
    "        self.epochs = 100             # Total number of epochs (used for scheduler)    # For reproducibility\n",
    "\n",
    "args = Args()\n",
    "\n",
    "# Now, call the RL function with adjusted arguments\n",
    "RL(data_loaders, model, criterion, args=args)\n",
    "\n",
    "# The unlearned model is now in 'model'\n",
    "unlearned_model = model\n",
    "\n",
    "# Evaluate the unlearned model on the test dataset\n",
    "unlearned_model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs = inputs.to(device).float()\n",
    "        labels = labels.to(device).long()\n",
    "        outputs = unlearned_model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the unlearned model on the test data: {:.2f}%'.format(100 * correct / total))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
